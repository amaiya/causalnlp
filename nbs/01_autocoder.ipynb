{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp causalinference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoCoder\n",
    "\n",
    "> Automatically codes text fields such as open-ended survey questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "def list2chunks(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ZeroShotClassifier():\n",
    "    \"\"\"\n",
    "    interface to Zero Shot Topic Classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name='facebook/bart-large-mnli', device=None):\n",
    "        \"\"\"\n",
    "        ZeroShotClassifier constructor\n",
    "\n",
    "        Args:\n",
    "          model_name(str): name of a BART NLI model\n",
    "          device(str): device to use (e.g., 'cuda', 'cpu')\n",
    "        \"\"\"\n",
    "        if 'mnli' not in model_name and 'xnli' not in model_name:\n",
    "            raise ValueError('ZeroShotClasifier requires an MNLI or XNLI model')\n",
    "        try:\n",
    "            import torch\n",
    "        except ImportError:\n",
    "            raise Exception('ZeroShotClassifier requires PyTorch to be installed.')\n",
    "        self.torch_device = device\n",
    "        if self.torch_device is None: self.torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.torch_device)\n",
    "\n",
    "\n",
    "    def predict(self, docs, labels=[], include_labels=False, multilabel=True,\n",
    "               max_length=512, batch_size=8, nli_template='This text is about {}.',  topic_strings=[]):\n",
    "        \"\"\"\n",
    "        This method performs zero-shot text classification using Natural Language Inference (NLI).\n",
    "        Args:\n",
    "          docs(list|str): text of document or list of texts\n",
    "          labels(list): a list of strings representing topics of your choice\n",
    "                        Example:\n",
    "                          labels=['political science', 'sports', 'science']\n",
    "          include_labels(bool): If True, will return topic labels along with topic probabilities\n",
    "          multilabel(bool): If True, labels are considered independent and multiple labels can predicted true for document and be close to 1.\n",
    "                            If False, scores are normalized such that probabilities sum to 1.\n",
    "          max_length(int): truncate long documents to this many tokens\n",
    "          batch_size(int): batch_size to use. default:8\n",
    "                           Increase this value to speed up predictions - especially\n",
    "                           if len(topic_strings) is large.\n",
    "          nli_template(str): labels are inserted into this template for use as hypotheses in natural language inference\n",
    "          topic_strings(list): alias for labels parameter for backwards compatibility\n",
    "        Returns:\n",
    "          inferred probabilities or list of inferred probabilities if doc is list\n",
    "        \"\"\"\n",
    "\n",
    "        # error checks\n",
    "        is_str_input = False\n",
    "        if not isinstance(docs, (list, np.ndarray)): \n",
    "            docs = [docs]\n",
    "            is_str_input = True\n",
    "        if not isinstance(docs[0], str): raise ValueError('docs must be string or a list of strings representing document(s)')\n",
    "        if len(labels) > 0 and len(topic_strings) > 0: raise ValueError('labels and topic_strings are mutually exclusive')\n",
    "        if not labels and not topic_strings: raise ValueError('labels must be a list of strings')\n",
    "        if topic_strings: \n",
    "            labels = topic_strings\n",
    "\n",
    "\n",
    "        # convert to sequences\n",
    "        sequence_pairs = []\n",
    "        for premise in docs:\n",
    "            sequence_pairs.extend([[premise, nli_template.format(label)] for label in labels])\n",
    "        if batch_size  > len(sequence_pairs): batch_size = len(sequence_pairs)\n",
    "        if len(sequence_pairs) >= 100 and batch_size==8:\n",
    "            warnings.warn('TIP: Try increasing batch_size to speedup ZeroShotClassifier predictions')\n",
    "        num_chunks = math.ceil(len(sequence_pairs)/batch_size)\n",
    "        sequence_chunks = list2chunks(sequence_pairs, n=num_chunks)\n",
    "\n",
    "        # inference\n",
    "        import torch\n",
    "        with torch.no_grad():\n",
    "            outputs = []\n",
    "            for sequences in sequence_chunks:\n",
    "                batch = self.tokenizer.batch_encode_plus(sequences, return_tensors='pt', max_length=max_length, truncation='only_first', padding=True).to(self.torch_device)\n",
    "                logits = self.model(batch['input_ids'], attention_mask=batch['attention_mask'], return_dict=False)[0]\n",
    "                outputs.extend(logits.cpu().detach().numpy())\n",
    "        outputs = np.array(outputs)\n",
    "        outputs = outputs.reshape((len(docs), len(labels), -1))\n",
    "\n",
    "        # process outputs\n",
    "        if multilabel:\n",
    "            # softmax over the entailment vs. contradiction dim for each label independently\n",
    "            entail_contr_logits = outputs[..., [0, -1]]\n",
    "            scores = np.exp(entail_contr_logits) / np.exp(entail_contr_logits).sum(-1, keepdims=True)\n",
    "            scores = scores[..., 1]\n",
    "        else:\n",
    "            # softmax the \"entailment\" logits over all candidate labels\n",
    "            entail_logits = outputs[..., -1]\n",
    "            scores = np.exp(entail_logits) / np.exp(entail_logits).sum(-1, keepdims=True)\n",
    "        scores = scores.tolist()\n",
    "        if include_labels:\n",
    "            scores = [list(zip(labels, s)) for s in scores]\n",
    "        if is_str_input: scores = scores[0]\n",
    "        return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsl = ZeroShotClassifier()\n",
    "labels=['politics', 'elections', 'sports', 'films', 'television']\n",
    "doc = 'I am extremely dissatisfied with the President and will definitely vote in 2020.'\n",
    "preds = zsl.predict(doc, labels=labels, include_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('politics', 0.979189932346344),\n",
       " ('elections', 0.9874580502510071),\n",
       " ('sports', 0.0005765454261563718),\n",
       " ('films', 0.002292441902682185),\n",
       " ('television', 0.001054605352692306)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(preds)\n",
    "assert d['politics'] > 0.9\n",
    "assert d['elections'] > 0.9\n",
    "assert d['sports'] < 0.1\n",
    "assert d['films'] < 0.1\n",
    "assert d['television'] < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AutoCoder:\n",
    "    \"\"\"\n",
    "    Autocodes text fields\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=1):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "        \"\"\"\n",
    "        self.v = verbose\n",
    "        self.zsl = ZeroShotClassifier()\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    def sentiment(self, texts, batch_size=8):\n",
    "        \"\"\"\n",
    "        Autocodes text for positive or negative sentiment\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str): texts = [texts]\n",
    "        \n",
    "        if not isinstance(texts, list): raise ValueError('texts must be a string or a list of strings')\n",
    "        \n",
    "        return zsl.predict(texts, labels=['negative', 'positive'], include_labels=True, multilabel=False,\n",
    "                           batch_size=batch_size,\n",
    "                           nli_template=\"The sentiment of this movie review is {}.\")\n",
    "    \n",
    "    def custom_topic(self, texts, labels, batch_size=8):\n",
    "        \"\"\"\n",
    "        Autocodes text for user-specified topics.\n",
    "        The `label` field is the name of the topic as a string (or a list of them.)\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str): texts = [texts]   \n",
    "        if not isinstance(texts, list): raise ValueError('texts must be a string or a list of strings')\n",
    "            \n",
    "        return zsl.predict(texts, labels=labels, include_labels=True, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('negative', 0.005033864174038172), ('positive', 0.9949660897254944)],\n",
       " [('negative', 0.9817894101142883), ('positive', 0.018210623413324356)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = AutoCoder()\n",
    "reviews = [\"I loved this doctor!\", \"This doctor was absolutely terrible.\"]\n",
    "result = ac.sentiment(reviews)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(result[0])\n",
    "assert d['negative'] < 0.1\n",
    "assert d['positive'] > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('television', 0.9813268780708313),\n",
       "  ('film', 0.012259923852980137),\n",
       "  ('politics', 0.0001566773426020518)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = \"What is your favorite sitcom of all time?\"\n",
    "result = ac.custom_topic(comment, labels=['television', 'film', 'politics'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(result[0])\n",
    "assert d['television'] > 0.9\n",
    "assert d['film'] < 0.1\n",
    "assert d['politics'] < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_causalinference.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
