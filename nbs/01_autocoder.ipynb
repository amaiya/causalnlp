{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp autocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Coder\n",
    "\n",
    "> Automatically codes text fields such as open-ended survey questions based on lingustic properties such as topic and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def list2chunks(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class ZeroShotClassifier():\n",
    "    \"\"\"\n",
    "    Interface to Zero Shot Topic Classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name='facebook/bart-large-mnli', device=None):\n",
    "        \"\"\"\n",
    "        ZeroShotClassifier constructor\n",
    "\n",
    "        Args:\n",
    "          model_name(str): name of a BART NLI model\n",
    "          device(str): device to use (e.g., 'cuda', 'cpu')\n",
    "        \"\"\"\n",
    "        if 'mnli' not in model_name and 'xnli' not in model_name:\n",
    "            raise ValueError('ZeroShotClasifier requires an MNLI or XNLI model')\n",
    "        try:\n",
    "            import torch\n",
    "        except ImportError:\n",
    "            raise Exception('ZeroShotClassifier requires PyTorch to be installed.')\n",
    "        self.torch_device = device\n",
    "        if self.torch_device is None: self.torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.torch_device)\n",
    "\n",
    "\n",
    "    def predict(self, docs, labels=[], include_labels=False, multilabel=True,\n",
    "               max_length=512, batch_size=8, nli_template='This text is about {}.',  topic_strings=[]):\n",
    "        \"\"\"\n",
    "        This method performs zero-shot text classification using Natural Language Inference (NLI).\n",
    "\n",
    "\n",
    "        **Parameters**:\n",
    "          - docs(list|str): text of document or list of texts\n",
    "          - labels(list): a list of strings representing topics of your choice\n",
    "                          Example:\n",
    "                           labels=['political science', 'sports', 'science']\n",
    "          - include_labels(bool): If True, will return topic labels along with topic probabilities\n",
    "          - multilabel(bool): If True, labels are considered independent and multiple labels can predicted true for document and be close to 1.\n",
    "                            If False, scores are normalized such that probabilities sum to 1.\n",
    "          - max_length(int): truncate long documents to this many tokens\n",
    "          - batch_size(int): batch_size to use. default:8\n",
    "                           Increase this value to speed up predictions - especially\n",
    "                           if len(topic_strings) is large.\n",
    "          - nli_template(str): labels are inserted into this template for use as hypotheses in natural language inference\n",
    "          - topic_strings(list): alias for labels parameter for backwards compatibility\n",
    "          \n",
    "        **Returns:**\n",
    "        \n",
    "        \n",
    "          inferred probabilities or list of inferred probabilities if doc is list\n",
    "        \"\"\"\n",
    "\n",
    "        # error checks\n",
    "        is_str_input = False\n",
    "        if not isinstance(docs, (list, np.ndarray)): \n",
    "            docs = [docs]\n",
    "            is_str_input = True\n",
    "        if not isinstance(docs[0], str): raise ValueError('docs must be string or a list of strings representing document(s)')\n",
    "        if len(labels) > 0 and len(topic_strings) > 0: raise ValueError('labels and topic_strings are mutually exclusive')\n",
    "        if not labels and not topic_strings: raise ValueError('labels must be a list of strings')\n",
    "        if topic_strings: \n",
    "            labels = topic_strings\n",
    "\n",
    "\n",
    "        # convert to sequences\n",
    "        sequence_pairs = []\n",
    "        for premise in docs:\n",
    "            sequence_pairs.extend([[premise, nli_template.format(label)] for label in labels])\n",
    "        if batch_size  > len(sequence_pairs): batch_size = len(sequence_pairs)\n",
    "        if len(sequence_pairs) >= 100 and batch_size==8:\n",
    "            warnings.warn('TIP: Try increasing batch_size to speedup ZeroShotClassifier predictions')\n",
    "        num_chunks = math.ceil(len(sequence_pairs)/batch_size)\n",
    "        sequence_chunks = list2chunks(sequence_pairs, n=num_chunks)\n",
    "\n",
    "        # inference\n",
    "        import torch\n",
    "        with torch.no_grad():\n",
    "            outputs = []\n",
    "            for sequences in sequence_chunks:\n",
    "                batch = self.tokenizer.batch_encode_plus(sequences, return_tensors='pt', max_length=max_length, truncation='only_first', padding=True).to(self.torch_device)\n",
    "                logits = self.model(batch['input_ids'], attention_mask=batch['attention_mask'], return_dict=False)[0]\n",
    "                outputs.extend(logits.cpu().detach().numpy())\n",
    "        outputs = np.array(outputs)\n",
    "        outputs = outputs.reshape((len(docs), len(labels), -1))\n",
    "\n",
    "        # process outputs\n",
    "        if multilabel:\n",
    "            # softmax over the entailment vs. contradiction dim for each label independently\n",
    "            entail_contr_logits = outputs[..., [0, -1]]\n",
    "            scores = np.exp(entail_contr_logits) / np.exp(entail_contr_logits).sum(-1, keepdims=True)\n",
    "            scores = scores[..., 1]\n",
    "        else:\n",
    "            # softmax the \"entailment\" logits over all candidate labels\n",
    "            entail_logits = outputs[..., -1]\n",
    "            scores = np.exp(entail_logits) / np.exp(entail_logits).sum(-1, keepdims=True)\n",
    "        scores = scores.tolist()\n",
    "        if include_labels:\n",
    "            scores = [list(zip(labels, s)) for s in scores]\n",
    "        if is_str_input: scores = scores[0]\n",
    "        return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ZeroShotClassifier.predict\" class=\"doc_header\"><code>ZeroShotClassifier.predict</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ZeroShotClassifier.predict</code>(**`docs`**, **`labels`**=*`[]`*, **`include_labels`**=*`False`*, **`multilabel`**=*`True`*, **`max_length`**=*`512`*, **`batch_size`**=*`8`*, **`nli_template`**=*`'This text is about {}.'`*, **`topic_strings`**=*`[]`*)\n",
       "\n",
       "This method performs zero-shot text classification using Natural Language Inference (NLI).\n",
       "\n",
       "\n",
       "**Parameters**:\n",
       "  - docs(list|str): text of document or list of texts\n",
       "  - labels(list): a list of strings representing topics of your choice\n",
       "                  Example:\n",
       "                   labels=['political science', 'sports', 'science']\n",
       "  - include_labels(bool): If True, will return topic labels along with topic probabilities\n",
       "  - multilabel(bool): If True, labels are considered independent and multiple labels can predicted true for document and be close to 1.\n",
       "                    If False, scores are normalized such that probabilities sum to 1.\n",
       "  - max_length(int): truncate long documents to this many tokens\n",
       "  - batch_size(int): batch_size to use. default:8\n",
       "                   Increase this value to speed up predictions - especially\n",
       "                   if len(topic_strings) is large.\n",
       "  - nli_template(str): labels are inserted into this template for use as hypotheses in natural language inference\n",
       "  - topic_strings(list): alias for labels parameter for backwards compatibility\n",
       "  \n",
       "**Returns:**\n",
       "  inferred probabilities or list of inferred probabilities if doc is list"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ZeroShotClassifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsl = ZeroShotClassifier()\n",
    "labels=['politics', 'elections', 'sports', 'films', 'television']\n",
    "doc = 'I am extremely dissatisfied with the President and will definitely vote in 2020.'\n",
    "preds = zsl.predict(doc, labels=labels, include_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('politics', 0.979189932346344),\n",
       " ('elections', 0.9874580502510071),\n",
       " ('sports', 0.0005765454261563718),\n",
       " ('films', 0.002292441902682185),\n",
       " ('television', 0.001054605352692306)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(preds)\n",
    "assert d['politics'] > 0.9\n",
    "assert d['elections'] > 0.9\n",
    "assert d['sports'] < 0.1\n",
    "assert d['films'] < 0.1\n",
    "assert d['television'] < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Autocoder:\n",
    "    \"\"\"\n",
    "    Autocodes text fields\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=1):\n",
    "        \"\"\"\n",
    "        Instantiates the Autocoder instance.\n",
    "        \"\"\"\n",
    "        self.v = verbose\n",
    "        self.zsl = ZeroShotClassifier()\n",
    "\n",
    "\n",
    "    def _format_to_df(self, results, df):\n",
    "        d = {}\n",
    "        for e in results:\n",
    "            if isinstance(e, dict): e = e.items()\n",
    "            for tup in e:\n",
    "                label = tup[0]\n",
    "                prob = tup[1]\n",
    "                lst = d.get(label, [])\n",
    "                lst.append(prob)\n",
    "                d[label] = lst\n",
    "        new_df = df.join(pd.DataFrame(d, index=df.index))      \n",
    "        return new_df\n",
    "    \n",
    "    def _binarize_df(self, df, colnames, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Binarizes each column in `colnames` based on threshold.\n",
    "        \"\"\"\n",
    "        for col in colnames:\n",
    "            df[col] = (df[col] >= threshold).astype(int)\n",
    "        return df\n",
    "        \n",
    "\n",
    "    def code_sentiment(self, docs, df, batch_size=8, binarize=False, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Autocodes text for positive or negative sentiment\n",
    "        \"\"\"\n",
    "        labels = ['negative', 'positive']\n",
    "        results = self.zsl.predict(docs, labels=labels, include_labels=True, multilabel=False,\n",
    "                              batch_size=batch_size,\n",
    "                              nli_template=\"The sentiment of this movie review is {}.\")\n",
    "        df= self._format_to_df(results, df)   \n",
    "        if binarize: df = self._binarize_df(df, labels, threshold=threshold)\n",
    "        return df\n",
    "        \n",
    "    def code_emotion(self, docs, df, batch_size=8, binarize=False, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Autocodes text for emotion\n",
    "        \"\"\"\n",
    "        labels = ['joy', 'anger', 'fear', 'sadness']\n",
    "        results = self.zsl.predict(docs, labels=labels, include_labels=True, multilabel=False,\n",
    "                              batch_size=batch_size,\n",
    "                              nli_template=\"The emotion of this text is {}.\")\n",
    "        df= self._format_to_df(results, df)   \n",
    "        if binarize: df = self._binarize_df(df, labels, threshold=threshold)\n",
    "        return df       \n",
    "    \n",
    "    def code_custom_topics(self, docs, df, labels, batch_size=8, binarize=False, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Autocodes text for user-specified topics.\n",
    "        The `label` field is the name of the topic as a string (or a list of them.)\n",
    "        \"\"\"\n",
    "            \n",
    "        results = self.zsl.predict(docs, labels=labels, include_labels=True, batch_size=8)\n",
    "        df = self._format_to_df(results, df)    \n",
    "        if binarize: df = self._binarize_df(df, labels, threshold=threshold)\n",
    "        return df\n",
    "    \n",
    "    def code_callable(self, docs, df, fn):\n",
    "        \"\"\"\n",
    "        Autocodes text for any user-specified function\n",
    "        The `fn` parameter must be a Callable and return a dictionary for each\n",
    "        text in `docs` where the keys are desired column names and values are scores\n",
    "        or probabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.zsl.predict(docs, labels=labels, include_labels=True, batch_size=8)\n",
    "        df = self._format_to_df(results, df)    \n",
    "        if binarize: df = self._binarize_df(df, labels, threshold=threshold)\n",
    "        return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Autocoder.code_sentiment\" class=\"doc_header\"><code>Autocoder.code_sentiment</code><a href=\"__main__.py#L36\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Autocoder.code_sentiment</code>(**`docs`**, **`df`**, **`batch_size`**=*`8`*, **`binarize`**=*`False`*, **`threshold`**=*`0.5`*)\n",
       "\n",
       "Autocodes text for positive or negative sentiment"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Autocoder.code_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Autocoder.code_custom_topics\" class=\"doc_header\"><code>Autocoder.code_custom_topics</code><a href=\"__main__.py#L60\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Autocoder.code_custom_topics</code>(**`docs`**, **`df`**, **`labels`**, **`batch_size`**=*`8`*, **`binarize`**=*`False`*, **`threshold`**=*`0.5`*)\n",
       "\n",
       "Autocodes text for user-specified topics.\n",
       "The `label` field is the name of the topic as a string (or a list of them.)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Autocoder.code_custom_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Autocoder.code_emotion\" class=\"doc_header\"><code>Autocoder.code_emotion</code><a href=\"__main__.py#L48\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Autocoder.code_emotion</code>(**`docs`**, **`df`**, **`batch_size`**=*`8`*, **`binarize`**=*`False`*, **`threshold`**=*`0.5`*)\n",
       "\n",
       "Autocodes text for emotion"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Autocoder.code_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the dataframe looks like before autocoding for sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>I loved this doctor!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>This doctor was absolutely terrible.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                review\n",
       "0  female                  I loved this doctor!\n",
       "1    male  This doctor was absolutely terrible."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = Autocoder()\n",
    "reviews = [\"I loved this doctor!\", \"This doctor was absolutely terrible.\"]\n",
    "df = pd.DataFrame({\n",
    "    'gender': ['female', 'male'],\n",
    "     'review' : reviews,\n",
    "      })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After autocoding for sentiment, the dataframe now has extra columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>review</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>I loved this doctor!</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.994966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>This doctor was absolutely terrible.</td>\n",
       "      <td>0.981789</td>\n",
       "      <td>0.018211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender                                review  negative  positive\n",
       "0  female                  I loved this doctor!  0.005034  0.994966\n",
       "1    male  This doctor was absolutely terrible.  0.981789  0.018211"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = ac.code_sentiment(df['review'].values, df)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert result_df[result_df['gender']=='female']['negative'].values[0] < 0.1\n",
    "assert result_df[result_df['gender']=='female']['positive'].values[0] > 0.9\n",
    "assert result_df[result_df['gender']=='male']['negative'].values[0] > 0.9\n",
    "assert result_df[result_df['gender']=='male']['positive'].values[0] < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the dataframe looks like before autocoding for custom, user-specified topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over_18</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>What is your favorite sitcom of all time?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>I cannot wait to vote!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  over_18                                   comments\n",
       "0     yes  What is your favorite sitcom of all time?\n",
       "1      no                     I cannot wait to vote!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = [\"What is your favorite sitcom of all time?\", 'I cannot wait to vote!']\n",
    "df = pd.DataFrame({\n",
    "    'over_18': ['yes', 'no'],\n",
    "     'comments' : comments,\n",
    "      })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After autocoding, the dataframe has a new column for each custom topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over_18</th>\n",
       "      <th>comments</th>\n",
       "      <th>television</th>\n",
       "      <th>film</th>\n",
       "      <th>politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>What is your favorite sitcom of all time?</td>\n",
       "      <td>0.981327</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>I cannot wait to vote!</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.936988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  over_18                                   comments  television      film  \\\n",
       "0     yes  What is your favorite sitcom of all time?    0.981327  0.012260   \n",
       "1      no                     I cannot wait to vote!    0.000518  0.004943   \n",
       "\n",
       "   politics  \n",
       "0  0.000157  \n",
       "1  0.936988  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = ac.code_custom_topics(df['comments'].values, df, labels=['television', 'film', 'politics'])\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert result_df[result_df['over_18']=='yes']['television'].values[0] > 0.9\n",
    "assert result_df[result_df['over_18']=='yes']['film'].values[0] < 0.1\n",
    "assert result_df[result_df['over_18']=='yes']['politics'].values[0] < 0.1\n",
    "assert result_df[result_df['over_18']=='no']['television'].values[0] < 0.1\n",
    "assert result_df[result_df['over_18']=='no']['film'].values[0] < 0.1\n",
    "assert result_df[result_df['over_18']=='no']['politics'].values[0] > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_causalinference.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
