{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: R-Learner\n",
    "output-file: meta.rlearner.html\n",
    "title: R-Learner\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp meta.rlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# REFERENCE: https://github.com/uber/causalml\n",
    "\n",
    "# Copyright 2019 Uber Technology, Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import cross_val_predict, KFold, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from causalnlp.meta.base import BaseLearner\n",
    "from causalnlp.meta.utils import (check_treatment_vector,\n",
    "    get_xgboost_objective_metric, convert_pd_to_np)\n",
    "from causalnlp.meta.explainer import Explainer\n",
    "from causalnlp.meta.propensity import compute_propensity_score, ElasticNetPropensityModel\n",
    "\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "class BaseRLearner(BaseLearner):\n",
    "    \"\"\"A parent class for R-learner classes.\n",
    "\n",
    "    An R-learner estimates treatment effects with two machine learning models and the propensity score.\n",
    "\n",
    "    Details of R-learner are available at Nie and Wager (2019) (https://arxiv.org/abs/1712.04912).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learner=None,\n",
    "                 outcome_learner=None,\n",
    "                 effect_learner=None,\n",
    "                 propensity_learner=ElasticNetPropensityModel(),\n",
    "                 ate_alpha=.05,\n",
    "                 control_name=0,\n",
    "                 n_fold=5,\n",
    "                 random_state=None):\n",
    "        \"\"\"Initialize an R-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            effect_learner (optional): a model to estimate treatment effects. It needs to take `sample_weight` as an\n",
    "                input argument for `fit()`\n",
    "            propensity_learner (optional): a model to estimate propensity scores. `ElasticNetPropensityModel()` will\n",
    "                be used by default.\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "            n_fold (int, optional): the number of cross validation folds for outcome_learner\n",
    "            random_state (int or RandomState, optional): a seed (int) or random number generator (RandomState)\n",
    "        \"\"\"\n",
    "        assert (learner is not None) or ((outcome_learner is not None) and (effect_learner is not None))\n",
    "        assert propensity_learner is not None\n",
    "\n",
    "        self.model_mu = outcome_learner if outcome_learner else deepcopy(learner)\n",
    "        self.model_tau = effect_learner if outcome_learner else deepcopy(learner)\n",
    "        self.model_p = propensity_learner\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.cv = KFold(n_splits=n_fold, shuffle=True, random_state=random_state)\n",
    "\n",
    "        self.propensity = None\n",
    "        self.propensity_model = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}\\n'\n",
    "                f'\\toutcome_learner={self.model_mu.__repr__()}\\n'\n",
    "                f'\\teffect_learner={self.model_tau.__repr__()}\\n'\n",
    "                f'\\tpropensity_learner={self.model_p.__repr__()}')\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None, verbose=True):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        if p is None:\n",
    "            self._set_propensity_models(X=X, treatment=treatment, y=y)\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models_tau = {group: deepcopy(self.model_tau) for group in self.t_groups}\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        if verbose:\n",
    "            logger.info('generating out-of-fold CV outcome estimates')\n",
    "        yhat = cross_val_predict(self.model_mu, X, y, cv=self.cv, n_jobs=-1)\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            X_filt = X[mask]\n",
    "            y_filt = y[mask]\n",
    "            yhat_filt = yhat[mask]\n",
    "            p_filt = p[group][mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "\n",
    "            if verbose:\n",
    "                logger.info('training the treatment effect model for {} with R-loss'.format(group))\n",
    "            self.models_tau[group].fit(X_filt, (y_filt - yhat_filt) / (w - p_filt),\n",
    "                                       sample_weight=(w - p_filt) ** 2)\n",
    "\n",
    "            self.vars_c[group] = (y_filt[w == 0] - yhat_filt[w == 0]).var()\n",
    "            self.vars_t[group] = (y_filt[w == 1] - yhat_filt[w == 1]).var()\n",
    "\n",
    "    def predict(self, X, p=None):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X = convert_pd_to_np(X)\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            dhat = self.models_tau[group].predict(X)\n",
    "            te[:, i] = dhat\n",
    "\n",
    "        return te\n",
    "\n",
    "    def fit_predict(self, X, treatment, y, p=None, return_ci=False,\n",
    "                    n_bootstraps=1000, bootstrap_size=10000, verbose=True):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            verbose (bool): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment].\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y, p, verbose=verbose)\n",
    "        te = self.predict(X)\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            models_tau_global = deepcopy(self.models_tau)\n",
    "            te_bootstraps = np.zeros(shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals')\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                if p is None:\n",
    "                    p = self.propensity\n",
    "                else:\n",
    "                    p = self._format_p(p, self.t_groups)\n",
    "                te_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha / 2) * 100, axis=2)\n",
    "            te_upper = np.percentile(te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.models_tau = deepcopy(models_tau_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(self, X, treatment, y, p=None, bootstrap_ci=False, n_bootstraps=1000, bootstrap_size=10000):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            bootstrap_ci (bool): whether run bootstrap for confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        te = self.fit_predict(X, treatment, y, p, return_ci=False)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            w = (treatment == group).astype(int)\n",
    "            prob_treatment = float(sum(w)) / X.shape[0]\n",
    "            _ate = te[:, i].mean()\n",
    "\n",
    "            se = (np.sqrt((self.vars_t[group] / prob_treatment)\n",
    "                          + (self.vars_c[group] / (1 - prob_treatment))\n",
    "                          + te[:, i].var())\n",
    "                  / X.shape[0])\n",
    "\n",
    "            _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "            _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "            ate[i] = _ate\n",
    "            ate_lb[i] = _ate_lb\n",
    "            ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            models_tau_global = deepcopy(self.models_tau)\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals for ATE')\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                if p is None:\n",
    "                    p = self.propensity\n",
    "                else:\n",
    "                    p = self._format_p(p, self.t_groups)\n",
    "                cate_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = cate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1)\n",
    "            ate_upper = np.percentile(ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.models_tau = deepcopy(models_tau_global)\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "\n",
    "class BaseRRegressor(BaseRLearner):\n",
    "    \"\"\"\n",
    "    A parent class for R-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learner=None,\n",
    "                 outcome_learner=None,\n",
    "                 effect_learner=None,\n",
    "                 propensity_learner=ElasticNetPropensityModel(),\n",
    "                 ate_alpha=.05,\n",
    "                 control_name=0,\n",
    "                 n_fold=5,\n",
    "                 random_state=None):\n",
    "        \"\"\"Initialize an R-learner regressor.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            effect_learner (optional): a model to estimate treatment effects. It needs to take `sample_weight` as an\n",
    "                input argument for `fit()`\n",
    "            propensity_learner (optional): a model to estimate propensity scores. `ElasticNetPropensityModel()` will\n",
    "                be used by default.\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "            n_fold (int, optional): the number of cross validation folds for outcome_learner\n",
    "            random_state (int or RandomState, optional): a seed (int) or random number generator (RandomState)\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            outcome_learner=outcome_learner,\n",
    "            effect_learner=effect_learner,\n",
    "            propensity_learner=propensity_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "            n_fold=n_fold,\n",
    "            random_state=random_state)\n",
    "\n",
    "\n",
    "class BaseRClassifier(BaseRLearner):\n",
    "    \"\"\"\n",
    "    A parent class for R-learner classifier classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 outcome_learner=None,\n",
    "                 effect_learner=None,\n",
    "                 propensity_learner=ElasticNetPropensityModel(),\n",
    "                 ate_alpha=.05,\n",
    "                 control_name=0,\n",
    "                 n_fold=5,\n",
    "                 random_state=None):\n",
    "        \"\"\"Initialize an R-learner classifier.\n",
    "\n",
    "        Args:\n",
    "            outcome_learner: a model to estimate outcomes. Should be a classifier.\n",
    "            effect_learner: a model to estimate treatment effects. It needs to take `sample_weight` as an\n",
    "                input argument for `fit()`. Should be a regressor.\n",
    "            propensity_learner (optional): a model to estimate propensity scores. `ElasticNetPropensityModel()` will\n",
    "                be used by default.\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "            n_fold (int, optional): the number of cross validation folds for outcome_learner\n",
    "            random_state (int or RandomState, optional): a seed (int) or random number generator (RandomState)\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=None,\n",
    "            outcome_learner=outcome_learner,\n",
    "            effect_learner=effect_learner,\n",
    "            propensity_learner=propensity_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "            n_fold=n_fold,\n",
    "            random_state=random_state)\n",
    "\n",
    "        if (outcome_learner is None) and (effect_learner is None):\n",
    "            raise ValueError(\"Either the outcome learner or the effect learner must be specified.\")\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None, verbose=True):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        if p is None:\n",
    "            self._set_propensity_models(X=X, treatment=treatment, y=y)\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models_tau = {group: deepcopy(self.model_tau) for group in self.t_groups}\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        if verbose:\n",
    "            logger.info('generating out-of-fold CV outcome estimates')\n",
    "        yhat = cross_val_predict(self.model_mu, X, y, cv=self.cv, method='predict_proba', n_jobs=-1)[:, 1]\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            X_filt = X[mask]\n",
    "            y_filt = y[mask]\n",
    "            yhat_filt = yhat[mask]\n",
    "            p_filt = p[group][mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "\n",
    "            if verbose:\n",
    "                logger.info('training the treatment effect model for {} with R-loss'.format(group))\n",
    "            self.models_tau[group].fit(X_filt, (y_filt - yhat_filt) / (w - p_filt),\n",
    "                                       sample_weight=(w - p_filt) ** 2)\n",
    "\n",
    "            self.vars_c[group] = (y_filt[w == 0] - yhat_filt[w == 0]).var()\n",
    "            self.vars_t[group] = (y_filt[w == 1] - yhat_filt[w == 1]).var()\n",
    "\n",
    "    def predict(self, X, p=None):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            dhat = self.models_tau[group].predict(X)\n",
    "            te[:, i] = dhat\n",
    "\n",
    "        return te\n",
    "\n",
    "\n",
    "class XGBRRegressor(BaseRRegressor):\n",
    "    def __init__(self,\n",
    "                 early_stopping=True,\n",
    "                 test_size=0.3,\n",
    "                 early_stopping_rounds=30,\n",
    "                 effect_learner_objective='rank:pairwise',\n",
    "                 effect_learner_n_estimators=500,\n",
    "                 random_state=42,\n",
    "                 *args,\n",
    "                 **kwargs):\n",
    "        \"\"\"Initialize an R-learner regressor with XGBoost model using pairwise ranking objective.\n",
    "\n",
    "        Args:\n",
    "            early_stopping: whether or not to use early stopping when fitting effect learner\n",
    "            test_size (float, optional): the proportion of the dataset to use as validation set when early stopping is\n",
    "                                         enabled\n",
    "            early_stopping_rounds (int, optional): validation metric needs to improve at least once in every\n",
    "                                                   early_stopping_rounds round(s) to continue training\n",
    "            effect_learner_objective (str, optional): the learning objective for the effect learner\n",
    "                                                      (default = 'rank:pairwise')\n",
    "            effect_learner_n_estimators (int, optional): number of trees to fit for the effect learner (default = 500)\n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(random_state, int), 'random_state should be int.'\n",
    "\n",
    "        objective, metric = get_xgboost_objective_metric(effect_learner_objective)\n",
    "        self.effect_learner_objective = objective\n",
    "        self.effect_learner_eval_metric = metric\n",
    "        self.effect_learner_n_estimators = effect_learner_n_estimators\n",
    "        self.early_stopping = early_stopping\n",
    "        if self.early_stopping:\n",
    "            self.test_size = test_size\n",
    "            self.early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        super().__init__(\n",
    "            outcome_learner=XGBRegressor(random_state=random_state, *args, **kwargs),\n",
    "            effect_learner=XGBRegressor(objective=self.effect_learner_objective,\n",
    "                                        n_estimators=self.effect_learner_n_estimators,\n",
    "                                        random_state=random_state,\n",
    "                                        *args,\n",
    "                                        **kwargs)\n",
    "        )\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None, verbose=True):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        if p is None:\n",
    "            self._set_propensity_models(X=X, treatment=treatment, y=y)\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models_tau = {group: deepcopy(self.model_tau) for group in self.t_groups}\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        if verbose:\n",
    "            logger.info('generating out-of-fold CV outcome estimates')\n",
    "        yhat = cross_val_predict(self.model_mu, X, y, cv=self.cv, n_jobs=-1)\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            treatment_mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[treatment_mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "\n",
    "            X_filt = X[treatment_mask]\n",
    "            y_filt = y[treatment_mask]\n",
    "            yhat_filt = yhat[treatment_mask]\n",
    "            p_filt = p[group][treatment_mask]\n",
    "\n",
    "            if verbose:\n",
    "                logger.info('training the treatment effect model for {} with R-loss'.format(group))\n",
    "\n",
    "            if self.early_stopping:\n",
    "                X_train_filt, X_test_filt, y_train_filt, y_test_filt, yhat_train_filt, yhat_test_filt, \\\n",
    "                    w_train, w_test, p_train_filt, p_test_filt = train_test_split(\n",
    "                        X_filt, y_filt, yhat_filt, w, p_filt,\n",
    "                        test_size=self.test_size, random_state=self.random_state\n",
    "                    )\n",
    "\n",
    "                self.models_tau[group].fit(X=X_train_filt,\n",
    "                                           y=(y_train_filt - yhat_train_filt) / (w_train - p_train_filt),\n",
    "                                           sample_weight=(w_train - p_train_filt) ** 2,\n",
    "                                           eval_set=[(X_test_filt,\n",
    "                                                      (y_test_filt - yhat_test_filt) / (w_test - p_test_filt))],\n",
    "                                           sample_weight_eval_set=[(w_test - p_test_filt) ** 2],\n",
    "                                           eval_metric=self.effect_learner_eval_metric,\n",
    "                                           early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                           verbose=verbose)\n",
    "\n",
    "            else:\n",
    "                self.models_tau[group].fit(X_filt, (y_filt - yhat_filt) / (w - p_filt),\n",
    "                                           sample_weight=(w - p_filt) ** 2,\n",
    "                                           eval_metric=self.effect_learner_eval_metric)\n",
    "\n",
    "            self.vars_c[group] = (y_filt[w == 0] - yhat_filt[w == 0]).var()\n",
    "            self.vars_t[group] = (y_filt[w == 1] - yhat_filt[w == 1]).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_causalinference.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted 02_analyzers.ipynb.\n",
      "Converted 03_key_driver_analysis.ipynb.\n",
      "Converted 04_preprocessing.ipynb.\n",
      "Converted 05a_meta.base.ipynb.\n",
      "Converted 05b_meta.explainer.ipynb.\n",
      "Converted 05c_meta.utils.ipynb.\n",
      "Converted 05d_meta.propensity.ipynb.\n",
      "Converted 05e_meta.tlearner.ipynb.\n",
      "Converted 05f_meta.slearner.ipynb.\n",
      "Converted 05g_meta.xlearner.ipynb.\n",
      "Converted 05h_meta.rlearner.ipynb.\n",
      "Converted 99_examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
