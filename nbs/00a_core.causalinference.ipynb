{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.causalinference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference\n",
    "\n",
    "> Causal Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import time\n",
    "\n",
    "from causalnlp.meta.tlearner import BaseTClassifier, BaseTRegressor\n",
    "from causalnlp.meta.slearner import BaseSClassifier, BaseSRegressor\n",
    "from causalnlp.meta.xlearner import BaseXClassifier, BaseXRegressor\n",
    "from causalnlp.meta.rlearner import BaseRClassifier, BaseRRegressor\n",
    "from causalnlp.meta.propensity import ElasticNetPropensityModel\n",
    "from causalnlp.meta.utils import NearestNeighborMatch, create_table_one\n",
    "from scipy import stats\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import numpy as np\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from causalnlp.preprocessing import DataframePreprocessor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "metalearner_cls_dict = {'t-learner' : BaseTClassifier,\n",
    "                        'x-learner' : BaseXClassifier,\n",
    "                        'r-learner' : BaseRClassifier,\n",
    "                         's-learner': BaseSClassifier}\n",
    "metalearner_reg_dict = {'t-learner' : BaseTRegressor,\n",
    "                        'x-learner' : BaseXRegressor,\n",
    "                        'r-learner' : BaseRRegressor,\n",
    "                        's-learner' : BaseSRegressor}\n",
    "\n",
    "class CausalInferenceModel:\n",
    "    \"\"\"Infers causality from the data contained in `df` using a metalearner.\n",
    "    \n",
    "    \n",
    "    Usage:\n",
    "\n",
    "    ```python\n",
    "    >>> cm = CausalInferenceModel(df, \n",
    "                                  treatment_col='Is_Male?', \n",
    "                                  outcome_col='Post_Shared?', text_col='Post_Text',\n",
    "                                  ignore_cols=['id', 'email'])\n",
    "        cm.fit()\n",
    "    ```\n",
    "    \n",
    "    **Parameters:**\n",
    "    \n",
    "    * **df** : pandas.DataFrame containing dataset\n",
    "    * **method** : metalearner model to use. One of {'t-learner', 's-learner', 'x-learner', 'r-learner'} (Default: 't-learner')\n",
    "    * **metalearner_type** : Alias of `method` for backwards compatibility. Overrides `method` if not None.\n",
    "    * **treatment_col** : treatment variable; column should contain binary values: 1 for treated, 0 for untreated.\n",
    "    * **outcome_col** : outcome variable; column should contain the categorical or numeric outcome values\n",
    "    * **text_col** : (optional) text column containing the strings (e.g., articles, reviews, emails). \n",
    "    * **ignore_cols** : columns to ignore in the analysis\n",
    "    * **include_cols** : columns to include as covariates (e.g., possible confounders)\n",
    "    * **treatment_effect_col** : name of column to hold causal effect estimations.  Does not need to exist.  Created by CausalNLP.\n",
    "    * **learner** : an instance of a custom learner.  If None, Log/Lin Regression is used for S-Learner \n",
    "                    and a default LightGBM model will be used for all other metalearner types.\n",
    "        # Example\n",
    "         learner = LGBMClassifier(num_leaves=1000)\n",
    "    * **effect_learner**: used for x-learner/r-learner and must be regression model\n",
    "    * **min_df** : min_df parameter used for text processing using sklearn\n",
    "    * **max_df** : max_df parameter used for text procesing using sklearn\n",
    "    * **ngram_range**: ngrams used for text vectorization. default: (1,1)\n",
    "    * **stop_words** : stop words used for text processing (from sklearn)\n",
    "    * **verbose** : If 1, print informational messages.  If 0, suppress.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 method='t-learner',\n",
    "                 metalearner_type=None, # alias for method\n",
    "                 treatment_col='treatment', \n",
    "                 outcome_col='outcome', \n",
    "                 text_col=None,\n",
    "                 ignore_cols=[],\n",
    "                 include_cols=[],\n",
    "                 treatment_effect_col = 'treatment_effect',\n",
    "                 learner = None,\n",
    "                 effect_learner=None,\n",
    "                 min_df=0.05,\n",
    "                 max_df=0.5,\n",
    "                 ngram_range=(1,1),\n",
    "                 stop_words='english',\n",
    "                 verbose=1):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "        \"\"\"\n",
    "        # for backwards compatibility\n",
    "        if metalearner_type is not None: \n",
    "            if method != 't-learner': \n",
    "                warnings.warn(f'metalearner_type and method are mutually exclusive. '+\\\n",
    "                              f'Used {metalearner_type} as method.')\n",
    "            method = metalearner_type\n",
    "\n",
    "        metalearner_list = list(metalearner_cls_dict.keys())\n",
    "        if method not in metalearner_list:\n",
    "            raise ValueError('method is required and must be one of: %s' % (metalearner_list))\n",
    "        self.te = treatment_effect_col # created\n",
    "        self.method = method\n",
    "        self.v = verbose\n",
    "        self.df = df.copy()\n",
    "        self.ps = None # computed by _create_metalearner, if necessary\n",
    "           \n",
    "        \n",
    "        # these are auto-populated by preprocess method\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.treatment = None\n",
    "        \n",
    "        # preprocess\n",
    "        self.pp = DataframePreprocessor(treatment_col = treatment_col,\n",
    "                                       outcome_col = outcome_col,\n",
    "                                       text_col=text_col,\n",
    "                                       include_cols=include_cols,\n",
    "                                       ignore_cols=ignore_cols,\n",
    "                                       verbose=self.v)\n",
    "        self.df, self.x, self.y, self.treatment = self.pp.preprocess(self.df,\n",
    "                                                                     training=True,\n",
    "                                                                     min_df=min_df,\n",
    "                                                                     max_df=max_df,\n",
    "                                                                     ngram_range=ngram_range,\n",
    "                                                                     stop_words=stop_words)\n",
    "\n",
    "        # setup model\n",
    "        self.model = self._create_metalearner(method=self.method,\n",
    "                                             supplied_learner=learner,\n",
    "                                             supplied_effect_learner=effect_learner)\n",
    "\n",
    "           \n",
    "\n",
    "    def _create_metalearner(self, method='t-learner', \n",
    "                            supplied_learner=None, supplied_effect_learner=None):\n",
    "        ## use LRSRegressor for s-learner regression as default instead of tree-based model\n",
    "        #if method =='s-learner' and supplied_learner is None: return LRSRegressor()\n",
    "\n",
    "        # set learner\n",
    "        default_learner = None\n",
    "        if self.pp.is_classification:\n",
    "            default_learner = LogisticRegression(max_iter=10000) if method=='s-learner' else LGBMClassifier()\n",
    "        else:\n",
    "            default_learner =  LinearRegression() if method=='s-learner' else LGBMRegressor()\n",
    "        default_effect_learner = LGBMRegressor()\n",
    "        learner = default_learner if supplied_learner is None else supplied_learner\n",
    "        effect_learner = default_effect_learner if supplied_effect_learner is None else\\\n",
    "                         supplied_effect_learner\n",
    "        \n",
    "        # set metalearner\n",
    "        metalearner_class = metalearner_cls_dict[method] if self.pp.is_classification \\\n",
    "                                                                   else metalearner_reg_dict[method]\n",
    "        if method in ['t-learner', 's-learner']:\n",
    "            model = metalearner_class(learner=learner,control_name=0)\n",
    "        elif method in ['x-learner']:\n",
    "            model = metalearner_class(\n",
    "                                      control_outcome_learner=deepcopy(learner),\n",
    "                                      treatment_outcome_learner=deepcopy(learner),\n",
    "                                      control_effect_learner=deepcopy(effect_learner),\n",
    "                                      treatment_effect_learner=deepcopy(effect_learner),\n",
    "                                      control_name=0) \n",
    "        else:\n",
    "            model = metalearner_class(outcome_learner=deepcopy(learner),\n",
    "                                      effect_learner=deepcopy(effect_learner),\n",
    "                                      control_name=0) \n",
    "\n",
    "        return model\n",
    "        \n",
    "           \n",
    "    def fit(self, p=None):\n",
    "        \"\"\"\n",
    "        Fits a causal inference model and estimates outcome\n",
    "        with and without treatment for each observation.\n",
    "        For X-Learner and R-Learner, propensity scores will be computed\n",
    "        using default propensity model unless `p` is not None.\n",
    "        Parameter `p` is not used for other methods.\n",
    "        \"\"\"\n",
    "        print(\"start fitting causal inference model\")\n",
    "        start_time = time.time()\n",
    "        self.model.fit(self.x.values, self.treatment.values, self.y.values, p=p)\n",
    "        preds = self._predict(self.x)\n",
    "        self.df[self.te] = preds\n",
    "        print(\"time to fit causal inference model: \",-start_time + time.time(),\" sec\")\n",
    "        return self\n",
    "        \n",
    "    def predict(self, df, p=None):\n",
    "        \"\"\"\n",
    "        Estimates the treatment effect for each observation in `df`.\n",
    "        The DataFrame represented by `df` should be the same format\n",
    "        as the one supplied to `CausalInferenceModel.__init__`.\n",
    "        For X-Learner and R-Learner, propensity scores will be computed\n",
    "        using default propensity model unless `p` is not None.\n",
    "        Parameter `p` is not used for other methods.\n",
    "        \"\"\"            \n",
    "        _, x, _, _ = self.pp.preprocess(df, training=False)\n",
    "        return self._predict(x, p=p)\n",
    "            \n",
    "\n",
    "    def _predict(self, x, p=None):\n",
    "        \"\"\"\n",
    "        Estimates the treatment effect for each observation in `x`,\n",
    "        where `x` is an **un-preprocessed** DataFrame of Numpy array.\n",
    "        \"\"\"\n",
    "        if isinstance(x, pd.DataFrame):\n",
    "            return self.model.predict(x.values, p=p)\n",
    "        else:\n",
    "            return self.model.predict(x, p=p)\n",
    "    \n",
    "    def estimate_ate(self, bool_mask=None):\n",
    "        \"\"\"\n",
    "        Estimates the treatment effect for each observation in\n",
    "        `self.df`.\n",
    "        \"\"\"\n",
    "        df = self.df if bool_mask is None else self.df[bool_mask]\n",
    "        a = df[self.te].values\n",
    "        mean = np.mean(a)\n",
    "        return {'ate' : mean}\n",
    "        \n",
    "\n",
    "    def interpret(self, plot=False, method='feature_importance'):\n",
    "        \"\"\"\n",
    "        Returns feature importances of treatment effect model.\n",
    "        The method parameter must be one of {'feature_importance', 'shap_values'}\n",
    "        \"\"\"\n",
    "        tau = self.df[self.te]\n",
    "        feature_names = self.x.columns.values\n",
    "        if plot:\n",
    "            if method=='feature_importance':\n",
    "                fn = self.model.plot_importance\n",
    "            elif method == 'shap_values':\n",
    "                fn = self.model.plot_shap_values\n",
    "            else:\n",
    "                raise ValueError('Unknown method: %s' % method)\n",
    "        else:\n",
    "            if method=='feature_importance':\n",
    "                fn = self.model.get_importance\n",
    "            elif method == 'shap_values':\n",
    "                fn = self.model.get_shap_values\n",
    "            else:\n",
    "                raise ValueError('Unknown method: %s' % method)\n",
    "        return fn(X=self.x, tau=tau, features = feature_names)\n",
    "        \n",
    "\n",
    "    def compute_propensity_scores(self, x_pred=None):\n",
    "        \"\"\"\n",
    "        Computes and returns propensity scores for `CausalInferenceModel.treatment`\n",
    "        in addition to the Propensity model.\n",
    "        \"\"\"\n",
    "        from causalnlp.meta import propensity\n",
    "        return propensity.compute_propensity_score(self.x, self.treatment, X_pred=x_pred)\n",
    "        \n",
    "        \n",
    "    def _balance(self, caliper = None, n_fold=3, overwrite=False):\n",
    "        \"\"\"\n",
    "        Balances dataset to minimize bias.  Currently uses propensity score matching.\n",
    "        Experimental and untested.\n",
    "        \"\"\"\n",
    "        if caliper is None:\n",
    "            warnings.warn('Since caliper is None, caliper is being set to 0.001.')\n",
    "            caliper = 0.001\n",
    "\n",
    "        print('-------Start balancing procedure----------')\n",
    "        start_time = time.time()\n",
    "        #Join x, y and treatment vectors\n",
    "        df_match = self.x.merge(self.treatment,left_index=True, right_index=True)\n",
    "        df_match = df_match.merge(self.y, left_index=True, right_index=True)\n",
    "\n",
    "        #ps - propensity score\n",
    "        df_match['ps'] = self.compute_propensity_scores(n_fold=n_fold)\n",
    "\n",
    "        #Matching model object\n",
    "        psm = NearestNeighborMatch(replace=False,\n",
    "                       ratio=1,\n",
    "                       random_state=423,\n",
    "                       caliper=caliper)\n",
    "\n",
    "        ps_cols = list(self.pp.feature_names_one_hot)\n",
    "        ps_cols.append('ps')\n",
    "\n",
    "        #Apply matching model\n",
    "        #If error, then sample is unbiased and we don't do anything\n",
    "        self.flg_bias = True\n",
    "        self.df_matched = psm.match(data=df_match, treatment_col=self.pp.treatment_col,score_cols=['ps'])\n",
    "        self.x_matched = self.df_matched[self.x.columns]\n",
    "        self.y_matched = self.df_matched[self.pp.outcome_col]\n",
    "        self.treatment_matched = self.df_matched[self.pp.treatment_col]\n",
    "        print('-------------------MATCHING RESULTS----------------')\n",
    "        print('-----BEFORE MATCHING-------')\n",
    "        print(create_table_one(data=df_match,\n",
    "                                treatment_col=self.pp.treatment_col,\n",
    "                                features=list(self.pp.feature_names_one_hot)))\n",
    "        print('-----AFTER MATCHING-------')\n",
    "        print(create_table_one(data=self.df_matched,\n",
    "                                treatment_col=self.pp.treatment_col,\n",
    "                                features=list(self.pp.feature_names_one_hot)))\n",
    "        if overwrite:\n",
    "            self.x = self.x_matched\n",
    "            self.y = self.y_matched\n",
    "            self.treatment = self.treatment_matched\n",
    "            self.df = self.df_matched\n",
    "            print('\\nBalancing prunes the dataset.  ' +\\\n",
    "                      'To revert, re-invoke CausalInferencModel ' +\\\n",
    "                       'with original dataset.')\n",
    "        else:\n",
    "            print('\\nBalanced data is available as variables: x_matched, y_matched, treatment_matched, df_matched')\n",
    "        return       \n",
    "    \n",
    "    def _predict_shap(self, x):\n",
    "        return self._predict(x)\n",
    "    \n",
    "    def explain(self, df, row_index=None, row_num=0, background_size=50, nsamples=500):\n",
    "        \"\"\"\n",
    "        Explain the treatment effect estimate of a single observation using SHAP.\n",
    "        \n",
    "        \n",
    "        **Parameters:**\n",
    "          - **df** (pd.DataFrame): a pd.DataFrame of test data is same format as original training data DataFrame\n",
    "          - **row_num** (int): raw row number in DataFrame to explain (default:0, the first row)\n",
    "          - **background_size** (int): size of background data (SHAP parameter)\n",
    "          - **nsamples** (int): number of samples (SHAP parameter)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import shap\n",
    "        except ImportError:\n",
    "            msg = 'The explain method requires shap library. Please install with: pip install shap. '+\\\n",
    "                    'Conda users should use this command instead: conda install -c conda-forge shap'\n",
    "            raise ImportError(msg)\n",
    "\n",
    "        f = self._predict_shap\n",
    "\n",
    "        # preprocess dataframe\n",
    "        _, df_display, _, _ = self.pp.preprocess(df.copy(), training=False)\n",
    "\n",
    "\n",
    "        # select row\n",
    "        df_display_row = df_display.iloc[[row_num]]\n",
    "        r_key = 'row_num'\n",
    "        r_val = row_num \n",
    "\n",
    "        # shap\n",
    "        explainer = shap.KernelExplainer(f, self.x.iloc[:background_size,:])\n",
    "        shap_values = explainer.shap_values(df_display_row, nsamples=nsamples, l1_reg='aic')\n",
    "        expected_value = explainer.expected_value\n",
    "\n",
    "        if not np.issubdtype(type(explainer.expected_value), np.floating):\n",
    "            expected_value = explainer.expected_value[0]\n",
    "        if type(shap_values) == list:\n",
    "            shap_values = shap_values[0]\n",
    "        plt.show(shap.force_plot(expected_value, shap_values, df_display_row, matplotlib=True))\n",
    "\n",
    "        \n",
    "    def get_required_columns(self):\n",
    "        \"\"\"\n",
    "        Returns required columns that must exist in any DataFrame supplied to `CausalInferenceModel.predict`.\n",
    "        \"\"\"\n",
    "        treatment_col = self.pp.treatment_col\n",
    "        other_cols = self.pp.feature_names\n",
    "        result = [treatment_col] + other_cols\n",
    "        if self.pp.text_col: result.append(self.pp.text_col)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def tune_and_use_default_learner(self, split_pct=0.2, random_state=314, scoring=None):\n",
    "        \"\"\"\n",
    "        Tunes the hyperparameters of a default LightGBM model, replaces `CausalInferenceModel.learner`,\n",
    "        and returns best parameters.\n",
    "        Should be invoked **prior** to running `CausalInferencemodel.fit`.\n",
    "        If `scoring` is None, then 'roc_auc' is used for classification and 'negative_mean_squared_error'\n",
    "        is used for regresssion.\n",
    "        \"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.x.values, self.y.values, \n",
    "                                                            test_size=split_pct, \n",
    "                                                            random_state=random_state)\n",
    "        \n",
    "        fit_params={\"early_stopping_rounds\":30, \n",
    "                    \"eval_metric\" : 'auc' if self.pp.is_classification else 'rmse', \n",
    "                    \"eval_set\" : [(X_test,y_test)],\n",
    "                    'eval_names': ['valid'],\n",
    "                    'verbose': 100,\n",
    "                    'categorical_feature': 'auto'}       \n",
    "\n",
    "                \n",
    "        from scipy.stats import randint as sp_randint\n",
    "        from scipy.stats import uniform as sp_uniform\n",
    "        param_test ={'num_leaves': sp_randint(6, 750), \n",
    "                     'min_child_samples': sp_randint(20, 500), \n",
    "                     'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "                     'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "                     'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "                     'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "                     'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "        n_HP_points_to_test = 100\n",
    "        if self.pp.is_classification:\n",
    "            learner_type = LGBMClassifier\n",
    "            scoring = 'roc_auc' if scoring is None else scoring\n",
    "        else:\n",
    "            learner_type =  LGBMRegressor\n",
    "            scoring = 'neg_mean_squared_error' if scoring is None else scoring\n",
    "        clf = learner_type(max_depth=-1, random_state=random_state, silent=True, \n",
    "                         metric='None', n_jobs=4, n_estimators=5000)\n",
    "        from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "        gs = RandomizedSearchCV(\n",
    "                estimator=clf, param_distributions=param_test, \n",
    "                n_iter=n_HP_points_to_test,\n",
    "                scoring=scoring,\n",
    "                cv=3,\n",
    "                refit=True,\n",
    "                random_state=random_state,\n",
    "                verbose=True)\n",
    "\n",
    "        gs.fit(X_train, y_train, **fit_params)\n",
    "        print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))\n",
    "        best_params = gs.best_params_\n",
    "        self.learner = learner_type(**best_params)\n",
    "        return best_params\n",
    "    \n",
    "    def evaluate_robustness(self, sample_size=0.8):\n",
    "        \"\"\"\n",
    "        Evaluates robustness on four sensitivity measures (see CausalML package for details on these methods):\n",
    "        - **Placebo Treatment**: ATE should become zero.\n",
    "        - **Random Cause**: ATE should not change.\n",
    "        - **Random Replacement**: ATE should not change.\n",
    "        - **Subset Data**: ATE should not change.\n",
    "        \"\"\"\n",
    "        from causalnlp.meta.sensitivity import Sensitivity\n",
    "        data_df = self.x.copy()\n",
    "        t_col = 'CausalNLP_t'\n",
    "        y_col = 'CausalNLP_y'\n",
    "        data_df[t_col] = self.treatment\n",
    "        data_df[y_col] = self.y\n",
    "        sens_x = Sensitivity(df=data_df, \n",
    "                             inference_features=self.x.columns.values,\n",
    "                             p_col=None,\n",
    "                             treatment_col=t_col, outcome_col=y_col, \n",
    "                             learner=self.model)\n",
    "        df = sens_x.sensitivity_analysis(methods=['Placebo Treatment',\n",
    "                                                  'Random Cause',\n",
    "                                                  'Subset Data',\n",
    "                                                  'Random Replace',\n",
    "                                                    ],sample_size=sample_size)\n",
    "        df['Distance from Desired (should be near 0)'] = np.where(df['Method']=='Placebo Treatment', \n",
    "                                                             df['New ATE']-0.0, \n",
    "                                                             df['New ATE']-df['ATE'])\n",
    "        \n",
    "        #df['Method'] = np.where(df['Method']=='Random Cause', 'Random Add', df['Method'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.fit\" class=\"doc_header\"><code>CausalInferenceModel.fit</code><a href=\"__main__.py#L167\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.fit</code>(**`p`**=*`None`*)\n",
       "\n",
       "Fits a causal inference model and estimates outcome\n",
       "with and without treatment for each observation.\n",
       "For X-Learner and R-Learner, propensity scores will be computed\n",
       "using default propensity model unless `p` is not None.\n",
       "Parameter `p` is not used for other methods."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.tune_and_use_default_learner\" class=\"doc_header\"><code>CausalInferenceModel.tune_and_use_default_learner</code><a href=\"__main__.py#L360\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.tune_and_use_default_learner</code>(**`split_pct`**=*`0.2`*, **`random_state`**=*`314`*, **`scoring`**=*`None`*)\n",
       "\n",
       "Tunes the hyperparameters of a default LightGBM model, replaces [`CausalInferenceModel.learner`](/causalnlp/core.causalinference.html#CausalInferenceModel.learner),\n",
       "and returns best parameters.\n",
       "Should be invoked **prior** to running `CausalInferencemodel.fit`.\n",
       "If `scoring` is None, then 'roc_auc' is used for classification and 'negative_mean_squared_error'\n",
       "is used for regresssion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.tune_and_use_default_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.predict\" class=\"doc_header\"><code>CausalInferenceModel.predict</code><a href=\"__main__.py#L183\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.predict</code>(**`df`**, **`p`**=*`None`*)\n",
       "\n",
       "Estimates the treatment effect for each observation in `df`.\n",
       "The DataFrame represented by `df` should be the same format\n",
       "as the one supplied to [`CausalInferenceModel.__init__`](/causalnlp/core.causalinference.html#CausalInferenceModel.__init__).\n",
       "For X-Learner and R-Learner, propensity scores will be computed\n",
       "using default propensity model unless `p` is not None.\n",
       "Parameter `p` is not used for other methods."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.get_required_columns\" class=\"doc_header\"><code>CausalInferenceModel.get_required_columns</code><a href=\"__main__.py#L349\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.get_required_columns</code>()\n",
       "\n",
       "Returns required columns that must exist in any DataFrame supplied to [`CausalInferenceModel.predict`](/causalnlp/core.causalinference.html#CausalInferenceModel.predict)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.get_required_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.estimate_ate\" class=\"doc_header\"><code>CausalInferenceModel.estimate_ate</code><a href=\"__main__.py#L206\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.estimate_ate</code>(**`bool_mask`**=*`None`*)\n",
       "\n",
       "Estimates the treatment effect for each observation in\n",
       "`self.df`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.estimate_ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bool_mask` parameter can be used to estimate the conditional average treatment estimate (CATE).\n",
    "For instance, to estimate the average treatment effect for only those individuals over 18 years of age:\n",
    "\n",
    "```python\n",
    "cm.estimate_ate(cm.df['age']>18])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.evaluate_robustness\" class=\"doc_header\"><code>CausalInferenceModel.evaluate_robustness</code><a href=\"__main__.py#L415\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.evaluate_robustness</code>(**`sample_size`**=*`0.8`*)\n",
       "\n",
       "Evaluates robustness on four sensitivity measures (see CausalML package for details on these methods):\n",
       "- **Placebo Treatment**: ATE should become zero.\n",
       "- **Random Cause**: ATE should not change.\n",
       "- **Random Replacement**: ATE should not change.\n",
       "- **Subset Data**: ATE should not change."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.evaluate_robustness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.interpret\" class=\"doc_header\"><code>CausalInferenceModel.interpret</code><a href=\"__main__.py#L217\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.interpret</code>(**`plot`**=*`False`*, **`method`**=*`'feature_importance'`*)\n",
       "\n",
       "Returns feature importances of treatment effect model.\n",
       "The method parameter must be one of {'feature_importance', 'shap_values'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.interpret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"CausalInferenceModel.explain\" class=\"doc_header\"><code>CausalInferenceModel.explain</code><a href=\"__main__.py#L308\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>CausalInferenceModel.explain</code>(**`df`**, **`row_index`**=*`None`*, **`row_num`**=*`0`*, **`background_size`**=*`50`*, **`nsamples`**=*`500`*)\n",
       "\n",
       "Explain the treatment effect estimate of a single observation using SHAP.\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "  - **df** (pd.DataFrame): a pd.DataFrame of test data is same format as original training data DataFrame\n",
       "  - **row_num** (int): raw row number in DataFrame to explain (default:0, the first row)\n",
       "  - **background_size** (int): size of background data (SHAP parameter)\n",
       "  - **nsamples** (int): number of samples (SHAP parameter)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CausalInferenceModel.explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Usage Example: Do social media posts by women get shared more often than those by men?\n",
    "\n",
    "Let's create a simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Male?</th>\n",
       "      <th>Post_Text</th>\n",
       "      <th>Post_Shared?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Is_Male?              Post_Text  Post_Shared?\n",
       "0         0  I really love my job!             0\n",
       "1         0  I really love my job!             0\n",
       "2         0  I really love my job!             0\n",
       "3         0  I really love my job!             0\n",
       "4         0  I really love my job!             0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "data = ((*a, b) for (a, b) in zip(itertools.product([0,1], [0,1], [0,1]), [36, 234, 25, 55, 6, 81, 71, 192]))\n",
    "df = pd.DataFrame(data, columns=['Is_Male?', 'Post_Text', 'Post_Shared?', 'N'])\n",
    "df = df.loc[df.index.repeat(df['N'])].reset_index(drop=True).drop(columns=['N'])\n",
    "values = sorted(df['Post_Text'].unique())\n",
    "df['Post_Text'].replace(values, ['I really love my job!', 'My boss is pretty terrible.'], inplace=True)\n",
    "original_df = df.copy()\n",
    "df = None\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, it seems like posts by women get shared more often.  More specifically, it appears that being male **reduces** your the chance your post is shared by 4.5 percentage points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_probability = original_df[(original_df['Is_Male?']==1)]['Post_Shared?'].value_counts(normalize=True)[1]\n",
    "male_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8257142857142857"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_probability = original_df[(original_df['Is_Male?']==0)]['Post_Shared?'].value_counts(normalize=True)[1]\n",
    "female_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04571428571428571"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_probability-female_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is inaccurate. In fact, this is an example of [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox), and the true causal effect of being male in this simulated datsaet is roughly **0.05** (as opposed to **-0.045**) with men's posts being more likely to be shared. The reason is that women in this simulation tend to make more positive posts which tend to be shared more often here. Post sentiment, then, is a [mediator](https://en.wikipedia.org/wiki/Mediation_(statistics), which is statistically statistically similar to a [confounder](https://en.wikipedia.org/wiki/Confounding).   \n",
    "\n",
    "When controlling for the sentiment of the post (the mediator variable in this dataset), it is revealed that men's posts are, in fact, shared more often (for both negative posts and positive posts). This can be quickly and easily estimated in **CausalNLP**.\n",
    "\n",
    "### Causal Inference from Text with Autocoders\n",
    "\n",
    "Let's first use the `Autocoder` to transform the raw text into sentiment.  We can then control for sentiment when estimating the causal effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85a51703c48484d846afecfaa37068e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from causalnlp.autocoder import Autocoder\n",
    "ac = Autocoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ac.code_sentiment(original_df['Post_Text'].values, original_df, binarize=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Male?</th>\n",
       "      <th>Post_Text</th>\n",
       "      <th>Post_Shared?</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Is_Male?              Post_Text  Post_Shared?  negative  positive\n",
       "0         0  I really love my job!             0  0.019191  0.980809\n",
       "1         0  I really love my job!             0  0.019191  0.980809\n",
       "2         0  I really love my job!             0  0.019191  0.980809\n",
       "3         0  I really love my job!             0  0.019191  0.980809\n",
       "4         0  I really love my job!             0  0.019191  0.980809"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When autocoding the raw text for sentiment, we have chosen to use the raw \"probabilities\" with `binarize=False`.  A binary variable can also be used with `binarize=True`.\n",
    "\n",
    "Next, let's estimate the treatment effects. We will ignore the `positive` and `Post_Shared?` columns, as their information is captured by the `negative` column in this example. We will use the T-Learner. See [this paper](https://arxiv.org/abs/1706.03461) for more information on metalearner types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome column (categorical): Post_Shared?\n",
      "treatment column: Is_Male?\n",
      "numerical/categorical covariates: ['negative']\n",
      "preprocess time:  0.013550996780395508  sec\n",
      "start fitting causal inference model\n",
      "time to fit causal inference model:  0.8901166915893555  sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<causalnlp.core.causalinference.CausalInferenceModel at 0x7fca0c2040f0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from causalnlp import CausalInferenceModel\n",
    "cm = CausalInferenceModel(df, method='t-learner',\n",
    "                          treatment_col='Is_Male?', outcome_col='Post_Shared?',\n",
    "                          include_cols=['negative'])\n",
    "cm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon controlling for sentiment, we see that the overall average treatment is correctly estimated as 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.05366850622769351}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate = cm.estimate_ate()\n",
    "ate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a small, simulated, toy problem, we can manually calculate the adjusted treatment effect by controlling for the single counfounder (i.e., post negativity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0534529194528211"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def ATE_adjusted(C, T, Y):\n",
    "    x = defaultdict(list)\n",
    "    for c, t, y in zip(C, T, Y):\n",
    "        x[c, t].append(y)\n",
    "\n",
    "    C0_ATE = np.mean(x[0,1]) - np.mean(x[0,0])\n",
    "    C1_ATE = np.mean(x[1,1]) - np.mean(x[1,0])\n",
    "    return np.mean([C0_ATE, C1_ATE])\n",
    "ATE_adjusted((df['negative']>0.5).astype('int'), df['Is_Male?'].values, df['Post_Shared?'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this value is close to our estimate.\n",
    "\n",
    "**CausalNLP** allows you to easily compute conditional or individualized treatment effects.\n",
    "For instance, for negative posts, being male increases the chance of your post being shared by about 4 percentage points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.042535751074149745}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.estimate_ate(cm.df['negative']>0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For positive posts, being male increases the chance of your post being shared by about 6 percentage points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.06436468274776497}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.estimate_ate(cm.df['negative']<0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ate['ate'] > 0.05\n",
    "assert ate['ate'] < 0.055"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions can be made for new observations.    We just have to make sure it contains the relevant columns included in the DataFrame supplied to `CausalInferenceModel.fit`. In this case, it must include `Is_Male?` and `negative`. This can be verified with the `CausalInferenceModel.get_required_columns` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is_Male?', 'negative']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_required_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06436468]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "     'text' : ['I love my life.'],\n",
    "    'Is_Male?' : [0],\n",
    "    'negative' : [0]\n",
    "      })\n",
    "effect = cm.predict(test_df)\n",
    "assert effect[0][0] < 0.065\n",
    "assert effect[0][0] > 0.064\n",
    "print(effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Inference Using Raw Text as a Confounder/Mediator\n",
    "\n",
    "In the example above, we approached the problem under the assumption that a specific lingustic property (sentiment) was an important mediator or confounder for which to control. In some cases, there may also be other unknown lingustic properties that are potential confounders/mediators (e.g., topic, politeness, toxic language, readability).  \n",
    "\n",
    "In **CausalNLP**, we can also use the **raw text** as the potential confounder/mediator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome column (categorical): Post_Shared?\n",
      "treatment column: Is_Male?\n",
      "numerical/categorical covariates: []\n",
      "text covariate: Post_Text\n",
      "preprocess time:  0.015369415283203125  sec\n",
      "start fitting causal inference model\n",
      "time to fit causal inference model:  0.5458502769470215  sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<causalnlp.core.causalinference.CausalInferenceModel at 0x7fca0d1921d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CausalInferenceModel(df, method='t-learner',\n",
    "                          treatment_col='Is_Male?', outcome_col='Post_Shared?', text_col='Post_Text',\n",
    "                         ignore_cols=['negative', 'positive'])\n",
    "cm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have excluded the **negative** and **positive** columns as extra covariates, you can use traditional categorical/numerical covariates in combination with a text field covariate (if they exist as extra columns in the dataframe).\n",
    "\n",
    "Here, we see that the same causal estimates are returned, as the text is easy to infer as positive or negative based on their correlations with the outcomes in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.05366850622769351}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate = cm.estimate_ate()\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.042535751074149745}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.estimate_ate(df['Post_Text'] == 'My boss is pretty terrible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.06436468274776497}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.estimate_ate(df['Post_Text'] == 'I really love my job!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ate['ate'] > 0.05\n",
    "assert ate['ate'] < 0.055"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Make predictions on new data.  Again, make sure the DataFrame contains the relevant columns included in the original DataFrame supplied to `CausalInferenceModel.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is_Male?', 'Post_Text']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_required_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06436468]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "     'Post_Text' : ['I love my life.'],\n",
    "    'New Column' : [1],\n",
    "    'Is_Male?' : [0],\n",
    "    'negative' : [0]\n",
    "      })\n",
    "effect = cm.predict(test_df)\n",
    "assert effect[0][0] < 0.065\n",
    "assert effect[0][0] > 0.064\n",
    "print(effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: v_boss        1.0\n",
       " v_terrible    0.0\n",
       " v_pretty      0.0\n",
       " dtype: float64}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.interpret(plot=False, method='feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.interpret(plot=True, method='feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x194.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm.interpret(plot=True, method='shap_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Inference With Text as a Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we were interested in estimating the causal impact of **sentiment** on the outcome.  That is, **sentiment** of text is the treatment, and the **gender** is a potential confounder. As we did above, we can use the `Autocoder` to create the treatment variable.  The only difference is that we would supply the `binarize=True` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ac.code_sentiment(original_df['Post_Text'].values, original_df, binarize=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Male?</th>\n",
       "      <th>Post_Text</th>\n",
       "      <th>Post_Shared?</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I really love my job!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Is_Male?              Post_Text  Post_Shared?  negative  positive\n",
       "0         0  I really love my job!             0         0         1\n",
       "1         0  I really love my job!             0         0         1\n",
       "2         0  I really love my job!             0         0         1\n",
       "3         0  I really love my job!             0         0         1\n",
       "4         0  I really love my job!             0         0         1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome column (categorical): Post_Shared?\n",
      "treatment column: positive\n",
      "numerical/categorical covariates: ['Is_Male?']\n",
      "preprocess time:  0.008125543594360352  sec\n",
      "start fitting causal inference model\n",
      "time to fit causal inference model:  0.5112130641937256  sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<causalnlp.core.causalinference.CausalInferenceModel at 0x7fca0ca17f98>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CausalInferenceModel(df, method='t-learner',\n",
    "                          treatment_col='positive', outcome_col='Post_Shared?',\n",
    "                          include_cols=['Is_Male?'])\n",
    "cm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 0.19008080596986368}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ate = cm.estimate_ate()\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ate['ate'] > 0.18\n",
    "assert ate['ate'] < 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'Is_Male?']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_required_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20099539]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'Is_Male?' : [1],\n",
    "    'positive' : [1]\n",
    "      })\n",
    "effect = cm.predict(test_df)\n",
    "print(effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00a_core.causalinference.ipynb.\n",
      "Converted 00b_core.causalbert.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted 02_analyzers.ipynb.\n",
      "Converted 03_key_driver_analysis.ipynb.\n",
      "Converted 04_preprocessing.ipynb.\n",
      "Converted 05a_meta.base.ipynb.\n",
      "Converted 05b_meta.tlearner.ipynb.\n",
      "Converted 05c_meta.slearner.ipynb.\n",
      "Converted 05d_meta.xlearner.ipynb.\n",
      "Converted 05e_meta.rlearner.ipynb.\n",
      "Converted 05f_meta.utils.ipynb.\n",
      "Converted 05g_meta.explainer.ipynb.\n",
      "Converted 05h_meta.propensity.ipynb.\n",
      "Converted 05i_meta.sensitivity.ipynb.\n",
      "Converted 99_examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
