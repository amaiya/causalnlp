{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp meta.tlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Learner\n",
    "\n",
    "> T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# REFERENCE: https://github.com/uber/causalml\n",
    "\n",
    "# Copyright 2019 Uber Technology, Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import numpy as np\n",
    "from packaging import version\n",
    "from scipy.stats import norm\n",
    "import sklearn\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "if version.parse(sklearn.__version__) >= version.parse('0.22.0'):\n",
    "    from sklearn.utils._testing import ignore_warnings\n",
    "else:\n",
    "    from sklearn.utils.testing import ignore_warnings\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from causalnlp.meta.base import BaseLearner\n",
    "from causalnlp.meta.explainer import Explainer\n",
    "from causalnlp.meta.utils import check_treatment_vector, convert_pd_to_np\n",
    "from causalnlp.meta.utils import regression_metrics, classification_metrics\n",
    "\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "class BaseTLearner(BaseLearner):\n",
    "    \"\"\"A parent class for T-learner regressor classes.\n",
    "\n",
    "    A T-learner estimates treatment effects with two machine learning models.\n",
    "\n",
    "    Details of T-learner are available at Kunzel et al. (2018) (https://arxiv.org/abs/1706.03461).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner=None, control_learner=None, treatment_learner=None, ate_alpha=.05, control_name=0):\n",
    "        \"\"\"Initialize a T-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (model): a model to estimate control and treatment outcomes.\n",
    "            control_learner (model, optional): a model to estimate control outcomes\n",
    "            treatment_learner (model, optional): a model to estimate treatment outcomes\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        assert (learner is not None) or ((control_learner is not None) and (treatment_learner is not None))\n",
    "\n",
    "        if control_learner is None:\n",
    "            self.model_c = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_c = control_learner\n",
    "\n",
    "        if treatment_learner is None:\n",
    "            self.model_t = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_t = treatment_learner\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(model_c={}, model_t={})'.format(self.__class__.__name__,\n",
    "                                                   self.model_c.__repr__(),\n",
    "                                                   self.model_t.__repr__())\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, X, treatment, y, p=None):\n",
    "        \"\"\"Fit the inference model\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models_c = {group: deepcopy(self.model_c) for group in self.t_groups}\n",
    "        self.models_t = {group: deepcopy(self.model_t) for group in self.t_groups}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            X_filt = X[mask]\n",
    "            y_filt = y[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "\n",
    "            self.models_c[group].fit(X_filt[w == 0], y_filt[w == 0])\n",
    "            self.models_t[group].fit(X_filt[w == 1], y_filt[w == 1])\n",
    "\n",
    "    def predict(self, X, treatment=None, y=None, p=None, return_components=False, verbose=True):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        yhat_cs = {}\n",
    "        yhat_ts = {}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            model_c = self.models_c[group]\n",
    "            model_t = self.models_t[group]\n",
    "            yhat_cs[group] = model_c.predict(X)\n",
    "            yhat_ts[group] = model_t.predict(X)\n",
    "\n",
    "            if (y is not None) and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                y_filt = y[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "\n",
    "                yhat = np.zeros_like(y_filt, dtype=float)\n",
    "                yhat[w == 0] = yhat_cs[group][mask][w == 0]\n",
    "                yhat[w == 1] = yhat_ts[group][mask][w == 1]\n",
    "\n",
    "                logger.info('Error metrics for group {}'.format(group))\n",
    "                regression_metrics(y_filt, yhat, w)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            te[:, i] = yhat_ts[group] - yhat_cs[group]\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, yhat_cs, yhat_ts\n",
    "\n",
    "    def fit_predict(self, X, treatment, y, p=None, return_ci=False, n_bootstraps=1000, bootstrap_size=10000,\n",
    "                    return_components=False, verbose=True):\n",
    "        \"\"\"Fit the inference model of the T learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (str): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment].\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y)\n",
    "        te = self.predict(X, treatment, y, return_components=return_components)\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_c_global = deepcopy(self.models_c)\n",
    "            models_t_global = deepcopy(self.models_t)\n",
    "            te_bootstraps = np.zeros(shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals')\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha/2)*100, axis=2)\n",
    "            te_upper = np.percentile(te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models_c = deepcopy(models_c_global)\n",
    "            self.models_t = deepcopy(models_t_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(self, X, treatment, y, p=None, bootstrap_ci=False, n_bootstraps=1000, bootstrap_size=10000):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            bootstrap_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        te, yhat_cs, yhat_ts = self.fit_predict(X, treatment, y, return_components=True)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            _ate = te[:, i].mean()\n",
    "\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            y_filt = y[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "            prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "            yhat_c = yhat_cs[group][mask]\n",
    "            yhat_t = yhat_ts[group][mask]\n",
    "\n",
    "            se = np.sqrt((\n",
    "                (y_filt[w == 0] - yhat_c[w == 0]).var()\n",
    "                / (1 - prob_treatment) +\n",
    "                (y_filt[w == 1] - yhat_t[w == 1]).var()\n",
    "                / prob_treatment +\n",
    "                (yhat_t - yhat_c).var()\n",
    "            ) / y_filt.shape[0])\n",
    "\n",
    "            _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "            _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "            ate[i] = _ate\n",
    "            ate_lb[i] = _ate_lb\n",
    "            ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_c_global = deepcopy(self.models_c)\n",
    "            models_t_global = deepcopy(self.models_t)\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals for ATE')\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                ate_b = self.bootstrap(X, treatment, y, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = ate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1)\n",
    "            ate_upper = np.percentile(ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models_c = deepcopy(models_c_global)\n",
    "            self.models_t = deepcopy(models_t_global)\n",
    "\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "\n",
    "class BaseTRegressor(BaseTLearner):\n",
    "    \"\"\"\n",
    "    A parent class for T-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learner=None,\n",
    "                 control_learner=None,\n",
    "                 treatment_learner=None,\n",
    "                 ate_alpha=.05,\n",
    "                 control_name=0):\n",
    "        \"\"\"Initialize a T-learner regressor.\n",
    "\n",
    "        Args:\n",
    "            learner (model): a model to estimate control and treatment outcomes.\n",
    "            control_learner (model, optional): a model to estimate control outcomes\n",
    "            treatment_learner (model, optional): a model to estimate treatment outcomes\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            control_learner=control_learner,\n",
    "            treatment_learner=treatment_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name)\n",
    "\n",
    "\n",
    "class BaseTClassifier(BaseTLearner):\n",
    "    \"\"\"\n",
    "    A parent class for T-learner classifier classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learner=None,\n",
    "                 control_learner=None,\n",
    "                 treatment_learner=None,\n",
    "                 ate_alpha=.05,\n",
    "                 control_name=0):\n",
    "        \"\"\"Initialize a T-learner classifier.\n",
    "\n",
    "        Args:\n",
    "            learner (model): a model to estimate control and treatment outcomes.\n",
    "            control_learner (model, optional): a model to estimate control outcomes\n",
    "            treatment_learner (model, optional): a model to estimate treatment outcomes\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            control_learner=control_learner,\n",
    "            treatment_learner=treatment_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name)\n",
    "\n",
    "    def predict(self, X, treatment=None, y=None, p=None, return_components=False, verbose=True):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        yhat_cs = {}\n",
    "        yhat_ts = {}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            model_c = self.models_c[group]\n",
    "            model_t = self.models_t[group]\n",
    "            yhat_cs[group] = model_c.predict_proba(X)[:, 1]\n",
    "            yhat_ts[group] = model_t.predict_proba(X)[:, 1]\n",
    "\n",
    "            if (y is not None) and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                y_filt = y[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "\n",
    "                yhat = np.zeros_like(y_filt, dtype=float)\n",
    "                yhat[w == 0] = yhat_cs[group][mask][w == 0]\n",
    "                yhat[w == 1] = yhat_ts[group][mask][w == 1]\n",
    "\n",
    "                logger.info('Error metrics for group {}'.format(group))\n",
    "                classification_metrics(y_filt, yhat, w)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            te[:, i] = yhat_ts[group] - yhat_cs[group]\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, yhat_cs, yhat_ts\n",
    "\n",
    "\n",
    "class XGBTRegressor(BaseTRegressor):\n",
    "    def __init__(self, ate_alpha=.05, control_name=0, *args, **kwargs):\n",
    "        \"\"\"Initialize a T-learner with two XGBoost models.\"\"\"\n",
    "        super().__init__(learner=XGBRegressor(*args, **kwargs),\n",
    "                         ate_alpha=ate_alpha,\n",
    "                         control_name=control_name)\n",
    "\n",
    "\n",
    "class MLPTRegressor(BaseTRegressor):\n",
    "    def __init__(self, ate_alpha=.05, control_name=0, *args, **kwargs):\n",
    "        \"\"\"Initialize a T-learner with two MLP models.\"\"\"\n",
    "        super().__init__(learner=MLPRegressor(*args, **kwargs),\n",
    "                         ate_alpha=ate_alpha,\n",
    "                         control_name=control_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_causalinference.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted 02_analyzers.ipynb.\n",
      "Converted 03_key_driver_analysis.ipynb.\n",
      "Converted 04_preprocessing.ipynb.\n",
      "Converted 05a_meta.base.ipynb.\n",
      "Converted 05b_meta.explainer.ipynb.\n",
      "Converted 05c_meta.utils.ipynb.\n",
      "Converted 05d_meta.propensity.ipynb.\n",
      "Converted 05e_meta.tlearner.ipynb.\n",
      "Converted 05f_meta.slearner.ipynb.\n",
      "Converted 99_examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
