{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Metalearner Utils\n",
    "output-file: meta.utils.html\n",
    "title: Metalearner Utils\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp meta.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# REFERENCE: https://github.com/uber/causalml\n",
    "\n",
    "# Copyright 2019 Uber Technology, Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from packaging import version\n",
    "from xgboost import __version__ as xgboost_version\n",
    "\n",
    "\n",
    "def convert_pd_to_np(*args):\n",
    "    output = [obj.to_numpy() if hasattr(obj, \"to_numpy\") else obj for obj in args]\n",
    "    return output if len(output) > 1 else output[0]\n",
    "\n",
    "\n",
    "def check_treatment_vector(treatment, control_name=None):\n",
    "    n_unique_treatments = np.unique(treatment).shape[0]\n",
    "    assert n_unique_treatments > 1, \\\n",
    "        'Treatment vector must have at least two levels.'\n",
    "    if control_name is not None:\n",
    "        assert control_name in treatment, \\\n",
    "            'Control group level {} not found in treatment vector.'.format(control_name)\n",
    "\n",
    "\n",
    "def check_p_conditions(p, t_groups):\n",
    "    eps = np.finfo(float).eps\n",
    "    assert isinstance(p, (np.ndarray, pd.Series, dict)), \\\n",
    "        'p must be an np.ndarray, pd.Series, or dict type'\n",
    "    if isinstance(p, (np.ndarray, pd.Series)):\n",
    "        assert t_groups.shape[0] == 1, \\\n",
    "            'If p is passed as an np.ndarray, there must be only 1 unique non-control group in the treatment vector.'\n",
    "        assert (0 + eps < p).all() and (p < 1 - eps).all(), \\\n",
    "            'The values of p should lie within the (0, 1) interval.'\n",
    "\n",
    "    if isinstance(p, dict):\n",
    "        for t_name in t_groups:\n",
    "            assert (0 + eps < p[t_name]).all() and (p[t_name] < 1 - eps).all(), \\\n",
    "                'The values of p should lie within the (0, 1) interval.'\n",
    "\n",
    "\n",
    "def check_explain_conditions(method, models, X=None, treatment=None, y=None):\n",
    "    valid_methods = ['gini', 'permutation', 'shapley']\n",
    "    assert method in valid_methods, 'Current supported methods: {}'.format(', '.join(valid_methods))\n",
    "\n",
    "    if method in ('gini', 'shapley'):\n",
    "        conds = [hasattr(mod, \"feature_importances_\") for mod in models]\n",
    "        assert all(conds), \"Both models must have .feature_importances_ attribute if method = {}\".format(method)\n",
    "\n",
    "    if method in ('permutation', 'shapley'):\n",
    "        assert all(arr is not None for arr in (X, treatment, y)), \\\n",
    "            \"X, treatment, and y must be provided if method = {}\".format(method)\n",
    "\n",
    "\n",
    "def clean_xgboost_objective(objective):\n",
    "    \"\"\"\n",
    "    Translate objective to be compatible with loaded xgboost version\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "\n",
    "    objective : string\n",
    "        The objective to translate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The translated objective, or original if no translation was required.\n",
    "    \"\"\"\n",
    "    compat_before_v83 = {'reg:squarederror': 'reg:linear'}\n",
    "    compat_v83_or_later = {'reg:linear': 'reg:squarederror'}\n",
    "    if version.parse(xgboost_version) < version.parse('0.83'):\n",
    "        if objective in compat_before_v83:\n",
    "            objective = compat_before_v83[objective]\n",
    "    else:\n",
    "        if objective in compat_v83_or_later:\n",
    "            objective = compat_v83_or_later[objective]\n",
    "    return objective\n",
    "\n",
    "\n",
    "def get_xgboost_objective_metric(objective):\n",
    "    \"\"\"\n",
    "    Get the xgboost version-compatible objective and evaluation metric from a potentially version-incompatible input.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "\n",
    "    objective : string\n",
    "        An xgboost objective that may be incompatible with the installed version.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple with the translated objective and evaluation metric.\n",
    "    \"\"\"\n",
    "    def clean_dict_keys(orig):\n",
    "        return {clean_xgboost_objective(k): v for (k, v) in orig.items()}\n",
    "\n",
    "    metric_mapping = clean_dict_keys({\n",
    "        'rank:pairwise': 'auc',\n",
    "        'reg:squarederror': 'rmse',\n",
    "    })\n",
    "\n",
    "    objective = clean_xgboost_objective(objective)\n",
    "\n",
    "    assert (objective in metric_mapping), \\\n",
    "        'Effect learner objective must be one of: ' + \", \".join(metric_mapping)\n",
    "    return objective, metric_mapping[objective]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "EPS = 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae # noqa\n",
    "from sklearn.metrics import r2_score    # noqa\n",
    "\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "def ape(y, p):\n",
    "    \"\"\"Absolute Percentage Error (APE).\n",
    "    Args:\n",
    "        y (float): target\n",
    "        p (float): prediction\n",
    "\n",
    "    Returns:\n",
    "        e (float): APE\n",
    "    \"\"\"\n",
    "\n",
    "    assert np.abs(y) > EPS\n",
    "    return np.abs(1 - p / y)\n",
    "\n",
    "\n",
    "def mape(y, p):\n",
    "    \"\"\"Mean Absolute Percentage Error (MAPE).\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "\n",
    "    Returns:\n",
    "        e (numpy.float64): MAPE\n",
    "    \"\"\"\n",
    "\n",
    "    filt = np.abs(y) > EPS\n",
    "    return np.mean(np.abs(1 - p[filt] / y[filt]))\n",
    "\n",
    "\n",
    "def smape(y, p):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error (sMAPE).\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "\n",
    "    Returns:\n",
    "        e (numpy.float64): sMAPE\n",
    "    \"\"\"\n",
    "    return 2. * np.mean(np.abs(y - p) / (np.abs(y) + np.abs(p)))\n",
    "\n",
    "\n",
    "def rmse(y, p):\n",
    "    \"\"\"Root Mean Squared Error (RMSE).\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "\n",
    "    Returns:\n",
    "        e (numpy.float64): RMSE\n",
    "    \"\"\"\n",
    "\n",
    "    # check and get number of samples\n",
    "    assert y.shape == p.shape\n",
    "\n",
    "    return np.sqrt(mse(y, p))\n",
    "\n",
    "\n",
    "def gini(y, p):\n",
    "    \"\"\"Normalized Gini Coefficient.\n",
    "\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "\n",
    "    Returns:\n",
    "        e (numpy.float64): normalized Gini coefficient\n",
    "    \"\"\"\n",
    "\n",
    "    # check and get number of samples\n",
    "    assert y.shape == p.shape\n",
    "\n",
    "    n_samples = y.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y, p]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    l_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    l_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    l_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    g_true = np.sum(l_ones - l_true)\n",
    "    g_pred = np.sum(l_ones - l_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return g_pred / g_true\n",
    "\n",
    "\n",
    "def regression_metrics(y, p, w=None, metrics={'RMSE': rmse, 'sMAPE': smape, 'Gini': gini}):\n",
    "    \"\"\"Log metrics for regressors.\n",
    "\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "        w (numpy.array, optional): a treatment vector (1 or True: treatment, 0 or False: control). If given, log\n",
    "            metrics for the treatment and control group separately\n",
    "        metrics (dict, optional): a dictionary of the metric names and functions\n",
    "    \"\"\"\n",
    "    assert metrics\n",
    "    assert y.shape[0] == p.shape[0]\n",
    "\n",
    "    for name, func in metrics.items():\n",
    "        if w is not None:\n",
    "            assert y.shape[0] == w.shape[0]\n",
    "            if w.dtype != bool:\n",
    "                w = w == 1\n",
    "            logger.info('{:>8s}   (Control): {:10.4f}'.format(name, func(y[~w], p[~w])))\n",
    "            logger.info('{:>8s} (Treatment): {:10.4f}'.format(name, func(y[w], p[w])))\n",
    "        else:\n",
    "            logger.info('{:>8s}: {:10.4f}'.format(name, func(y, p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "def logloss(y, p):\n",
    "    \"\"\"Bounded log loss error.\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "    Returns:\n",
    "        bounded log loss error\n",
    "    \"\"\"\n",
    "\n",
    "    p[p < EPS] = EPS\n",
    "    p[p > 1 - EPS] = 1 - EPS\n",
    "    return log_loss(y, p)\n",
    "\n",
    "\n",
    "def classification_metrics(y, p, w=None, metrics={'AUC': roc_auc_score, 'Log Loss': logloss}):\n",
    "    \"\"\"Log metrics for classifiers.\n",
    "\n",
    "    Args:\n",
    "        y (numpy.array): target\n",
    "        p (numpy.array): prediction\n",
    "        w (numpy.array, optional): a treatment vector (1 or True: treatment, 0 or False: control). If given, log\n",
    "            metrics for the treatment and control group separately\n",
    "        metrics (dict, optional): a dictionary of the metric names and functions\n",
    "    \"\"\"\n",
    "    regression_metrics(y=y, p=p, w=w, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "def smd(feature, treatment):\n",
    "    \"\"\"Calculate the standard mean difference (SMD) of a feature between the\n",
    "    treatment and control groups.\n",
    "\n",
    "    The definition is available at\n",
    "    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3144483/#s11title\n",
    "\n",
    "    Args:\n",
    "        feature (pandas.Series): a column of a feature to calculate SMD for\n",
    "        treatment (pandas.Series): a column that indicate whether a row is in\n",
    "                                   the treatment group or not\n",
    "\n",
    "    Returns:\n",
    "        (float): The SMD of the feature\n",
    "    \"\"\"\n",
    "    t = feature[treatment == 1]\n",
    "    c = feature[treatment == 0]\n",
    "    return (t.mean() - c.mean()) / np.sqrt(.5 * (t.var() + c.var()))\n",
    "\n",
    "\n",
    "def create_table_one(data, treatment_col, features):\n",
    "    \"\"\"Report balance in input features between the treatment and control groups.\n",
    "\n",
    "    References:\n",
    "        R's tableone at CRAN: https://github.com/kaz-yos/tableone\n",
    "        Python's tableone at PyPi: https://github.com/tompollard/tableone\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): total or matched sample data\n",
    "        treatment_col (str): the column name for the treatment\n",
    "        features (list of str): the column names of features\n",
    "\n",
    "    Returns:\n",
    "        (pandas.DataFrame): A table with the means and standard deviations in\n",
    "            the treatment and control groups, and the SMD between two groups\n",
    "            for the features.\n",
    "    \"\"\"\n",
    "    t1 = pd.pivot_table(data[features + [treatment_col]],\n",
    "                        columns=treatment_col,\n",
    "                        aggfunc=[lambda x: '{:.2f} ({:.2f})'.format(x.mean(),\n",
    "                                                                    x.std())])\n",
    "    t1.columns = t1.columns.droplevel(level=0)\n",
    "    t1['SMD'] = data[features].apply(\n",
    "        lambda x: smd(x, data[treatment_col])\n",
    "    ).round(4)\n",
    "\n",
    "    n_row = pd.pivot_table(data[[features[0], treatment_col]],\n",
    "                           columns=treatment_col,\n",
    "                           aggfunc=['count'])\n",
    "    n_row.columns = n_row.columns.droplevel(level=0)\n",
    "    n_row['SMD'] = ''\n",
    "    n_row.index = ['n']\n",
    "\n",
    "    t1 = pd.concat([n_row, t1], axis=0)\n",
    "    t1.columns.name = ''\n",
    "    t1.columns = ['Control', 'Treatment', 'SMD']\n",
    "    t1.index.name = 'Variable'\n",
    "\n",
    "    return t1\n",
    "\n",
    "\n",
    "class NearestNeighborMatch(object):\n",
    "    \"\"\"\n",
    "    Propensity score matching based on the nearest neighbor algorithm.\n",
    "\n",
    "    Attributes:\n",
    "        caliper (float): threshold to be considered as a match.\n",
    "        replace (bool): whether to match with replacement or not\n",
    "        ratio (int): ratio of control / treatment to be matched. used only if\n",
    "            replace=True.\n",
    "        shuffle (bool): whether to shuffle the treatment group data before\n",
    "            matching\n",
    "        random_state (numpy.random.RandomState or int): RandomState or an int\n",
    "            seed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, caliper=.2, replace=False, ratio=1, shuffle=True,\n",
    "                 random_state=None):\n",
    "        \"\"\"Initialize a propensity score matching model.\n",
    "\n",
    "        Args:\n",
    "            caliper (float): threshold to be considered as a match.\n",
    "            replace (bool): whether to match with replacement or not\n",
    "            shuffle (bool): whether to shuffle the treatment group data before\n",
    "                matching or not\n",
    "            random_state (numpy.random.RandomState or int): RandomState or an\n",
    "                int seed\n",
    "        \"\"\"\n",
    "        self.caliper = caliper\n",
    "        self.replace = replace\n",
    "        self.ratio = ratio\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = check_random_state(random_state)\n",
    "\n",
    "    def match(self, data, treatment_col, score_cols):\n",
    "        \"\"\"Find matches from the control group by matching on specified columns\n",
    "        (propensity preferred).\n",
    "\n",
    "        Args:\n",
    "            data (pandas.DataFrame): total input data\n",
    "            treatment_col (str): the column name for the treatment\n",
    "            score_cols (list): list of column names for matching (propensity\n",
    "                column should be included)\n",
    "\n",
    "        Returns:\n",
    "            (pandas.DataFrame): The subset of data consisting of matched\n",
    "                treatment and control group data.\n",
    "        \"\"\"\n",
    "        assert type(score_cols) is list, 'score_cols must be a list'\n",
    "        treatment = data.loc[data[treatment_col] == 1, score_cols]\n",
    "        control = data.loc[data[treatment_col] == 0, score_cols]\n",
    "\n",
    "        sdcal = self.caliper * np.std(data[score_cols].values)\n",
    "\n",
    "        if self.replace:\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(data[score_cols])\n",
    "            treatment_scaled = pd.DataFrame(scaler.transform(treatment),\n",
    "                                            index=treatment.index)\n",
    "            control_scaled = pd.DataFrame(scaler.transform(control),\n",
    "                                          index=control.index)\n",
    "\n",
    "            # SD is the same as caliper because we use a StandardScaler above\n",
    "            sdcal = self.caliper\n",
    "\n",
    "            matching_model = NearestNeighbors(n_neighbors=self.ratio)\n",
    "            matching_model.fit(control_scaled)\n",
    "            distances, indices = matching_model.kneighbors(treatment_scaled)\n",
    "\n",
    "            # distances and indices are (n_obs, self.ratio) matrices.\n",
    "            # To index easily, reshape distances, indices and treatment into\n",
    "            # the (n_obs * self.ratio, 1) matrices and data frame.\n",
    "            distances = distances.T.flatten()\n",
    "            indices = indices.T.flatten()\n",
    "            treatment_scaled = pd.concat([treatment_scaled] * self.ratio,\n",
    "                                         axis=0)\n",
    "\n",
    "            cond = (distances / np.sqrt(len(score_cols)) ) < sdcal\n",
    "            # Deduplicate the indices of the treatment group\n",
    "            t_idx_matched = np.unique(treatment_scaled.loc[cond].index)\n",
    "            # XXX: Should we deduplicate the indices of the control group too?\n",
    "            c_idx_matched = np.array(control_scaled.iloc[indices[cond]].index)\n",
    "        else:\n",
    "            assert len(score_cols) == 1, (\n",
    "                'Matching on multiple columns is only supported using the '\n",
    "                'replacement method (if matching on multiple columns, set '\n",
    "                'replace=True).'\n",
    "            )\n",
    "            # unpack score_cols for the single-variable matching case\n",
    "            score_col = score_cols[0]\n",
    "\n",
    "            if self.shuffle:\n",
    "                t_indices = self.random_state.permutation(treatment.index)\n",
    "            else:\n",
    "                t_indices = treatment.index\n",
    "\n",
    "            t_idx_matched = []\n",
    "            c_idx_matched = []\n",
    "            control['unmatched'] = True\n",
    "\n",
    "            for t_idx in t_indices:\n",
    "                dist = np.abs(control.loc[control.unmatched, score_col]\n",
    "                              - treatment.loc[t_idx, score_col])\n",
    "                c_idx_min = dist.idxmin()\n",
    "                if dist[c_idx_min] <= sdcal:\n",
    "                    t_idx_matched.append(t_idx)\n",
    "                    c_idx_matched.append(c_idx_min)\n",
    "                    control.loc[c_idx_min, 'unmatched'] = False\n",
    "\n",
    "        return data.loc[np.concatenate([np.array(t_idx_matched),\n",
    "                                        np.array(c_idx_matched)])]\n",
    "\n",
    "    def match_by_group(self, data, treatment_col, score_cols, groupby_col):\n",
    "        \"\"\"Find matches from the control group stratified by groupby_col, by\n",
    "        matching on specified columns (propensity preferred).\n",
    "\n",
    "        Args:\n",
    "            data (pandas.DataFrame): total sample data\n",
    "            treatment_col (str): the column name for the treatment\n",
    "            score_cols (list): list of column names for matching (propensity\n",
    "                column should be included)\n",
    "            groupby_col (str): the column name to be used for stratification\n",
    "\n",
    "        Returns:\n",
    "            (pandas.DataFrame): The subset of data consisting of matched\n",
    "                treatment and control group data.\n",
    "        \"\"\"\n",
    "        matched = data.groupby(groupby_col).apply(\n",
    "            lambda x: self.match(data=x, treatment_col=treatment_col,\n",
    "                                 score_cols=score_cols)\n",
    "        )\n",
    "        return matched.reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "class MatchOptimizer(object):\n",
    "    def __init__(self, treatment_col='is_treatment', ps_col='pihat',\n",
    "                 user_col=None, matching_covariates=['pihat'], max_smd=0.1,\n",
    "                 max_deviation=0.1, caliper_range=(0.01, 0.5),\n",
    "                 max_pihat_range=(0.95, 0.999), max_iter_per_param=5,\n",
    "                 min_users_per_group=1000, smd_cols=['pihat'],\n",
    "                 dev_cols_transformations={'pihat': np.mean},\n",
    "                 dev_factor=1., verbose=True):\n",
    "        \"\"\"Finds the set of parameters that gives the best matching result.\n",
    "\n",
    "        Score = (number of features with SMD > max_smd)\n",
    "                + (sum of deviations for important variables\n",
    "                   * deviation factor)\n",
    "\n",
    "        The logic behind the scoring is that we are most concerned with\n",
    "        minimizing the number of features where SMD is lower than a certain\n",
    "        threshold (max_smd). However, we would also like the matched dataset\n",
    "        not deviate too much from the original dataset, in terms of key\n",
    "        variable(s), so that we still retain a similar userbase.\n",
    "\n",
    "        Args:\n",
    "            - treatment_col (str): name of the treatment column\n",
    "            - ps_col (str): name of the propensity score column\n",
    "            - max_smd (float): maximum acceptable SMD\n",
    "            - max_deviation (float): maximum acceptable deviation for\n",
    "                important variables\n",
    "            - caliper_range (tuple): low and high bounds for caliper search\n",
    "                range\n",
    "            - max_pihat_range (tuple): low and high bounds for max pihat\n",
    "                search range\n",
    "            - max_iter_per_param (int): maximum number of search values per\n",
    "                parameters\n",
    "            - min_users_per_group (int): minimum number of users per group in\n",
    "                matched set\n",
    "            - smd_cols (list): score is more sensitive to these features\n",
    "                exceeding max_smd\n",
    "            - dev_factor (float): importance weight factor for dev_cols\n",
    "                (e.g. dev_factor=1 means a 10% deviation leads to penalty of 1\n",
    "                in score)\n",
    "            - dev_cols_transformations (dict): dict of transformations to be\n",
    "                made on dev_cols\n",
    "            - verbose (bool): boolean flag for printing statements\n",
    "\n",
    "        Returns:\n",
    "            The best matched dataset (pd.DataFrame)\n",
    "        \"\"\"\n",
    "        self.treatment_col = treatment_col\n",
    "        self.ps_col = ps_col\n",
    "        self.user_col = user_col\n",
    "        self.matching_covariates = matching_covariates\n",
    "        self.max_smd = max_smd\n",
    "        self.max_deviation = max_deviation\n",
    "        self.caliper_range = np.linspace(*caliper_range,\n",
    "                                         num=max_iter_per_param)\n",
    "        self.max_pihat_range = np.linspace(*max_pihat_range,\n",
    "                                           num=max_iter_per_param)\n",
    "        self.max_iter_per_param = max_iter_per_param\n",
    "        self.min_users_per_group = min_users_per_group\n",
    "        self.smd_cols = smd_cols\n",
    "        self.dev_factor = dev_factor\n",
    "        self.dev_cols_transformations = dev_cols_transformations\n",
    "        self.best_params = {}\n",
    "        self.best_score = 1e7   # ideal score is 0\n",
    "        self.verbose = verbose\n",
    "        self.pass_all = False\n",
    "\n",
    "    def single_match(self, score_cols, pihat_threshold, caliper):\n",
    "        matcher = NearestNeighborMatch(caliper=caliper, replace=True)\n",
    "        df_matched = matcher.match(\n",
    "            data=self.df[self.df[self.ps_col] < pihat_threshold],\n",
    "            treatment_col=self.treatment_col, score_cols=score_cols\n",
    "        )\n",
    "        return df_matched\n",
    "\n",
    "    def check_table_one(self, tableone, matched, score_cols, pihat_threshold,\n",
    "                        caliper):\n",
    "        # check if better than past runs\n",
    "        smd_values = np.abs(tableone[tableone.index != 'n']['SMD'].astype(float))\n",
    "        num_cols_over_smd = (smd_values >= self.max_smd).sum()\n",
    "        self.cols_to_fix = smd_values[smd_values >= self.max_smd].sort_values(ascending=False).index.values\n",
    "        if self.user_col is None:\n",
    "            num_users_per_group = matched.reset_index().groupby(self.treatment_col)['index'].count().min()\n",
    "        else:\n",
    "            num_users_per_group = matched.groupby(self.treatment_col)[self.user_col].count().min()\n",
    "        deviations = [np.abs(self.original_stats[col] / matched[matched[self.treatment_col] == 1][col].mean() - 1)\n",
    "                      for col in self.dev_cols_transformations.keys()]\n",
    "\n",
    "        score = num_cols_over_smd\n",
    "        score += len([col for col in self.smd_cols if smd_values.loc[col] >= self.max_smd])\n",
    "        score += np.sum([dev*10*self.dev_factor for dev in deviations])\n",
    "\n",
    "        # check if can be considered as best score\n",
    "        if score < self.best_score and num_users_per_group > self.min_users_per_group:\n",
    "            self.best_score = score\n",
    "            self.best_params = {'score_cols': score_cols.copy(), 'pihat': pihat_threshold, 'caliper': caliper}\n",
    "            self.best_matched = matched.copy()\n",
    "        if self.verbose:\n",
    "            logger.info('\\tScore: {:.03f} (Best Score: {:.03f})\\n'.format(score, self.best_score))\n",
    "\n",
    "        # check if passes all criteria\n",
    "        self.pass_all = ((num_users_per_group > self.min_users_per_group) and (num_cols_over_smd == 0) and\n",
    "                         all(dev < self.max_deviation for dev in deviations))\n",
    "\n",
    "    def match_and_check(self, score_cols, pihat_threshold, caliper):\n",
    "        if self.verbose:\n",
    "            logger.info('Preparing match for: caliper={:.03f}, '\n",
    "                        'pihat_threshold={:.03f}, '\n",
    "                        'score_cols={}'.format(caliper, pihat_threshold, score_cols))\n",
    "        df_matched = self.single_match(score_cols=score_cols, pihat_threshold=pihat_threshold, caliper=caliper)\n",
    "        tableone = create_table_one(df_matched, self.treatment_col, self.matching_covariates)\n",
    "        self.check_table_one(tableone, df_matched, score_cols, pihat_threshold, caliper)\n",
    "\n",
    "    def search_best_match(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        self.original_stats = {}\n",
    "        for col, trans in self.dev_cols_transformations.items():\n",
    "            self.original_stats[col] = trans(self.df[self.df[self.treatment_col] == 1][col])\n",
    "\n",
    "        # search best max pihat\n",
    "        if self.verbose:\n",
    "            logger.info('SEARCHING FOR BEST PIHAT')\n",
    "        score_cols = [self.ps_col]\n",
    "        caliper = self.caliper_range[-1]\n",
    "        for pihat_threshold in self.max_pihat_range:\n",
    "            self.match_and_check(score_cols, pihat_threshold, caliper)\n",
    "\n",
    "        # search best score_cols\n",
    "        if self.verbose:\n",
    "            logger.info('SEARCHING FOR BEST SCORE_COLS')\n",
    "        pihat_threshold = self.best_params['pihat']\n",
    "        caliper = self.caliper_range[int(self.caliper_range.shape[0]/2)]\n",
    "        score_cols = [self.ps_col]\n",
    "        while not self.pass_all:\n",
    "            if len(self.cols_to_fix) == 0:\n",
    "                break\n",
    "            elif np.intersect1d(self.cols_to_fix, score_cols).shape[0] > 0:\n",
    "                break\n",
    "            else:\n",
    "                score_cols.append(self.cols_to_fix[0])\n",
    "                self.match_and_check(score_cols, pihat_threshold, caliper)\n",
    "\n",
    "        # search best caliper\n",
    "        if self.verbose:\n",
    "            logger.info('SEARCHING FOR BEST CALIPER')\n",
    "        score_cols = self.best_params['score_cols']\n",
    "        pihat_threshold = self.best_params['pihat']\n",
    "        for caliper in self.caliper_range:\n",
    "            self.match_and_check(score_cols, pihat_threshold, caliper)\n",
    "\n",
    "        # summarize\n",
    "        if self.verbose:\n",
    "            logger.info('\\n-----\\nBest params are:\\n{}'.format(self.best_params))\n",
    "\n",
    "        return self.best_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_causalinference.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted 02_analyzers.ipynb.\n",
      "Converted 03_key_driver_analysis.ipynb.\n",
      "Converted 04_preprocessing.ipynb.\n",
      "Converted 05a_meta.base.ipynb.\n",
      "Converted 05b_meta.explainer.ipynb.\n",
      "Converted 05c_meta.utils.ipynb.\n",
      "Converted 05d_meta.propensity.ipynb.\n",
      "Converted 05e_meta.tlearner.ipynb.\n",
      "Converted 05f_meta.slearner.ipynb.\n",
      "Converted 05g_meta.xlearner.ipynb.\n",
      "Converted 05h_meta.rlearner.ipynb.\n",
      "Converted 99_examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
