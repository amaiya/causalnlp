{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: S-Learner\n",
    "output-file: meta.slearner.html\n",
    "title: S-Learner\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp meta.slearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# REFERENCE: https://github.com/uber/causalml\n",
    "\n",
    "# Copyright 2019 Uber Technology, Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from copy import deepcopy\n",
    "\n",
    "from causalnlp.meta.base import BaseLearner\n",
    "from causalnlp.meta.explainer import Explainer\n",
    "from causalnlp.meta.utils import check_treatment_vector, convert_pd_to_np\n",
    "from causalnlp.meta.utils import regression_metrics, classification_metrics\n",
    "\n",
    "\n",
    "logger = logging.getLogger('causalnlp')\n",
    "\n",
    "\n",
    "\n",
    "class BaseSLearner(BaseLearner):\n",
    "    \"\"\"A parent class for S-learner classes.\n",
    "    An S-learner estimates treatment effects with one machine learning model.\n",
    "    Details of S-learner are available at Kunzel et al. (2018) (https://arxiv.org/abs/1706.03461).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner=None, ate_alpha=0.05, control_name=0):\n",
    "        \"\"\"Initialize an S-learner.\n",
    "        Args:\n",
    "            learner (optional): a model to estimate the treatment effect\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        if learner is not None:\n",
    "            self.model = learner\n",
    "        else:\n",
    "            self.model = DummyRegressor()\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(model={})'.format(self.__class__.__name__,\n",
    "                                     self.model.__repr__())\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None):\n",
    "        \"\"\"Fit the inference model\n",
    "        Args:\n",
    "            X (np.matrix, np.array, or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models = {group: deepcopy(self.model) for group in self.t_groups}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            X_filt = X[mask]\n",
    "            y_filt = y[mask]\n",
    "\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "            X_new = np.hstack((w.reshape((-1, 1)), X_filt))\n",
    "            self.models[group].fit(X_new, y_filt)\n",
    "\n",
    "    def predict(self, X, treatment=None, y=None, p=None, return_components=False, verbose=True):\n",
    "        \"\"\"Predict treatment effects.\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        yhat_cs = {}\n",
    "        yhat_ts = {}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            model = self.models[group]\n",
    "\n",
    "            # set the treatment column to zero (the control group)\n",
    "            X_new = np.hstack((np.zeros((X.shape[0], 1)), X))\n",
    "            yhat_cs[group] = model.predict(X_new)\n",
    "\n",
    "            # set the treatment column to one (the treatment group)\n",
    "            X_new[:, 0] = 1\n",
    "            yhat_ts[group] = model.predict(X_new)\n",
    "\n",
    "            if (y is not None) and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "                y_filt = y[mask]\n",
    "\n",
    "                yhat = np.zeros_like(y_filt, dtype=float)\n",
    "                yhat[w == 0] = yhat_cs[group][mask][w == 0]\n",
    "                yhat[w == 1] = yhat_ts[group][mask][w == 1]\n",
    "\n",
    "                logger.info('Error metrics for group {}'.format(group))\n",
    "                regression_metrics(y_filt, yhat, w)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            te[:, i] = yhat_ts[group] - yhat_cs[group]\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, yhat_cs, yhat_ts\n",
    "\n",
    "    def fit_predict(self, X, treatment, y, p=None, return_ci=False, n_bootstraps=1000, bootstrap_size=10000,\n",
    "                    return_components=False, verbose=True):\n",
    "        \"\"\"Fit the inference model of the S learner and predict treatment effects.\n",
    "        Args:\n",
    "            X (np.matrix, np.array, or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            return_ci (bool, optional): whether to return confidence intervals\n",
    "            n_bootstraps (int, optional): number of bootstrap iterations\n",
    "            bootstrap_size (int, optional): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment].\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        self.fit(X, treatment, y)\n",
    "        te = self.predict(X, treatment, y, return_components=return_components)\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_global = deepcopy(self.models)\n",
    "            te_bootstraps = np.zeros(shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals')\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha/2)*100, axis=2)\n",
    "            te_upper = np.percentile(te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models = deepcopy(models_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(self, X, treatment, y, p=None, return_ci=False, bootstrap_ci=False,\n",
    "                     n_bootstraps=1000, bootstrap_size=10000):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix, np.array, or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            return_ci (bool, optional): whether to return confidence intervals\n",
    "            bootstrap_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        te, yhat_cs, yhat_ts = self.fit_predict(X, treatment, y, return_components=True)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            _ate = te[:, i].mean()\n",
    "\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            y_filt = y[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "            prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "            yhat_c = yhat_cs[group][mask]\n",
    "            yhat_t = yhat_ts[group][mask]\n",
    "\n",
    "            se = np.sqrt((\n",
    "                (y_filt[w == 0] - yhat_c[w == 0]).var()\n",
    "                / (1 - prob_treatment) +\n",
    "                (y_filt[w == 1] - yhat_t[w == 1]).var()\n",
    "                / prob_treatment +\n",
    "                (yhat_t - yhat_c).var()\n",
    "            ) / y_filt.shape[0])\n",
    "\n",
    "            _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "            _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "            ate[i] = _ate\n",
    "            ate_lb[i] = _ate_lb\n",
    "            ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not return_ci:\n",
    "            return ate\n",
    "        elif return_ci and not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_global = deepcopy(self.models)\n",
    "\n",
    "            logger.info('Bootstrap Confidence Intervals for ATE')\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                ate_b = self.bootstrap(X, treatment, y, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = ate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1)\n",
    "            ate_upper = np.percentile(ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1)\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models = deepcopy(models_global)\n",
    "\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "\n",
    "class BaseSRegressor(BaseSLearner):\n",
    "    \"\"\"\n",
    "    A parent class for S-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner=None, ate_alpha=0.05, control_name=0):\n",
    "        \"\"\"Initialize an S-learner regressor.\n",
    "        Args:\n",
    "            learner (optional): a model to estimate the treatment effect\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name)\n",
    "\n",
    "\n",
    "class BaseSClassifier(BaseSLearner):\n",
    "    \"\"\"\n",
    "    A parent class for S-learner classifier classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learner=None, ate_alpha=0.05, control_name=0):\n",
    "        \"\"\"Initialize an S-learner classifier.\n",
    "        Args:\n",
    "            learner (optional): a model to estimate the treatment effect.\n",
    "                Should have a predict_proba() method.\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name)\n",
    "\n",
    "    def predict(self, X, treatment=None, y=None, p=None, return_components=False, verbose=True):\n",
    "        \"\"\"Predict treatment effects.\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        yhat_cs = {}\n",
    "        yhat_ts = {}\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            model = self.models[group]\n",
    "\n",
    "            # set the treatment column to zero (the control group)\n",
    "            X_new = np.hstack((np.zeros((X.shape[0], 1)), X))\n",
    "            yhat_cs[group] = model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "            # set the treatment column to one (the treatment group)\n",
    "            X_new[:, 0] = 1\n",
    "            yhat_ts[group] = model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "            if y is not None and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "                y_filt = y[mask]\n",
    "\n",
    "                yhat = np.zeros_like(y_filt, dtype=float)\n",
    "                yhat[w == 0] = yhat_cs[group][mask][w == 0]\n",
    "                yhat[w == 1] = yhat_ts[group][mask][w == 1]\n",
    "\n",
    "                logger.info('Error metrics for group {}'.format(group))\n",
    "                classification_metrics(y_filt, yhat, w)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            te[:, i] = yhat_ts[group] - yhat_cs[group]\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, yhat_cs, yhat_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00a_core.causalinference.ipynb.\n",
      "Converted 00b_core.causalbert.ipynb.\n",
      "Converted 01_autocoder.ipynb.\n",
      "Converted 02_analyzers.ipynb.\n",
      "Converted 03_key_driver_analysis.ipynb.\n",
      "Converted 04_preprocessing.ipynb.\n",
      "Converted 05a_meta.base.ipynb.\n",
      "Converted 05b_meta.tlearner.ipynb.\n",
      "Converted 05c_meta.slearner.ipynb.\n",
      "Converted 05d_meta.xlearner.ipynb.\n",
      "Converted 05e_meta.rlearner.ipynb.\n",
      "Converted 05f_meta.utils.ipynb.\n",
      "Converted 05g_meta.explainer.ipynb.\n",
      "Converted 05h_meta.propensity.ipynb.\n",
      "Converted 05i_meta.sensitivity.ipynb.\n",
      "Converted 99_examples.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
