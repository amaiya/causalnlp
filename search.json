[
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "from causalnlp import CausalInferenceModel\nfrom causalnlp import Autocoder",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "examples.html#what-is-the-causal-impact-of-a-positive-review-on-product-views",
    "href": "examples.html#what-is-the-causal-impact-of-a-positive-review-on-product-views",
    "title": "Examples",
    "section": "What is the causal impact of a positive review on product views?",
    "text": "What is the causal impact of a positive review on product views?\nWe use a semi-simulated dataset generated from this repo, which is available in the sample_data folder. The reviews and product types are real, while the outcomes (e.g., 1=product clicked, 0=not clicked) are simulated.\n\nimport pandas as pd\n\n\ndf = pd.read_csv('sample_data/music_seed50.tsv', sep='\\t', on_bad_lines='skip')\n\n\ndf.head()\n\n\n\n\n\n\n\n\nindex\nid\nrating\nproduct\ntext\nsummary\nprice\nT_true\nC_true\nY_sim\nnegative\npositive\nT_ac\n\n\n\n\n0\n7\n0001388703\n1.0\nmp3 music\nbuy the cd. do not buy the mp3 album. downlo...\nBuy the CD. Do not buy the MP3.\n13.01\n0\n0\n0\n0.548733\n0.451267\n0\n\n\n1\n8\n0001388703\n5.0\nmp3 music\ntakes me back to my childhood!\nLove it!\n13.01\n1\n0\n0\n0.008373\n0.991627\n1\n\n\n2\n12\n0001388703\n5.0\naudio cd\nthe passion and ingenuity of green's music is ...\nNo one like Keith Green\n13.01\n1\n1\n1\n0.043761\n0.956239\n1\n\n\n3\n13\n0001388703\n5.0\nmp3 music\nkeith's music is a timeless message. since hi...\nNever Gets Old\n13.01\n1\n0\n1\n0.038876\n0.961124\n1\n\n\n4\n15\n0001377647\n5.0\naudio cd\ni have fallen in love with john michael talbot...\nTalbot a masterpiece\n18.99\n1\n1\n1\n0.019828\n0.980172\n1\n\n\n\n\n\n\n\nY_sim is the simulated outcome indicating whether or not the product was clicked. C_true is a categorical variable, where 1 is an audio CD and and 0 is something else (e.g., MP3). In this dataset, outcomes were simulated such that C_true is a counfounding variable for this problem.\nThe treatment is whether or not the review is positive, which affects Y_sim. Let’s pretend we don’t have a rating and need to infer this from text using the Autocoder. This can be done with:\nac = Autocoder()\ndf = ac.code_sentiment(df['text'].values, df, batch_size=16, binarize=True)\ndf['T_ac'] = df['positive']\nWe’ve already created this as the T_ac column (along with the positive and negative columns), so invoking the above is not needed. Note that T_ac is an imperfect approximation of T_true. In CausalNLP, we can include the raw text as covariates to improve our estimates.\nLet’s fit the causal inference model. We will adjust for both C_true and the raw text of the review to minimize bias from confounding. CausalNLP supports the following metalearners: S-Learner, T-Learner, X-Learner, and R-Learner. See this paper for more information on these. We will use the T-Learner as the metalearner here. By default, T-Learners use LightGBM classifiers with 31 leaves. Let’s increase the number of leaves to 500. In practice, you can supply a learner with hyperparameters that you’ve tuned beforehand to accurately predict the outcome.\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\ncm = CausalInferenceModel(df, method='t-learner',\n                    learner=LGBMClassifier(num_leaves=500),\n                    treatment_col='T_ac', \n                    outcome_col='Y_sim', \n                    text_col='text',\n                    include_cols=['C_true'])\ncm.fit()\n\noutcome column (categorical): Y_sim\ntreatment column: T_ac\nnumerical/categorical covariates: ['C_true']\ntext covariate: text\npreprocess time:  1.118110179901123  sec\nstart fitting causal inference model\ntime to fit causal inference model:  10.667636632919312  sec\n\n\n&lt;causalnlp.causalinference.CausalInferenceModel&gt;\n\n\n\nAverage Treatment Effect (ATE)\nWe can calculate the overall average treatment effect (ATE) as follows:\n\ncm.estimate_ate()\n\n{'ate': 0.1309311542209525}\n\n\nThe overall ATE is an increase of 13 percentage points in probability.\nUnlike machine learning, there is no ground truth to which our estimate can be compared for causal inference on real-world datasets. Hoewver, since this is a simulated dataset, we can compare our estimate with the ground truth ATE of 0.1479 (14.79 percentage point change in outcome), and our estimate is close.\n\nfrom collections import defaultdict\nimport numpy as np\ndef ATE_adjusted(C, T, Y):\n    x = defaultdict(list)\n    for c, t, y in zip(C, T, Y):\n        x[c, t].append(y)\n\n    C0_ATE = np.mean(x[0,1]) - np.mean(x[0,0])\n    C1_ATE =  np.mean(x[1,1]) - np.mean(x[1,0])\n    return np.mean([C0_ATE, C1_ATE])\nprint(ATE_adjusted(df.C_true, df.T_true, df.Y_sim))\n\n0.14785542719890196\n\n\nSuch oracle estimates are not available for real-world datsets, as mentioned. For real-world scenarios, we can, at least, evaluate the robustness of the ATE estimate to various data manipuations (i.e., sensitivity analysis or refutation).\n\ncm.evaluate_robustness()\n\n\n\n\n\n\n\n\nMethod\nATE\nNew ATE\nNew ATE LB\nNew ATE UB\nDistance from Desired (should be near 0)\n\n\n\n\n0\nPlacebo Treatment\n0.130931\n0.00477642\n-0.00452705\n0.0140799\n0.00477642\n\n\n0\nRandom Cause\n0.130931\n0.131122\n0.122196\n0.140049\n0.000191267\n\n\n0\nSubset Data(sample size @0.8)\n0.130931\n0.129383\n0.117239\n0.141528\n-0.0015477\n\n\n0\nRandom Replace\n0.130931\n0.130196\n0.121209\n0.139184\n-0.000734766\n\n\n\n\n\n\n\nHere, we see the distance from the desired value is near zero for each sensitivy analysis method , which is good.\n\n\nConditional Average Treatment Effect (CATE)\nWe can also calculate the conditional average treatment effects (CATE). For instance, here is the treatment effect for those reviews that mention the word ``toddler.’’\n\nseries = df['text']\ncm.estimate_ate(df['text'].str.contains('toddler'))\n\n{'ate': 0.15559234254638685}\n\n\n\n\nIndividualized Treatment Effect (ITE)\nWe can easily predict the treatment effect for new or existing observations on a per-unit basis. We just need to make sure the DataFrame supplied as input to CausalInferenceModel.predict contains the right columns. This can easily be checked with CausalInferenceModel.get_required_columns:\n\ncm.get_required_columns()\n\n['T_ac', 'C_true', 'text']\n\n\n\ntest_df = pd.DataFrame({\n    'T_ac' : [1],\n    'C_true' : [1],\n    'text' : ['I love the music of Zamfir and his pan flute.']\n      })\n\n\ncm.predict(test_df)\n\narray([[0.40062776]])\n\n\n\n\nModel Interpetability\nWe can use the interpret method to identify the attributes most predictive of individualized treatment effects across observations. Features begnning with v_ are word (or vocabulary) features. We see that words like “music”, “cd”, and “love” in addition to the categorical attribute C_true (the known confounder which is 1 for audio CDs) are most predictive of individualized causal effects.\n\ncm.interpret(plot=False, method='feature_importance')[1][:10]\n\nv_music    0.079042\nv_cd       0.066838\nv_album    0.055168\nv_like     0.040784\nv_love     0.040635\nC_true     0.039949\nv_just     0.035671\nv_song     0.035362\nv_great    0.029918\nv_heard    0.028373\ndtype: float64\n\n\n\ncm.explain(test_df, row_num=0)\n\n\n\n\n\n\n\n\n\n\n\n## What is the causal impact of having a PhD on making over $50K?\n\nText is Optional in CausalNLP\n\nDespite the “NLP” in the name, CausalNLP can be used for causal analyses on traditional tabular datasets with no text fields.\nNote: This dataset is from the early to mid 1990s, and we are using it as a toy dataset for demonstration purposes only.\n\nimport pandas as pd\n\n\ndf = pd.read_csv('sample_data/adult-census.csv')\ndf = df.rename(columns=lambda x: x.strip())\ndf = df.applymap(lambda x: x.strip() if isinstance(x, str) else x) \nfilter_set = 'Doctorate'\ndf['treatment'] = df['education'].apply(lambda x: 1 if x in filter_set else 0)\ndf.head()\n\n\n\n\n\n\n\n\nage\nworkclass\nfnlwgt\neducation\neducation-num\nmarital-status\noccupation\nrelationship\nrace\nsex\ncapital-gain\ncapital-loss\nhours-per-week\nnative-country\nclass\ntreatment\n\n\n\n\n0\n25\nPrivate\n178478\nBachelors\n13\nNever-married\nTech-support\nOwn-child\nWhite\nFemale\n0\n0\n40\nUnited-States\n&lt;=50K\n0\n\n\n1\n23\nState-gov\n61743\n5th-6th\n3\nNever-married\nTransport-moving\nNot-in-family\nWhite\nMale\n0\n0\n35\nUnited-States\n&lt;=50K\n0\n\n\n2\n46\nPrivate\n376789\nHS-grad\n9\nNever-married\nOther-service\nNot-in-family\nWhite\nMale\n0\n0\n15\nUnited-States\n&lt;=50K\n0\n\n\n3\n55\n?\n200235\nHS-grad\n9\nMarried-civ-spouse\n?\nHusband\nWhite\nMale\n0\n0\n50\nUnited-States\n&gt;50K\n0\n\n\n4\n36\nPrivate\n224541\n7th-8th\n4\nMarried-civ-spouse\nHandlers-cleaners\nHusband\nWhite\nMale\n0\n0\n40\nEl-Salvador\n&lt;=50K\n0\n\n\n\n\n\n\n\n\nfrom causalnlp import CausalInferenceModel\ncm = CausalInferenceModel(df, method='t-learner',\n                   treatment_col='treatment', \n                   outcome_col='class',\n                   ignore_cols=['fnlwgt', 'education','education-num']).fit()\n\nreplaced ['&lt;=50K', '&gt;50K'] in column \"class\" with [0, 1]\noutcome column (categorical): class\ntreatment column: treatment\nnumerical/categorical covariates: ['age', 'workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\npreprocess time:  0.4857158660888672  sec\nstart fitting causal inference model\ntime to fit causal inference model:  5.035430908203125  sec\n\n\nOverall, the average treatment effect of having a PhD is an increase of 20 percentage points in the probability of making over $50K (with respect to this model and dataset):\n\ncm.estimate_ate()\n\n{'ate': 0.20340645077516034}\n\n\nFor those who have a Master’s degree:\n\ncm.estimate_ate(cm.df['education'] == 'Masters')\n\n{'ate': 0.17672418257642838}\n\n\nFor those who are high school dropouts:\n\ncm.estimate_ate(cm.df['education'].isin(['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '12th']))\n\n{'ate': 0.2586697863578173}\n\n\n## What is the causal impact of a job training program on earnings?\nThis is another example of causal inference on purely tabular data (no text). Here, we will use the famous LaLonde dataset from a job training study.\n\nimport pandas as pd\ndf = pd.read_csv('sample_data/lalonde.csv')\ndf.head()\n\n\n\n\n\n\n\n\nID\ntreat\nage\neduc\nblack\nhispan\nmarried\nnodegree\nre74\nre75\nre78\n\n\n\n\n0\nNSW1\n1\n37\n11\n1\n0\n1\n1\n0.0\n0.0\n9930.0460\n\n\n1\nNSW2\n1\n22\n9\n0\n1\n0\n1\n0.0\n0.0\n3595.8940\n\n\n2\nNSW3\n1\n30\n12\n1\n0\n0\n0\n0.0\n0.0\n24909.4500\n\n\n3\nNSW4\n1\n27\n11\n1\n0\n0\n1\n0.0\n0.0\n7506.1460\n\n\n4\nNSW5\n1\n33\n8\n1\n0\n0\n1\n0.0\n0.0\n289.7899\n\n\n\n\n\n\n\nUnlike other meta-learners that use LightGBM as a default, the S-Learner uses Linear Regression as the default base learner for regression problems, which is a model that is often used for this dataset. The ATE estimate is $1548, which indicates that the job training program had an overall positive effect.\n\nfrom causalnlp import CausalInferenceModel\ncm = CausalInferenceModel(df, method='s-learner',\n                   treatment_col='treat', \n                   outcome_col='re78',\n                   include_cols=['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75'])\ncm.fit()\nprint(cm.estimate_ate()) # ATE estimate = $1548\n\noutcome column (numerical): re78\ntreatment column: treat\nnumerical/categorical covariates: ['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75']\npreprocess time:  0.017691612243652344  sec\nstart fitting causal inference model\ntime to fit causal inference model:  0.0024728775024414062  sec\n{'ate': 1548.2438019996084}",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "preprocessing.html",
    "href": "preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "source\n\nDataframePreprocessor\n\n DataframePreprocessor (treatment_col='treatment', outcome_col='outcome',\n                        text_col=None, include_cols=[], ignore_cols=[],\n                        verbose=1)\n\nPreproceses a pandas DataFrame for causal inference\n\nsource\n\n\nDataframePreprocessor.preprocess\n\n DataframePreprocessor.preprocess (df, training=False, min_df=0.05,\n                                   max_df=0.5, ngram_range=(1, 1),\n                                   stop_words='english', na_cont_value=-1,\n                                   na_cat_value='MISSING')\n\nPreprocess a dataframe for causal inference.\n\nimport pandas as pd\n\n\ndf = pd.read_csv('sample_data/music_seed50.tsv', sep='\\t', on_bad_lines='skip')\n\n\npp = DataframePreprocessor(treatment_col='T_ac', outcome_col='Y_sim', \n                           text_col='text', include_cols=['C_true', 'product'])\n\n\ndf, X, Y, T = pp.preprocess(df, training=True)\n\noutcome column (categorical): Y_sim\ntreatment column: T_ac\nnumerical/categorical covariates: ['product', 'C_true']\ntext covariate: text\npreprocess time:  1.49556303024292  sec\n\n\n\nX.head()\n\n\n\n\n\n\n\n\nC_true\nproduct_audio cd\nproduct_mp3 music\nproduct_vinyl\nv_album\nv_albums\nv_band\nv_beautiful\nv_best\nv_better\nv_bought\nv_buy\nv_cd\nv_collection\nv_did\nv_don\nv_excellent\nv_fan\nv_favorite\nv_good\nv_got\nv_great\nv_hear\nv_heard\nv_just\nv_know\nv_like\nv_listen\nv_listening\nv_love\nv_music\nv_new\nv_old\nv_original\nv_really\nv_record\nv_recording\nv_rock\nv_song\nv_songs\nv_sound\nv_sounds\nv_think\nv_time\nv_track\nv_tracks\nv_ve\nv_voice\nv_way\nv_work\nv_years\n\n\n\n\n0\n0\n0\n1\n0\n0.25232\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.850798\n0.251679\n0.0\n0.0\n0.386181\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0\n0\n1\n0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n1\n1\n0\n0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.542250\n0.0\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.625138\n0.561398\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0\n0\n1\n0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.0\n0.629106\n0.000000\n0.0\n0.0\n0.000000\n0.777319\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n1\n1\n0\n0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000000\n0.000000\n0.0\n0.0\n0.000000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.527751\n0.0\n0.000000\n0.392572\n0.0\n0.0\n0.372982\n0.334952\n0.0\n0.0\n0.56219\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\ntest_df = pd.DataFrame({\n    'C_true' : [0, 1],\n    'product': ['vinyl', 'mp3 music'],\n     'text' : ['This record hurts my ears.', \"The music of Yanni is beautiful and breath-taking.\"],\n    'Y_sim' : [0, 1],\n     'T_ac' : [0, 1],\n      })\ntest_df.head()\n\n\n\n\n\n\n\n\nC_true\nproduct\ntext\nY_sim\nT_ac\n\n\n\n\n0\n0\nvinyl\nThis record hurts my ears.\n0\n0\n\n\n1\n1\nmp3 music\nThe music of Yanni is beautiful and breath-tak...\n1\n1\n\n\n\n\n\n\n\n\n_, X_test, _, _ = pp.preprocess(test_df, training=False)\n\n\nassert sum([X_test.columns.values[i] == col for i,col in enumerate(X.columns.values)]) == len(X.columns.values)\n\n\ntest_df = pd.DataFrame({\n    'product': ['vinyl', 'mp3 music'],\n     'text' : ['This record hurts my ears.', \"The music of Yanni is beautiful and breath-taking.\"],\n    'Y_sim' : [0, 1],\n     'T_ac' : [0, 1],\n      })\nerror = False\ntry: \n    _, X_test, _, _ = pp.preprocess(test_df, training=False)\nexcept ValueError:\n    error = True\nassert error is True",
    "crumbs": [
      "Preprocessing"
    ]
  },
  {
    "objectID": "analyzers.html",
    "href": "analyzers.html",
    "title": "Analyzers",
    "section": "",
    "text": "source\n\nlist2chunks\n\n list2chunks (a, n)\n\n\nsource\n\n\nZeroShotClassifier\n\n ZeroShotClassifier (model_name='facebook/bart-large-mnli', device=None)\n\nInterface to Zero Shot Topic Classifier\n\nsource\n\n\nZeroShotClassifier.predict\n\n ZeroShotClassifier.predict (docs, labels=[], include_labels=False,\n                             multilabel=True, max_length=512,\n                             batch_size=8, nli_template='This text is\n                             about {}.', topic_strings=[])\n\n*This method performs zero-shot text classification using Natural Language Inference (NLI).\nParameters: - docs(list|str): text of document or list of texts - labels(list): a list of strings representing topics of your choice Example: labels=[‘political science’, ‘sports’, ‘science’] - include_labels(bool): If True, will return topic labels along with topic probabilities - multilabel(bool): If True, labels are considered independent and multiple labels can predicted true for document and be close to 1. If False, scores are normalized such that probabilities sum to 1. - max_length(int): truncate long documents to this many tokens - batch_size(int): batch_size to use. default:8 Increase this value to speed up predictions - especially if len(topic_strings) is large. - nli_template(str): labels are inserted into this template for use as hypotheses in natural language inference - topic_strings(list): alias for labels parameter for backwards compatibility\nReturns:\ninferred probabilities or list of inferred probabilities if doc is list*\n\nzsl = ZeroShotClassifier()\nlabels=['politics', 'elections', 'sports', 'films', 'television']\ndoc = 'I am extremely dissatisfied with the President and will definitely vote in 2020.'\npreds = zsl.predict(doc, labels=labels, include_labels=True)\n\n\npreds\n\n[('politics', 0.9791897535324097),\n ('elections', 0.9874581098556519),\n ('sports', 0.0005765464738942683),\n ('films', 0.002292431192472577),\n ('television', 0.0010546175763010979)]\n\n\n\nd = dict(preds)\nassert d['politics'] &gt; 0.9\nassert d['elections'] &gt; 0.9\nassert d['sports'] &lt; 0.1\nassert d['films'] &lt; 0.1\nassert d['television'] &lt; 0.1\n\n\nsource\n\n\nTextEncoder\n\n TextEncoder (model_name='stsb-roberta-large', device=None)\n\nTiny wrapper to sentence-transformers\n\nte = TextEncoder()\n\n/home/amaiya/mambaforge/envs/pt/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\n\n\ne = te.encode('The moon is bright.')\n\n\nassert e.shape[0] == 1\nassert e.shape[1] == 1024\n\n\nsource\n\n\nTopicModel\n\n TopicModel (texts=None, n_topics=None, n_features=10000, min_df=5,\n             max_df=0.5, stop_words='english', model_type='lda',\n             lda_max_iter=5, lda_mode='online', token_pattern=None,\n             verbose=1, hyperparam_kwargs=None)\n\nFits a topic model to documents in . Example: tm = ktrain.text.get_topic_model(docs, n_topics=20, n_features=1000, min_df=2, max_df=0.95) Args: texts (list of str): list of texts n_topics (int): number of topics. If None, n_topics = min{400, sqrt[# documents/2]}) n_features (int): maximum words to consider max_df (float): words in more than max_df proportion of docs discarded stop_words (str or list): either ‘english’ for built-in stop words or a list of stop words to ignore model_type(str): type of topic model to fit. One of {‘lda’, ‘nmf’}. Default:‘lda’ lda_max_iter (int): maximum iterations for ‘lda’. 5 is default if using lda_mode=‘online’. If lda_mode=‘batch’, this should be increased (e.g., 1500). Ignored if model_type != ‘lda’ lda_mode (str): one of {‘online’, ‘batch’}. Ignored if model_type !=‘lda’ token_pattern(str): regex pattern to use to tokenize documents. verbose(bool): verbosity\n\nfrom sklearn.datasets import fetch_20newsgroups\n\n\n# we only want to keep the body of the documents!\nremove = ('headers', 'footers', 'quotes')\n\n# fetch train and test data\nnewsgroups_train = fetch_20newsgroups(subset='train', remove=remove)\nnewsgroups_test = fetch_20newsgroups(subset='test', remove=remove)\n\n# compile the texts\ntexts = newsgroups_train.data +  newsgroups_test.data\n\n# let's also store the newsgroup category associated with each document\n# we can display this information in visualizations\ntargets = [target for target in list(newsgroups_train.target) + list(newsgroups_test.target)]\ncategories = [newsgroups_train.target_names[target] for target in targets]\n\n\ntm = TopicModel(texts, n_features=10000)\n\nn_topics automatically set to 97\npreprocessing texts...\nfitting model...\niteration: 1 of max_iter: 5\niteration: 2 of max_iter: 5\niteration: 3 of max_iter: 5\niteration: 4 of max_iter: 5\niteration: 5 of max_iter: 5\ndone.\n\n\n\ntm.print_topics()\n\ntopic 0 | tape adam tim case moved bag quote mass marked zionism\ntopic 1 | image jpeg images format programs tiff files jfif save lossless\ntopic 2 | alternative movie film static cycles films philips dynamic hou phi\ntopic 3 | hell humans poster frank reality kent gerard gant eternal bell\ntopic 4 | air phd chz kit cbc ups w-s rus w47 mot\ntopic 5 | dog math great figure poster couldn don trying rushdie fatwa\ntopic 6 | collaboration nazi fact end expression germany philly world certified moore\ntopic 7 | gif points scale postscript mirror plane rendering algorithm polygon rayshade\ntopic 8 | fonts font shell converted iii characters slight composite breaks compress\ntopic 9 | power station supply options option led light tank plastic wall\ntopic 10 | transmission rider bmw driver automatic shift gear japanese stick highway\ntopic 11 | tyre ezekiel ruler hernia appeared appointed supreme man land power\ntopic 12 | space nasa earth data launch surface solar moon mission planet\ntopic 13 | israel jews jewish israeli arab peace war arabs palestinian kuwait\ntopic 14 | olvwm xremote animals kinds roughing toolkit close corp glenn imakefile\ntopic 15 | medical health disease cancer patients drug treatment drugs aids study\ntopic 16 | biden chip gear like information number automatic mode insurance know\ntopic 17 | graphics zip amiga shareware formats ftp gif program sgi convert\ntopic 18 | brilliant mail did god coming christianity people got ideas reading\ntopic 19 | black red white blue green cross wires lines helmet mask\ntopic 20 | car engine cars miles clutch new ford rear slip road\ntopic 21 | list mailing service model small large lists radar available major\ntopic 22 | key encryption chip keys clipper phone security use government privacy\ntopic 23 | talking pit nyr stl phi edm mtl wsh hfd cgy\ntopic 24 | signal input switch connected circuit audio noise output control voltage\ntopic 25 | stuff deleted die posting beware fantastic motives authentic reluctant hope\ntopic 26 | adams douglas dc-x garrett ingres tin sdio incremental mcdonnell guide\ntopic 27 | men homosexual homosexuality women gay sexual homosexuals male kinsey pop\ntopic 28 | usual leo rs-232 martian reading cooperative unmanned somalia decompress visited\ntopic 29 | edu university information send new computer research mail internet address\ntopic 30 | reserve naval marine ret commission one-way irgun prior closure facilities\ntopic 31 | state intelligence militia units army zone georgia sam croats belongs\ntopic 32 | says article pain known warning doctor stone bug kidney response\ntopic 33 | faq rsa ripem lights yes patent nist management wax cipher\ntopic 34 | wolverine comics hulk appearance special liefeld sabretooth incredible hobgoblin x-force\ntopic 35 | software ram worth cycles controller available make dram dynamic situation\ntopic 36 | religion people religious catalog bobby used driven involved long like\ntopic 37 | intel sites experiment ftp does know family good like mrs\ntopic 38 | armenian people army russian turkish genocide armenians ottoman turks jews\ntopic 39 | theft geo available face couldn cover sony people number shop\ntopic 40 | christianity did exists mail matter mind tool status god reading\ntopic 41 | propane probe earth orbit orbiter titan cassini space atmosphere gravity\ntopic 42 | people government right think rights law make public fbi don\ntopic 43 | god people does say believe bible true think evidence religion\ntopic 44 | mov phone south key war supply push left just registered\ntopic 45 | period goal pts play chicago pittsburgh buffalo shots new blues\ntopic 46 | game team games year hockey season players player baseball league\ntopic 47 | speed dod student technician just hits right note giant light\ntopic 48 | sex marriage relationship family married couple depression pregnancy childhood trademark\ntopic 49 | protects rejecting com4 couple decides taking connect unc nearest richer\ntopic 50 | president states united american national press april washington america white\ntopic 51 | card memory windows board ram bus drivers driver cpu problem\ntopic 52 | window application manager display button xterm path widget event resources\ntopic 53 | cable win van det bos tor cal nyi chi buf\ntopic 54 | americans baltimore rochester cape springfield moncton providence utica binghamton adirondack\ntopic 55 | color monitor screen mouse video colors resolution vga colour monitors\ntopic 56 | option power ssf flights capability module redesign missions station options\ntopic 57 | body father son vitamin diet day cells cell form literature\ntopic 58 | max g9v b8f a86 bhj giz bxn biz qax b4q\ntopic 59 | bit fast chip ibm faster mode chips scsi-2 speeds quadra\ntopic 60 | book books law adl islam islamic iran media bullock muslims\ntopic 61 | armenian russian turkish ottoman people army armenians genocide war turks\ntopic 62 | oscillator partition tune nun umumiye nezareti mecmuasi muharrerat-i evrak version\ntopic 63 | tongues seat est didn raise copied lazy schemes adapter leap\ntopic 64 | com object jim app function motorola heterosexual objects pointers encountered\ntopic 65 | effective boy projects grow jason ain dump keyboards vastly grants\ntopic 66 | armenian people russian armenians turks ottoman army turkish genocide muslim\ntopic 67 | mac apple pin ground wire quicktime macs pins connector simms\ntopic 68 | bastard turning likes hooks notions turks cited proud pointers chuck\ntopic 69 | bought dealer cost channel replaced face sony stereo warranty tube\ntopic 70 | myers food reaction msg writes loop eat dee effects taste\ntopic 71 | lander contradiction reconcile apparent somebody supplement essential needs produce insulin\ntopic 72 | re-boost systems virginia voice unix input ken easily summary developing\ntopic 73 | block tests suck shadow dte screws macedonia sunlight fin message\ntopic 74 | jesus church christ god lord holy spirit mary shall heaven\ntopic 75 | gun number year guns rate insurance police years new firearms\ntopic 76 | rule automatically characteristic wider thumb recommendation inline mr2 halfway width\ntopic 77 | drive disk hard scsi drives controller floppy ide master transfer\ntopic 78 | stephanopoulos water gas oil heat energy hot temperature cold nuclear\ntopic 79 | like know does use don just good thanks need want\ntopic 80 | starters mlb mov higher signing left accessible argument viola teams\ntopic 81 | entry rules info define entries year int printf include contest\ntopic 82 | price new sale offer sell condition shipping interested asking prices\ntopic 83 | issue germany title magazine german cover race generation origin nazi\ntopic 84 | armenian armenians people turkish war said killed children russian turkey\ntopic 85 | dos windows software comp library os/2 version microsoft applications code\ntopic 86 | probe space launch titan earth cassini orbiter orbit atmosphere mission\ntopic 87 | housed throws fills daylight occurring activities adjacent presenting punish occuring\ntopic 88 | statement folk raids thor disarmed anatolia polygon inria arrive smehlik\ntopic 89 | sound steve pro convert ati ultra fahrenheit orchid hercules blaster\ntopic 90 | joke tricky wearing golden trickle seen geneva csh course caesar\ntopic 91 | moral objective values morality child defined bank definition wrong different\ntopic 92 | files file edu ftp available version server data use sun\ntopic 93 | catalog tons seal ordering kawasaki tools fax free ultraviolet packages\ntopic 94 | file program error output use section line code command problem\ntopic 95 | power ssf module capability option flights redesign missions human station\ntopic 96 | just don think know like time did going didn people\n\n\n\ntm.build(texts)\n\ndone.\n\n\n\ntexts[1]\n\n\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\"\n\n\n\ntm.doc_topics[1]\n\narray([0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.05935853, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.04939132, 0.00105197,\n       0.00105197, 0.00105197, 0.04181867, 0.00105197, 0.00105197,\n       0.00105197, 0.21681858, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.02146013, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.0458702 , 0.02146013, 0.14892628,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.00105197, 0.00105197, 0.00105197,\n       0.00105197, 0.00105197, 0.13724779, 0.00105197, 0.00105197,\n       0.00105197, 0.16612722])\n\n\n\ntm.topics[ np.argmax(tm.doc_topics[1])]\n\n'card memory windows board ram bus drivers driver cpu problem'\n\n\n\ntm.predict(['Elon Musk leads Space Exploration Technologies (SpaceX), where he oversees '  +\n            'the development and manufacturing of advanced rockets and spacecraft for missions ' +\n            'to and beyond Earth orbit.'])\n\narray([[0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.65009096, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.06185567, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214, 0.00303214, 0.00303214, 0.00303214,\n        0.00303214, 0.00303214]])\n\n\n\ntm.topics[ np.argmax(tm.predict(['Elon Musk leads Space Exploration Technologies (SpaceX), where he oversees '  +\n            'the development and manufacturing of advanced rockets and spacecraft for missions ' +\n            'to and beyond Earth orbit.']))]\n\n'space nasa earth data launch surface solar moon mission planet'",
    "crumbs": [
      "Analyzers"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to CausalNLP",
    "section": "",
    "text": "CausalNLP is a practical toolkit for causal inference with text as treatment, outcome, or “controlled-for” variable.",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#what-is-causalnlp",
    "href": "index.html#what-is-causalnlp",
    "title": "Welcome to CausalNLP",
    "section": "",
    "text": "CausalNLP is a practical toolkit for causal inference with text as treatment, outcome, or “controlled-for” variable.",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Welcome to CausalNLP",
    "section": "Features",
    "text": "Features\n\nLow-code causal inference in as little as two commands\nOut-of-the-box support for using text as a “controlled-for” variable (e.g., confounder)\nBuilt-in Autocoder that transforms raw text into useful variables for causal analyses (e.g., topics, sentiment, emotion, etc.)\nSensitivity analysis to assess robustness of causal estimates\nQuick and simple key driver analysis to yield clues on potential drivers of an outcome based on predictive power, correlations, etc.\nCan easily be applied to “traditional” tabular datasets without text (i.e., datasets with only numerical and categorical variables)\nIncludes an experimental PyTorch implementation of CausalBert by Veitch, Sridar, and Blei (based on reference implementation by R. Pryzant)",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Welcome to CausalNLP",
    "section": "Install",
    "text": "Install\n\npip install -U pip\npip install causalnlp\n\nNOTE: On Python 3.6.x, if you get a RuntimeError: Python version &gt;= 3.7 required, try ensuring NumPy is installed before CausalNLP (e.g., pip install numpy==1.18.5).",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Welcome to CausalNLP",
    "section": "Usage",
    "text": "Usage\nTo try out the examples yourself:\n\n\nExample: What is the causal impact of a positive review on a product click?\n\nimport pandas as pd\n\n\ndf = pd.read_csv('sample_data/music_seed50.tsv', sep='\\t', on_bad_lines='skip')\n\nThe file music_seed50.tsv is a semi-simulated dataset from here. Columns of relevance include: - Y_sim: outcome, where 1 means product was clicked and 0 means not. - text: raw text of review - rating: rating associated with review (1 through 5) - T_true: 0 means rating less than 3, 1 means rating of 5, where T_true affects the outcome Y_sim. - T_ac: an approximation of true review sentiment (T_true) created with Autocoder from raw review text - C_true:confounding categorical variable (1=audio CD, 0=other)\nWe’ll pretend the true sentiment (i.e., review rating and T_true) is hidden and only use T_ac as the treatment variable.\nUsing the text_col parameter, we include the raw review text as another “controlled-for” variable.\n\nfrom causalnlp import CausalInferenceModel\nfrom lightgbm import LGBMClassifier\n\n\ncm = CausalInferenceModel(df, \n                         metalearner_type='t-learner', learner=LGBMClassifier(num_leaves=500),\n                         treatment_col='T_ac', outcome_col='Y_sim', text_col='text',\n                         include_cols=['C_true'])\ncm.fit()\n\noutcome column (categorical): Y_sim\ntreatment column: T_ac\nnumerical/categorical covariates: ['C_true']\ntext covariate: text\npreprocess time:  1.1179866790771484  sec\nstart fitting causal inference model\ntime to fit causal inference model:  10.361494302749634  sec\n\n\n\nEstimating Treatment Effects\nCausalNLP supports estimation of heterogeneous treatment effects (i.e., how causal impacts vary across observations, which could be documents, emails, posts, individuals, or organizations).\nWe will first calculate the overall average treatment effect (or ATE), which shows that a positive review increases the probability of a click by 13 percentage points in this dataset.\nAverage Treatment Effect (or ATE):\n\nprint( cm.estimate_ate() )\n\n{'ate': 0.1309311542209525}\n\n\nConditional Average Treatment Effect (or CATE): reviews that mention the word “toddler”:\n\nprint( cm.estimate_ate(df['text'].str.contains('toddler')) )\n\n{'ate': 0.15559234254638685}\n\n\nIndividualized Treatment Effects (or ITE):\n\ntest_df = pd.DataFrame({'T_ac' : [1], 'C_true' : [1], \n                        'text' : ['I never bought this album, but I love his music and will soon!']})\neffect = cm.predict(test_df)\nprint(effect)\n\n[[0.80538201]]\n\n\nModel Interpretability:\n\nprint( cm.interpret(plot=False)[1][:10] )\n\nv_music    0.079042\nv_cd       0.066838\nv_album    0.055168\nv_like     0.040784\nv_love     0.040635\nC_true     0.039949\nv_just     0.035671\nv_song     0.035362\nv_great    0.029918\nv_heard    0.028373\ndtype: float64\n\n\nFeatures with the v_ prefix are word features. C_true is the categorical variable indicating whether or not the product is a CD.\n\n\n\nText is Optional in CausalNLP\nDespite the “NLP” in CausalNLP, the library can be used for causal inference on data without text (e.g., only numerical and categorical variables). See the examples for more info.",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#documentation",
    "href": "index.html#documentation",
    "title": "Welcome to CausalNLP",
    "section": "Documentation",
    "text": "Documentation\nAPI documentation and additional usage examples are available at: https://amaiya.github.io/causalnlp/",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "Welcome to CausalNLP",
    "section": "How to Cite",
    "text": "How to Cite\nPlease cite the following paper when using CausalNLP in your work:\n@article{maiya2021causalnlp,\n    title={CausalNLP: A Practical Toolkit for Causal Inference with Text},\n    author={Arun S. Maiya},\n    year={2021},\n    eprint={2106.08043},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL},\n    journal={arXiv preprint arXiv:2106.08043},\n}",
    "crumbs": [
      "Welcome to CausalNLP"
    ]
  },
  {
    "objectID": "meta.xlearner.html",
    "href": "meta.xlearner.html",
    "title": "X-Learner",
    "section": "",
    "text": "source\n\nBaseXClassifier\n\n BaseXClassifier (outcome_learner=None, effect_learner=None,\n                  control_outcome_learner=None,\n                  treatment_outcome_learner=None,\n                  control_effect_learner=None,\n                  treatment_effect_learner=None, ate_alpha=0.05,\n                  control_name=0)\n\nA parent class for X-learner classifier classes.\n\nsource\n\n\nBaseXRegressor\n\n BaseXRegressor (learner=None, control_outcome_learner=None,\n                 treatment_outcome_learner=None,\n                 control_effect_learner=None,\n                 treatment_effect_learner=None, ate_alpha=0.05,\n                 control_name=0)\n\nA parent class for X-learner regressor classes.\n\nsource\n\n\nBaseXLearner\n\n BaseXLearner (learner=None, control_outcome_learner=None,\n               treatment_outcome_learner=None,\n               control_effect_learner=None, treatment_effect_learner=None,\n               ate_alpha=0.05, control_name=0)\n\n*A parent class for X-learner regressor classes.\nAn X-learner estimates treatment effects with four machine learning models.\nDetails of X-learner are available at Kunzel et al. (2018) (https://arxiv.org/abs/1706.03461).*",
    "crumbs": [
      "X-Learner"
    ]
  },
  {
    "objectID": "meta.rlearner.html",
    "href": "meta.rlearner.html",
    "title": "R-Learner",
    "section": "",
    "text": "source\n\nXGBRRegressor\n\n XGBRRegressor (early_stopping=True, test_size=0.3,\n                early_stopping_rounds=30,\n                effect_learner_objective='rank:pairwise',\n                effect_learner_n_estimators=500, random_state=42, *args,\n                **kwargs)\n\nA parent class for R-learner regressor classes.\n\nsource\n\n\nBaseRClassifier\n\n BaseRClassifier (outcome_learner=None, effect_learner=None,\n                  propensity_learner=LogisticRegressionCV(Cs=array([1.0023\n                  0524, 2.15608891, 4.63802765, 9.97700064]),\n                  cv=StratifiedKFold(n_splits=4, random_state=42,\n                  shuffle=True),\n                  l1_ratios=array([0.001     , 0.33366667, 0.66633333,\n                  0.999     ]),                      penalty='elasticnet',\n                  random_state=42, solver='saga'), ate_alpha=0.05,\n                  control_name=0, n_fold=5, random_state=None)\n\nA parent class for R-learner classifier classes.\n\nsource\n\n\nBaseRRegressor\n\n BaseRRegressor (learner=None, outcome_learner=None, effect_learner=None,\n                 propensity_learner=LogisticRegressionCV(Cs=array([1.00230\n                 524, 2.15608891, 4.63802765, 9.97700064]),\n                 cv=StratifiedKFold(n_splits=4, random_state=42,\n                 shuffle=True),\n                 l1_ratios=array([0.001     , 0.33366667, 0.66633333,\n                 0.999     ]),                      penalty='elasticnet',\n                 random_state=42, solver='saga'), ate_alpha=0.05,\n                 control_name=0, n_fold=5, random_state=None)\n\nA parent class for R-learner regressor classes.\n\nsource\n\n\nBaseRLearner\n\n BaseRLearner (learner=None, outcome_learner=None, effect_learner=None,\n               propensity_learner=LogisticRegressionCV(Cs=array([1.0023052\n               4, 2.15608891, 4.63802765, 9.97700064]),\n               cv=StratifiedKFold(n_splits=4, random_state=42,\n               shuffle=True),                      l1_ratios=array([0.001\n               , 0.33366667, 0.66633333, 0.999     ]),\n               penalty='elasticnet', random_state=42, solver='saga'),\n               ate_alpha=0.05, control_name=0, n_fold=5,\n               random_state=None)\n\n*A parent class for R-learner classes.\nAn R-learner estimates treatment effects with two machine learning models and the propensity score.\nDetails of R-learner are available at Nie and Wager (2019) (https://arxiv.org/abs/1712.04912).*",
    "crumbs": [
      "R-Learner"
    ]
  },
  {
    "objectID": "meta.sensitivity.html",
    "href": "meta.sensitivity.html",
    "title": "Metalearner Sensitivity",
    "section": "",
    "text": "source\n\nSensitivitySelectionBias\n\n SensitivitySelectionBias (*args, confound='one_sided', alpha_range=None,\n                           sensitivity_features=None, **kwargs)\n\n*Reference:\n[1] Blackwell, Matthew. “A selection bias approach to sensitivity analysis for causal effects.” Political Analysis 22.2 (2014): 169-182. https://www.mattblackwell.org/files/papers/causalsens.pdf\n[2] Confouding parameter alpha_range using the same range as in: https://github.com/mattblackwell/causalsens/blob/master/R/causalsens.R*\n\nsource\n\n\nSensitivitySubsetData\n\n SensitivitySubsetData (*args, **kwargs)\n\nTakes a random subset of size sample_size of the data.\n\nsource\n\n\nSensitivityRandomReplace\n\n SensitivityRandomReplace (*args, **kwargs)\n\nReplaces a random covariate with an irrelevant variable.\n\nsource\n\n\nSensitivityRandomCause\n\n SensitivityRandomCause (*args, **kwargs)\n\nAdds an irrelevant random covariate to the dataframe.\n\nsource\n\n\nSensitivityPlaceboTreatment\n\n SensitivityPlaceboTreatment (*args, **kwargs)\n\nReplaces the treatment variable with a new variable randomly generated.\n\nsource\n\n\nSensitivity\n\n Sensitivity (df, inference_features, p_col, treatment_col, outcome_col,\n              learner, *args, **kwargs)\n\n*A Sensitivity Check class to support Placebo Treatment, Irrelevant Additional Confounder and Subset validation refutation methods to verify causal inference.\nReference: https://github.com/microsoft/dowhy/blob/master/dowhy/causal_refuters/*\n\nsource\n\n\nalignment_att\n\n alignment_att (alpha, p, treatment)\n\n*Alignment confounding function for the average effect of the treatment among the treated units (ATT)\nReference: Blackwell, Matthew. “A selection bias approach to sensitivity analysis for causal effects.” Political Analysis 22.2 (2014): 169-182. https://www.mattblackwell.org/files/papers/causalsens.pdf\nArgs: alpha (np.array): a confounding values vector p (np.array): a propensity score vector between 0 and 1 treatment (np.array): a treatment vector (1 if treated, otherwise 0)*\n\nsource\n\n\none_sided_att\n\n one_sided_att (alpha, p, treatment)\n\n*One sided confounding function for the average effect of the treatment among the treated units (ATT)\nReference: Blackwell, Matthew. “A selection bias approach to sensitivity analysis for causal effects.” Political Analysis 22.2 (2014): 169-182. https://www.mattblackwell.org/files/papers/causalsens.pdf\nArgs: alpha (np.array): a confounding values vector p (np.array): a propensity score vector between 0 and 1 treatment (np.array): a treatment vector (1 if treated, otherwise 0)*\n\nsource\n\n\nalignment\n\n alignment (alpha, p, treatment)\n\n*Alignment confounding function. Reference: Blackwell, Matthew. “A selection bias approach to sensitivity analysis for causal effects.” Political Analysis 22.2 (2014): 169-182. https://www.mattblackwell.org/files/papers/causalsens.pdf\nArgs: alpha (np.array): a confounding values vector p (np.array): a propensity score vector between 0 and 1 treatment (np.array): a treatment vector (1 if treated, otherwise 0)*\n\nsource\n\n\none_sided\n\n one_sided (alpha, p, treatment)\n\n*One sided confounding function. Reference: Blackwell, Matthew. “A selection bias approach to sensitivity analysis for causal effects.” Political Analysis 22.2 (2014): 169-182. https://www.mattblackwell.org/files/papers/causalsens.pdf\nArgs: alpha (np.array): a confounding values vector p (np.array): a propensity score vector between 0 and 1 treatment (np.array): a treatment vector (1 if treated, otherwise 0)*",
    "crumbs": [
      "Metalearner Sensitivity"
    ]
  },
  {
    "objectID": "core.causalinference.html",
    "href": "core.causalinference.html",
    "title": "Causal Inference",
    "section": "",
    "text": "source",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "core.causalinference.html#usage-example-do-social-media-posts-by-women-get-shared-more-often-than-those-by-men",
    "href": "core.causalinference.html#usage-example-do-social-media-posts-by-women-get-shared-more-often-than-those-by-men",
    "title": "Causal Inference",
    "section": "Usage Example: Do social media posts by women get shared more often than those by men?",
    "text": "Usage Example: Do social media posts by women get shared more often than those by men?\nLet’s create a simulated dataset.\n\nimport itertools\nimport pandas as pd\n\n\ndata = ((*a, b) for (a, b) in zip(itertools.product([0,1], [0,1], [0,1]), [36, 234, 25, 55, 6, 81, 71, 192]))\ndf = pd.DataFrame(data, columns=['Is_Male?', 'Post_Text', 'Post_Shared?', 'N'])\ndf = df.loc[df.index.repeat(df['N'])].reset_index(drop=True).drop(columns=['N'])\nvalues = sorted(df['Post_Text'].unique())\ndf['Post_Text'].replace(values, ['I really love my job!', 'My boss is pretty terrible.'], inplace=True)\noriginal_df = df.copy()\ndf = None\noriginal_df.head()\n\n\n\n\n\n\n\n\nIs_Male?\nPost_Text\nPost_Shared?\n\n\n\n\n0\n0\nI really love my job!\n0\n\n\n1\n0\nI really love my job!\n0\n\n\n2\n0\nI really love my job!\n0\n\n\n3\n0\nI really love my job!\n0\n\n\n4\n0\nI really love my job!\n0\n\n\n\n\n\n\n\nAt first glance, it seems like posts by women get shared more often. More specifically, it appears that being male reduces your the chance your post is shared by 4.5 percentage points:\n\nmale_probability = original_df[(original_df['Is_Male?']==1)]['Post_Shared?'].value_counts(normalize=True)[1]\nmale_probability\n\n0.78\n\n\n\nfemale_probability = original_df[(original_df['Is_Male?']==0)]['Post_Shared?'].value_counts(normalize=True)[1]\nfemale_probability\n\n0.8257142857142857\n\n\n\nmale_probability-female_probability\n\n-0.04571428571428571\n\n\nHowever, this is inaccurate. In fact, this is an example of Simpson’s Paradox, and the true causal effect of being male in this simulated datsaet is roughly 0.05 (as opposed to -0.045) with men’s posts being more likely to be shared. The reason is that women in this simulation tend to make more positive posts which tend to be shared more often here. Post sentiment, then, is a [mediator](https://en.wikipedia.org/wiki/Mediation_(statistics), which is statistically statistically similar to a confounder.\nWhen controlling for the sentiment of the post (the mediator variable in this dataset), it is revealed that men’s posts are, in fact, shared more often (for both negative posts and positive posts). This can be quickly and easily estimated in CausalNLP.\n\nCausal Inference from Text with Autocoders\nLet’s first use the Autocoder to transform the raw text into sentiment. We can then control for sentiment when estimating the causal effect.\n\nfrom causalnlp.autocoder import Autocoder\n\n\nac = Autocoder()\n\n\n\n\n\ndf = ac.code_sentiment(original_df['Post_Text'].values, original_df, binarize=False, batch_size=16)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nIs_Male?\nPost_Text\nPost_Shared?\nnegative\npositive\n\n\n\n\n0\n0\nI really love my job!\n0\n0.019191\n0.980809\n\n\n1\n0\nI really love my job!\n0\n0.019191\n0.980809\n\n\n2\n0\nI really love my job!\n0\n0.019191\n0.980809\n\n\n3\n0\nI really love my job!\n0\n0.019191\n0.980809\n\n\n4\n0\nI really love my job!\n0\n0.019191\n0.980809\n\n\n\n\n\n\n\nWhen autocoding the raw text for sentiment, we have chosen to use the raw “probabilities” with binarize=False. A binary variable can also be used with binarize=True.\nNext, let’s estimate the treatment effects. We will ignore the positive and Post_Shared? columns, as their information is captured by the negative column in this example. We will use the T-Learner. See this paper for more information on metalearner types.\n\nfrom causalnlp import CausalInferenceModel\n\n\ncm = CausalInferenceModel(df, method='t-learner',\n                          treatment_col='Is_Male?', outcome_col='Post_Shared?',\n                          include_cols=['negative'])\ncm.fit()\n\noutcome column (categorical): Post_Shared?\ntreatment column: Is_Male?\nnumerical/categorical covariates: ['negative']\npreprocess time:  0.013550996780395508  sec\nstart fitting causal inference model\ntime to fit causal inference model:  0.8901166915893555  sec\n\n\n&lt;causalnlp.core.causalinference.CausalInferenceModel&gt;\n\n\nUpon controlling for sentiment, we see that the overall average treatment is correctly estimated as 0.05.\n\nate = cm.estimate_ate()\nate\n\n{'ate': 0.05366850622769351}\n\n\nSince this is a small, simulated, toy problem, we can manually calculate the adjusted treatment effect by controlling for the single counfounder (i.e., post negativity):\n\nfrom collections import defaultdict\n\n\ndef ATE_adjusted(C, T, Y):\n    x = defaultdict(list)\n    for c, t, y in zip(C, T, Y):\n        x[c, t].append(y)\n\n    C0_ATE = np.mean(x[0,1]) - np.mean(x[0,0])\n    C1_ATE = np.mean(x[1,1]) - np.mean(x[1,0])\n    return np.mean([C0_ATE, C1_ATE])\nATE_adjusted((df['negative']&gt;0.5).astype('int'), df['Is_Male?'].values, df['Post_Shared?'].values)\n\n0.0534529194528211\n\n\nWe see that this value is close to our estimate.\nCausalNLP allows you to easily compute conditional or individualized treatment effects. For instance, for negative posts, being male increases the chance of your post being shared by about 4 percentage points:\n\ncm.estimate_ate(cm.df['negative']&gt;0.9)\n\n{'ate': 0.042535751074149745}\n\n\nFor positive posts, being male increases the chance of your post being shared by about 6 percentage points:\n\ncm.estimate_ate(cm.df['negative']&lt;0.1)\n\n{'ate': 0.06436468274776497}\n\n\n\nassert ate['ate'] &gt; 0.05\nassert ate['ate'] &lt; 0.055\n\nPredictions can be made for new observations. We just have to make sure it contains the relevant columns included in the DataFrame supplied to CausalInferenceModel.fit. In this case, it must include Is_Male? and negative. This can be verified with the CausalInferenceModel.get_required_columns method:\n\ncm.get_required_columns()\n\n['Is_Male?', 'negative']\n\n\n\ntest_df = pd.DataFrame({\n     'text' : ['I love my life.'],\n    'Is_Male?' : [0],\n    'negative' : [0]\n      })\neffect = cm.predict(test_df)\nassert effect[0][0] &lt; 0.065\nassert effect[0][0] &gt; 0.064\nprint(effect)\n\n[[0.06436468]]\n\n\n\n\nCausal Inference Using Raw Text as a Confounder/Mediator\nIn the example above, we approached the problem under the assumption that a specific lingustic property (sentiment) was an important mediator or confounder for which to control. In some cases, there may also be other unknown lingustic properties that are potential confounders/mediators (e.g., topic, politeness, toxic language, readability).\nIn CausalNLP, we can also use the raw text as the potential confounder/mediator.\n\ncm = CausalInferenceModel(df, method='t-learner',\n                          treatment_col='Is_Male?', outcome_col='Post_Shared?', text_col='Post_Text',\n                         ignore_cols=['negative', 'positive'])\ncm.fit()\n\noutcome column (categorical): Post_Shared?\ntreatment column: Is_Male?\nnumerical/categorical covariates: []\ntext covariate: Post_Text\npreprocess time:  0.015369415283203125  sec\nstart fitting causal inference model\ntime to fit causal inference model:  0.5458502769470215  sec\n\n\n&lt;causalnlp.core.causalinference.CausalInferenceModel&gt;\n\n\nAlthough we have excluded the negative and positive columns as extra covariates, you can use traditional categorical/numerical covariates in combination with a text field covariate (if they exist as extra columns in the dataframe).\nHere, we see that the same causal estimates are returned, as the text is easy to infer as positive or negative based on their correlations with the outcomes in this problem.\n\nate = cm.estimate_ate()\nate\n\n{'ate': 0.05366850622769351}\n\n\n\ncm.estimate_ate(df['Post_Text'] == 'My boss is pretty terrible.')\n\n{'ate': 0.042535751074149745}\n\n\n\ncm.estimate_ate(df['Post_Text'] == 'I really love my job!')\n\n{'ate': 0.06436468274776497}\n\n\n\nassert ate['ate'] &gt; 0.05\nassert ate['ate'] &lt; 0.055\n\nMake predictions on new data.  Again, make sure the DataFrame contains the relevant columns included in the original DataFrame supplied to `CausalInferenceModel.fit`:\n\ncm.get_required_columns()\n\n['Is_Male?', 'Post_Text']\n\n\n\ntest_df = pd.DataFrame({\n     'Post_Text' : ['I love my life.'],\n    'New Column' : [1],\n    'Is_Male?' : [0],\n    'negative' : [0]\n      })\neffect = cm.predict(test_df)\nassert effect[0][0] &lt; 0.065\nassert effect[0][0] &gt; 0.064\nprint(effect)\n\n[[0.06436468]]\n\n\n\ncm.interpret(plot=False, method='feature_importance')\n\n{1: v_boss        1.0\n v_terrible    0.0\n v_pretty      0.0\n dtype: float64}\n\n\n\ncm.interpret(plot=True, method='feature_importance')\n\n\n\n\n\n\n\n\n\ncm.interpret(plot=True, method='shap_values')\n\n\n\n\n\n\n\n\n\n\nCausal Inference With Text as a Treatment\nSuppose we were interested in estimating the causal impact of sentiment on the outcome. That is, sentiment of text is the treatment, and the gender is a potential confounder. As we did above, we can use the Autocoder to create the treatment variable. The only difference is that we would supply the binarize=True as an argument.\n\ndf = ac.code_sentiment(original_df['Post_Text'].values, original_df, binarize=True, batch_size=16)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nIs_Male?\nPost_Text\nPost_Shared?\nnegative\npositive\n\n\n\n\n0\n0\nI really love my job!\n0\n0\n1\n\n\n1\n0\nI really love my job!\n0\n0\n1\n\n\n2\n0\nI really love my job!\n0\n0\n1\n\n\n3\n0\nI really love my job!\n0\n0\n1\n\n\n4\n0\nI really love my job!\n0\n0\n1\n\n\n\n\n\n\n\n\ncm = CausalInferenceModel(df, method='t-learner',\n                          treatment_col='positive', outcome_col='Post_Shared?',\n                          include_cols=['Is_Male?'])\ncm.fit()\n\noutcome column (categorical): Post_Shared?\ntreatment column: positive\nnumerical/categorical covariates: ['Is_Male?']\npreprocess time:  0.008125543594360352  sec\nstart fitting causal inference model\ntime to fit causal inference model:  0.5112130641937256  sec\n\n\n&lt;causalnlp.core.causalinference.CausalInferenceModel&gt;\n\n\n\nate = cm.estimate_ate()\nate\n\n{'ate': 0.19008080596986368}\n\n\n\nassert ate['ate'] &gt; 0.18\nassert ate['ate'] &lt; 0.2\n\n\ncm.get_required_columns()\n\n['positive', 'Is_Male?']\n\n\n\ntest_df = pd.DataFrame({\n    'Is_Male?' : [1],\n    'positive' : [1]\n      })\neffect = cm.predict(test_df)\nprint(effect)\n\n[[0.20099539]]",
    "crumbs": [
      "Causal Inference"
    ]
  },
  {
    "objectID": "meta.base.html",
    "href": "meta.base.html",
    "title": "Base Metalearner",
    "section": "",
    "text": "source\n\nBaseLearner\n\n BaseLearner ()\n\nInitialize self. See help(type(self)) for accurate signature.",
    "crumbs": [
      "Base Metalearner"
    ]
  },
  {
    "objectID": "meta.slearner.html",
    "href": "meta.slearner.html",
    "title": "S-Learner",
    "section": "",
    "text": "source\n\nBaseSClassifier\n\n BaseSClassifier (learner=None, ate_alpha=0.05, control_name=0)\n\nA parent class for S-learner classifier classes.\n\nsource\n\n\nBaseSRegressor\n\n BaseSRegressor (learner=None, ate_alpha=0.05, control_name=0)\n\nA parent class for S-learner regressor classes.\n\nsource\n\n\nBaseSLearner\n\n BaseSLearner (learner=None, ate_alpha=0.05, control_name=0)\n\nA parent class for S-learner classes. An S-learner estimates treatment effects with one machine learning model. Details of S-learner are available at Kunzel et al. (2018) (https://arxiv.org/abs/1706.03461).",
    "crumbs": [
      "S-Learner"
    ]
  },
  {
    "objectID": "key_driver_analysis.html",
    "href": "key_driver_analysis.html",
    "title": "Key Driver Analysis",
    "section": "",
    "text": "source\n\nKeyDriverAnalysis\n\n KeyDriverAnalysis (df, outcome_col='outcome', text_col=None,\n                    include_cols=[], ignore_cols=[], verbose=1)\n\nPerforms key driver analysis\n\nsource\n\n\nKeyDriverAnalysis.correlations\n\n KeyDriverAnalysis.correlations (outcome_only=True)\n\nComputes corelations between independent variables and outcome\n\nimport pandas as pd\nfrom causalnlp.key_driver_analysis import KeyDriverAnalysis\n\n\ndf = pd.read_csv('sample_data/houses.csv')\n\n\nkda = KeyDriverAnalysis(df, outcome_col='SalePrice', ignore_cols=['Id', 'YearSold'])\n\noutcome column (numerical): SalePrice\ntreatment column: CausalNLP_temp_treatment\nnumerical/categorical covariates: ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\npreprocess time:  0.3556947708129883  sec\n\n\n\ndf_results = kda.correlations()\ndf_results.head()\n\n\n\n\n\n\n\n\nSalePrice\n\n\n\n\nOverallQual\n0.790982\n\n\nGrLivArea\n0.708624\n\n\nGarageCars\n0.640409\n\n\nGarageArea\n0.623431\n\n\nTotalBsmtSF\n0.613581\n\n\n\n\n\n\n\n\nassert df_results.iloc[[0]].index.values[0] == 'OverallQual'\n\n\nsource\n\n\nKeyDriverAnalysis.importances\n\n KeyDriverAnalysis.importances (plot=True, split_pct=0.2, use_shap=False,\n                                shap_background_size=50, rf_model=None,\n                                n_estimators=100, n_jobs=-1,\n                                random_state=42)\n\nIdentifies important predictors using a RandomForest model.\n\nExample: Variable Importances for Housing Prices\n\ndf_results = kda.importances()\ndf_results.head()\n\nR^2 Training Score: 0.98 \nOOB Score: 0.85 \nR^2 Validation Score: 0.89\n\n\n\n\n\n\n\n\n\nDriver\nImportance\n\n\n\n\n3\nOverallQual\n0.557707\n\n\n15\nGrLivArea\n0.121145\n\n\n11\nTotalBsmtSF\n0.035977\n\n\n13\n2ndFlrSF\n0.033758\n\n\n8\nBsmtFinSF1\n0.028563\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample: Variable Importances for Probability of Making Over $50K\n\nimport pandas as pd\n\n\ndf = pd.read_csv('sample_data/adult-census.csv')\nkda = KeyDriverAnalysis(df, outcome_col='class', ignore_cols=['fnlwgt'])\ndf_results = kda.importances(use_shap=True, plot=True)\ndf_results.head()\n\nreplaced ['&lt;=50K', '&gt;50K'] in column \"class\" with [0, 1]\noutcome column (categorical): class\ntreatment column: CausalNLP_temp_treatment\nnumerical/categorical covariates: ['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\npreprocess time:  0.5094420909881592  sec\nR^2 Training Score: 0.98 \nOOB Score: 0.85 \nR^2 Validation Score: 0.85\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDriver\nImportance\n\n\n\n\n2\ncapital-gain\n0.102854\n\n\n0\nage\n0.036508\n\n\n1\neducation-num\n0.035481\n\n\n32\nmarital-status_Married-civ-spouse\n0.031246\n\n\n52\nrelationship_Husband\n0.028451",
    "crumbs": [
      "Key Driver Analysis"
    ]
  },
  {
    "objectID": "meta.utils.html",
    "href": "meta.utils.html",
    "title": "Metalearner Utils",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Args\n  else: warn(msg)\n\nsource\n\nget_xgboost_objective_metric\n\n get_xgboost_objective_metric (objective)\n\nGet the xgboost version-compatible objective and evaluation metric from a potentially version-incompatible input.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nobjective\n\n\n\n\nReturns\nA tuple with the translated objective and evaluation metric.\n\n\n\n\n\nsource\n\n\nclean_xgboost_objective\n\n clean_xgboost_objective (objective)\n\nTranslate objective to be compatible with loaded xgboost version\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nobjective\n\n\n\n\nReturns\nThe translated objective, or original if no translation was required.\n\n\n\n\n\nsource\n\n\ncheck_explain_conditions\n\n check_explain_conditions (method, models, X=None, treatment=None, y=None)\n\n\nsource\n\n\ncheck_p_conditions\n\n check_p_conditions (p, t_groups)\n\n\nsource\n\n\ncheck_treatment_vector\n\n check_treatment_vector (treatment, control_name=None)\n\n\nsource\n\n\nconvert_pd_to_np\n\n convert_pd_to_np (*args)\n\n\nsource\n\n\nregression_metrics\n\n regression_metrics (y, p, w=None, metrics={'RMSE': &lt;function rmse at\n                     0x7f41ad79dcf0&gt;, 'sMAPE': &lt;function smape at\n                     0x7f41ad79dd80&gt;, 'Gini': &lt;function gini at\n                     0x7f41ad79f250&gt;})\n\n*Log metrics for regressors.\nArgs: y (numpy.array): target p (numpy.array): prediction w (numpy.array, optional): a treatment vector (1 or True: treatment, 0 or False: control). If given, log metrics for the treatment and control group separately metrics (dict, optional): a dictionary of the metric names and functions*\n\nsource\n\n\ngini\n\n gini (y, p)\n\n*Normalized Gini Coefficient.\nArgs: y (numpy.array): target p (numpy.array): prediction\nReturns: e (numpy.float64): normalized Gini coefficient*\n\nsource\n\n\nrmse\n\n rmse (y, p)\n\n*Root Mean Squared Error (RMSE). Args: y (numpy.array): target p (numpy.array): prediction\nReturns: e (numpy.float64): RMSE*\n\nsource\n\n\nsmape\n\n smape (y, p)\n\n*Symmetric Mean Absolute Percentage Error (sMAPE). Args: y (numpy.array): target p (numpy.array): prediction\nReturns: e (numpy.float64): sMAPE*\n\nsource\n\n\nmape\n\n mape (y, p)\n\n*Mean Absolute Percentage Error (MAPE). Args: y (numpy.array): target p (numpy.array): prediction\nReturns: e (numpy.float64): MAPE*\n\nsource\n\n\nape\n\n ape (y, p)\n\n*Absolute Percentage Error (APE). Args: y (float): target p (float): prediction\nReturns: e (float): APE*\n\nsource\n\n\nclassification_metrics\n\n classification_metrics (y, p, w=None, metrics={'AUC': &lt;function\n                         roc_auc_score at 0x7f41ca9ca320&gt;, 'Log Loss':\n                         &lt;function logloss at 0x7f41ad79f9a0&gt;})\n\n*Log metrics for classifiers.\nArgs: y (numpy.array): target p (numpy.array): prediction w (numpy.array, optional): a treatment vector (1 or True: treatment, 0 or False: control). If given, log metrics for the treatment and control group separately metrics (dict, optional): a dictionary of the metric names and functions*\n\nsource\n\n\nlogloss\n\n logloss (y, p)\n\nBounded log loss error. Args: y (numpy.array): target p (numpy.array): prediction Returns: bounded log loss error\n\nsource\n\n\nMatchOptimizer\n\n MatchOptimizer (treatment_col='is_treatment', ps_col='pihat',\n                 user_col=None, matching_covariates=['pihat'],\n                 max_smd=0.1, max_deviation=0.1, caliper_range=(0.01,\n                 0.5), max_pihat_range=(0.95, 0.999),\n                 max_iter_per_param=5, min_users_per_group=1000,\n                 smd_cols=['pihat'], dev_cols_transformations={'pihat':\n                 &lt;function mean at 0x7f41e7727db0&gt;}, dev_factor=1.0,\n                 verbose=True)\n\n*Finds the set of parameters that gives the best matching result.\nScore = (number of features with SMD &gt; max_smd) + (sum of deviations for important variables * deviation factor)\nThe logic behind the scoring is that we are most concerned with minimizing the number of features where SMD is lower than a certain threshold (max_smd). However, we would also like the matched dataset not deviate too much from the original dataset, in terms of key variable(s), so that we still retain a similar userbase.\nArgs: - treatment_col (str): name of the treatment column - ps_col (str): name of the propensity score column - max_smd (float): maximum acceptable SMD - max_deviation (float): maximum acceptable deviation for important variables - caliper_range (tuple): low and high bounds for caliper search range - max_pihat_range (tuple): low and high bounds for max pihat search range - max_iter_per_param (int): maximum number of search values per parameters - min_users_per_group (int): minimum number of users per group in matched set - smd_cols (list): score is more sensitive to these features exceeding max_smd - dev_factor (float): importance weight factor for dev_cols (e.g. dev_factor=1 means a 10% deviation leads to penalty of 1 in score) - dev_cols_transformations (dict): dict of transformations to be made on dev_cols - verbose (bool): boolean flag for printing statements\nReturns: The best matched dataset (pd.DataFrame)*\n\nsource\n\n\nNearestNeighborMatch\n\n NearestNeighborMatch (caliper=0.2, replace=False, ratio=1, shuffle=True,\n                       random_state=None)\n\n*Propensity score matching based on the nearest neighbor algorithm.\nAttributes: caliper (float): threshold to be considered as a match. replace (bool): whether to match with replacement or not ratio (int): ratio of control / treatment to be matched. used only if replace=True. shuffle (bool): whether to shuffle the treatment group data before matching random_state (numpy.random.RandomState or int): RandomState or an int seed*\n\nsource\n\n\ncreate_table_one\n\n create_table_one (data, treatment_col, features)\n\n*Report balance in input features between the treatment and control groups.\nReferences: R’s tableone at CRAN: https://github.com/kaz-yos/tableone Python’s tableone at PyPi: https://github.com/tompollard/tableone\nArgs: data (pandas.DataFrame): total or matched sample data treatment_col (str): the column name for the treatment features (list of str): the column names of features\nReturns: (pandas.DataFrame): A table with the means and standard deviations in the treatment and control groups, and the SMD between two groups for the features.*\n\nsource\n\n\nsmd\n\n smd (feature, treatment)\n\n*Calculate the standard mean difference (SMD) of a feature between the treatment and control groups.\nThe definition is available at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3144483/#s11title\nArgs: feature (pandas.Series): a column of a feature to calculate SMD for treatment (pandas.Series): a column that indicate whether a row is in the treatment group or not\nReturns: (float): The SMD of the feature*",
    "crumbs": [
      "Metalearner Utils"
    ]
  },
  {
    "objectID": "meta.propensity.html",
    "href": "meta.propensity.html",
    "title": "Metalearner Propensity",
    "section": "",
    "text": "source\n\ncompute_propensity_score\n\n compute_propensity_score (X, treatment, p_model=None, X_pred=None,\n                           treatment_pred=None, calibrate_p=True)\n\n*Generate propensity score if user didn’t provide\nArgs: X (np.matrix): features for training treatment (np.array or pd.Series): a treatment vector for training p_model (propensity model object, optional): ElasticNetPropensityModel (default) / GradientBoostedPropensityModel X_pred (np.matrix, optional): features for prediction treatment_pred (np.array or pd.Series, optional): a treatment vector for prediciton calibrate_p (bool, optional): whether calibrate the propensity score\nReturns: (tuple) - p (numpy.ndarray): propensity score - p_model (PropensityModel): a trained PropensityModel object*\n\nsource\n\n\ncalibrate\n\n calibrate (ps, treatment)\n\n*Calibrate propensity scores with logistic GAM.\nRef: https://pygam.readthedocs.io/en/latest/api/logisticgam.html\nArgs: ps (numpy.array): a propensity score vector treatment (numpy.array): a binary treatment vector (0: control, 1: treated)\nReturns: (numpy.array): a calibrated propensity score vector*\n\nsource\n\n\nGradientBoostedPropensityModel\n\n GradientBoostedPropensityModel (early_stop=False, clip_bounds=(0.001,\n                                 0.999), **model_kwargs)\n\nGradient boosted propensity score model with optional early stopping.\n\nsource\n\n\nElasticNetPropensityModel\n\n ElasticNetPropensityModel (clip_bounds=(0.001, 0.999), **model_kwargs)\n\nPropensity regression model based on the LogisticRegression algorithm.\n\nsource\n\n\nSimplePropensityModel\n\n SimplePropensityModel (clip_bounds=(0.001, 0.999), **model_kwargs)\n\nPropensity regression model based on the LogisticRegression algorithm.\n\nsource\n\n\nLogisticRegressionPropensityModel\n\n LogisticRegressionPropensityModel (clip_bounds=(0.001, 0.999),\n                                    **model_kwargs)\n\nPropensity regression model based on the LogisticRegression algorithm.\n\nsource\n\n\nPropensityModel\n\n PropensityModel (clip_bounds=(0.001, 0.999), **model_kwargs)\n\nArgs: clip_bounds (tuple): lower and upper bounds for clipping propensity scores. Bounds should be implemented such that: 0 &lt; lower &lt; upper &lt; 1, to avoid division by zero in BaseRLearner.fit_predict() step. model_kwargs: Keyword arguments to be passed to the underlying classification model.",
    "crumbs": [
      "Metalearner Propensity"
    ]
  },
  {
    "objectID": "core.causalbert.html",
    "href": "core.causalbert.html",
    "title": "CausalBert",
    "section": "",
    "text": "source\n\nCausalBertModel\n\n CausalBertModel (g_weight=0.0, Q_weight=0.1, mlm_weight=1.0,\n                  batch_size=32, max_length=128, model_name='distilbert-\n                  base-uncased')\n\nCausalBertModel is a wrapper for CausalBert\n\nsource\n\n\nCausalBert\n\n CausalBert (config)\n\nCausalBert is essentially an S-Learner that uses a DistilBert sequence classification model as the base learner.\n\nsource\n\n\nmake_bow_vector\n\n make_bow_vector (ids, vocab_size, use_counts=False)\n\nMake a sparse BOW vector from a tensor of dense ids. Args: ids: torch.LongTensor [batch, features]. Dense tensor of ids. vocab_size: vocab size for this tensor. use_counts: if true, the outgoing BOW vector will contain feature counts. If false, will contain binary indicators. Returns: The sparse bag-of-words representation of ids.\n\nsource\n\n\ngelu\n\n gelu (x)\n\n\nsource\n\n\nplatt_scale\n\n platt_scale (outcome, probs)\n\n\nsource\n\n\nCausalBertModel.train\n\n CausalBertModel.train (texts, confounds, treatments, outcomes,\n                        learning_rate=2e-05, epochs=3)\n\nTrains a CausalBert model\n\nsource\n\n\nCausalBertModel.estimate_ate\n\n CausalBertModel.estimate_ate (C, W, Y=None, platt_scaling=False)\n\nComputes average treatment effect using the trained estimator\n\nsource\n\n\nCausalBertModel.inference\n\n CausalBertModel.inference (texts, confounds, outcome=None)\n\nPerform inference using the trained model\n\n\nExample\nThis implementation of CausalBert was adapted from Causal Effects of Linguistic Properties by Pryzant et al. CausalBert is essentially a kind of S-Learner that uses a DistilBert sequence classification model as the base learner.\n\nimport pandas as pd\nfrom causalnlp.core.causalbert import CausalBertModel\n\n\ndf = pd.read_csv('sample_data/music_seed50.tsv', sep='\\t', on_bad_lines='skip')\ncb = CausalBertModel(batch_size=32, max_length=128)\ncb.train(df['text'], df['C_true'], df['T_ac'], df['Y_sim'], epochs=1, learning_rate=2e-5)\nprint(cb.estimate_ate(df['C_true'], df['text']))\n\nSome weights of CausalBert were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['Q_cls.1.0.bias', 'Q_cls.0.0.bias', 'g_cls.weight', 'Q_cls.1.0.weight', 'g_cls.bias', 'Q_cls.1.2.bias', 'Q_cls.0.2.weight', 'Q_cls.0.0.weight', 'Q_cls.0.2.bias', 'Q_cls.1.2.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 666/666 [02:12&lt;00:00,  5.01it/s]\n100%|██████████| 666/666 [00:27&lt;00:00, 24.32it/s]\n\n\n0.17478953341997637\n\n\n(Reduce the batch_size if you receive an Out-Of-Memory error when running the code above.)",
    "crumbs": [
      "CausalBert"
    ]
  },
  {
    "objectID": "meta.tlearner.html",
    "href": "meta.tlearner.html",
    "title": "T-Learner",
    "section": "",
    "text": "source\n\nMLPTRegressor\n\n MLPTRegressor (ate_alpha=0.05, control_name=0, *args, **kwargs)\n\nA parent class for T-learner regressor classes.\n\nsource\n\n\nXGBTRegressor\n\n XGBTRegressor (ate_alpha=0.05, control_name=0, *args, **kwargs)\n\nA parent class for T-learner regressor classes.\n\nsource\n\n\nBaseTClassifier\n\n BaseTClassifier (learner=None, control_learner=None,\n                  treatment_learner=None, ate_alpha=0.05, control_name=0)\n\nA parent class for T-learner classifier classes.\n\nsource\n\n\nBaseTRegressor\n\n BaseTRegressor (learner=None, control_learner=None,\n                 treatment_learner=None, ate_alpha=0.05, control_name=0)\n\nA parent class for T-learner regressor classes.\n\nsource\n\n\nBaseTLearner\n\n BaseTLearner (learner=None, control_learner=None, treatment_learner=None,\n               ate_alpha=0.05, control_name=0)\n\n*A parent class for T-learner regressor classes.\nA T-learner estimates treatment effects with two machine learning models.\nDetails of T-learner are available at Kunzel et al. (2018) (https://arxiv.org/abs/1706.03461).*",
    "crumbs": [
      "T-Learner"
    ]
  },
  {
    "objectID": "meta.explainer.html",
    "href": "meta.explainer.html",
    "title": "Metalearner Explainer",
    "section": "",
    "text": "source\n\nExplainer\n\n Explainer (method, control_name, X, tau, classes, model_tau=None,\n            features=None, normalize=True, test_size=0.3,\n            random_state=None, override_checks=False, r_learners=None)\n\n*The Explainer class handles all feature explanation/interpretation functions, including plotting feature importances, shapley value distributions, and shapley value dependency plots.\nCurrently supported methods are: - auto (calculates importance based on estimator’s default implementation of feature importance; estimator must be tree-based) Note: if none provided, it uses lightgbm’s LGBMRegressor as estimator, and “gain” as importance type - permutation (calculates importance based on mean decrease in accuracy when a feature column is permuted; estimator can be any form) - shapley (calculates shapley values; estimator must be tree-based) Hint: for permutation, downsample data for better performance especially if X.shape[1] is large\nArgs: method (str): auto, permutation, shapley control_name (str/int/float): name of control group X (np.matrix): a feature matrix tau (np.array): a treatment effect vector (estimated/actual) classes (dict): a mapping of treatment names to indices (used for indexing tau array) model_tau (sklearn/lightgbm/xgboost model object): a model object features (np.array): list/array of feature names. If None, an enumerated list will be used. normalize (bool): normalize by sum of importances if method=auto (defaults to True) test_size (float/int): if float, represents the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples (used for estimating permutation importance) random_state (int/RandomState instance/None): random state used in permutation importance estimation override_checks (bool): overrides self.check_conditions (e.g. if importance/shapley values are pre-computed) r_learners (dict): a mapping of treatment group to fitted R Learners*",
    "crumbs": [
      "Metalearner Explainer"
    ]
  },
  {
    "objectID": "autocoder.html",
    "href": "autocoder.html",
    "title": "Auto Coder",
    "section": "",
    "text": "source\n\nAutocoder\n\n Autocoder (verbose=1, device=None)\n\nAutocodes text fields\n\nsource\n\n\nAutocoder.code_sentiment\n\n Autocoder.code_sentiment (docs, df, batch_size=8, binarize=False,\n                           threshold=0.5)\n\nAutocodes text for positive or negative sentiment\nLet’s prepare a toy dataset:\n\nac = Autocoder()\nreviews = [\"I loved this doctor!\", \"This doctor was absolutely terrible.\"]\ndf = pd.DataFrame({\n    'gender': ['female', 'male'],\n     'review' : reviews,\n      })\ndf.head()\n\n\n\n\n\n\n\n\ngender\nreview\n\n\n\n\n0\nfemale\nI loved this doctor!\n\n\n1\nmale\nThis doctor was absolutely terrible.\n\n\n\n\n\n\n\nAfter autocoding for sentiment, the dataframe now has extra columns:\n\nresult_df = ac.code_sentiment(df['review'].values, df)\nresult_df.head()\n\n\n\n\n\n\n\n\ngender\nreview\nnegative\npositive\n\n\n\n\n0\nfemale\nI loved this doctor!\n0.005034\n0.994966\n\n\n1\nmale\nThis doctor was absolutely terrible.\n0.981789\n0.018211\n\n\n\n\n\n\n\n\nassert result_df[result_df['gender']=='female']['negative'].values[0] &lt; 0.1\nassert result_df[result_df['gender']=='female']['positive'].values[0] &gt; 0.9\nassert result_df[result_df['gender']=='male']['negative'].values[0] &gt; 0.9\nassert result_df[result_df['gender']=='male']['positive'].values[0] &lt; 0.1\n\n\nsource\n\n\nAutocoder.code_custom_topics\n\n Autocoder.code_custom_topics (docs, df, labels, batch_size=8,\n                               binarize=False, threshold=0.5)\n\nAutocodes text for user-specified topics. The label field is the name of the topic as a string (or a list of them.)\nLet’s prepare a toy dataset:\n\ncomments = [\"What is your favorite sitcom of all time?\", 'I cannot wait to vote!']\ndf = pd.DataFrame({\n    'over_18': ['yes', 'no'],\n     'comments' : comments,\n      })\ndf.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\n\n\n\n\n0\nyes\nWhat is your favorite sitcom of all time?\n\n\n1\nno\nI cannot wait to vote!\n\n\n\n\n\n\n\nAfter autocoding, the dataframe has a new column for each custom topic:\n\nresult_df = ac.code_custom_topics(df['comments'].values, df, labels=['television', 'film', 'politics'])\nresult_df.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\ntelevision\nfilm\npolitics\n\n\n\n\n0\nyes\nWhat is your favorite sitcom of all time?\n0.981327\n0.012260\n0.000157\n\n\n1\nno\nI cannot wait to vote!\n0.000518\n0.004943\n0.936988\n\n\n\n\n\n\n\n\nassert result_df[result_df['over_18']=='yes']['television'].values[0] &gt; 0.9\nassert result_df[result_df['over_18']=='yes']['film'].values[0] &lt; 0.1\nassert result_df[result_df['over_18']=='yes']['politics'].values[0] &lt; 0.1\nassert result_df[result_df['over_18']=='no']['television'].values[0] &lt; 0.1\nassert result_df[result_df['over_18']=='no']['film'].values[0] &lt; 0.1\nassert result_df[result_df['over_18']=='no']['politics'].values[0] &gt; 0.9\n\n\nsource\n\n\nAutocoder.code_emotion\n\n Autocoder.code_emotion (docs, df, batch_size=8, binarize=False,\n                         threshold=0.5)\n\nAutocodes text for emotion\n\ncomments = [\"I'm nervous about tomorrow.\", 'I got a promotion at work!',\n            \"My best friend was in a car accident.\", \"I hate it when I'm cut off in traffic.\"]\ndf = pd.DataFrame({\n    'over_18': ['yes', 'no', 'yes', 'yes'],\n     'comments' : comments,\n      })\ndf.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\n\n\n\n\n0\nyes\nI'm nervous about tomorrow.\n\n\n1\nno\nI got a promotion at work!\n\n\n2\nyes\nMy best friend was in a car accident.\n\n\n3\nyes\nI hate it when I'm cut off in traffic.\n\n\n\n\n\n\n\n\nresult_df = ac.code_emotion(df['comments'].values, df, binarize=True)\nresult_df.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\njoy\nanger\nfear\nsadness\n\n\n\n\n0\nyes\nI'm nervous about tomorrow.\n0\n0\n1\n0\n\n\n1\nno\nI got a promotion at work!\n1\n0\n0\n0\n\n\n2\nyes\nMy best friend was in a car accident.\n0\n0\n0\n1\n\n\n3\nyes\nI hate it when I'm cut off in traffic.\n0\n1\n0\n0\n\n\n\n\n\n\n\n\nassert result_df.iloc[0]['fear'] == 1\nassert result_df.iloc[1]['joy'] == 1\nassert result_df.iloc[2]['sadness'] == 1\nassert result_df.iloc[3]['anger'] == 1\n\n\nsource\n\n\nAutocoder.code_transformer\n\n Autocoder.code_transformer (docs, df, batch_size=32, model_name='stsb-\n                             roberta-large', show_progress_bar=False)\n\nEncode texts as semantically meaningful vectors using a Transformer model\n\nreviews = [\"I loved this doctor!\", \"This doctor was absolutely terrible.\"]\ndf = pd.DataFrame({\n    'gender': ['female', 'male'],\n     'review' : reviews,\n      })\ndf.head()\n\n\n\n\n\n\n\n\ngender\nreview\n\n\n\n\n0\nfemale\nI loved this doctor!\n\n\n1\nmale\nThis doctor was absolutely terrible.\n\n\n\n\n\n\n\n\ndf = ac.code_transformer(df.review.values, df)\n\n\ndf.head()\n\n\n\n\n\n\n\n\ngender\nreview\ne_0000\ne_0001\ne_0002\ne_0003\ne_0004\ne_0005\ne_0006\ne_0007\ne_0008\ne_0009\ne_0010\ne_0011\ne_0012\ne_0013\ne_0014\ne_0015\ne_0016\ne_0017\ne_0018\ne_0019\ne_0020\ne_0021\ne_0022\ne_0023\ne_0024\ne_0025\ne_0026\ne_0027\ne_0028\ne_0029\ne_0030\ne_0031\ne_0032\ne_0033\ne_0034\ne_0035\ne_0036\ne_0037\ne_0038\ne_0039\ne_0040\ne_0041\ne_0042\ne_0043\ne_0044\ne_0045\ne_0046\ne_0047\ne_0048\ne_0049\ne_0050\ne_0051\ne_0052\ne_0053\ne_0054\ne_0055\ne_0056\ne_0057\ne_0058\ne_0059\ne_0060\ne_0061\ne_0062\ne_0063\ne_0064\ne_0065\ne_0066\ne_0067\ne_0068\ne_0069\ne_0070\ne_0071\ne_0072\ne_0073\ne_0074\ne_0075\ne_0076\ne_0077\ne_0078\ne_0079\ne_0080\ne_0081\ne_0082\ne_0083\ne_0084\ne_0085\ne_0086\ne_0087\ne_0088\ne_0089\ne_0090\ne_0091\ne_0092\ne_0093\ne_0094\ne_0095\ne_0096\ne_0097\ne_0098\ne_0099\ne_0100\ne_0101\ne_0102\ne_0103\ne_0104\ne_0105\ne_0106\ne_0107\ne_0108\ne_0109\ne_0110\ne_0111\ne_0112\ne_0113\ne_0114\ne_0115\ne_0116\ne_0117\ne_0118\ne_0119\ne_0120\ne_0121\ne_0122\ne_0123\ne_0124\ne_0125\ne_0126\ne_0127\ne_0128\ne_0129\ne_0130\ne_0131\ne_0132\ne_0133\ne_0134\ne_0135\ne_0136\ne_0137\ne_0138\ne_0139\ne_0140\ne_0141\ne_0142\ne_0143\ne_0144\ne_0145\ne_0146\ne_0147\ne_0148\ne_0149\ne_0150\ne_0151\ne_0152\ne_0153\ne_0154\ne_0155\ne_0156\ne_0157\ne_0158\ne_0159\ne_0160\ne_0161\ne_0162\ne_0163\ne_0164\ne_0165\ne_0166\ne_0167\ne_0168\ne_0169\ne_0170\ne_0171\ne_0172\ne_0173\ne_0174\ne_0175\ne_0176\ne_0177\ne_0178\ne_0179\ne_0180\ne_0181\ne_0182\ne_0183\ne_0184\ne_0185\ne_0186\ne_0187\ne_0188\ne_0189\ne_0190\ne_0191\ne_0192\ne_0193\ne_0194\ne_0195\ne_0196\ne_0197\ne_0198\ne_0199\ne_0200\ne_0201\ne_0202\ne_0203\ne_0204\ne_0205\ne_0206\ne_0207\ne_0208\ne_0209\ne_0210\ne_0211\ne_0212\ne_0213\ne_0214\ne_0215\ne_0216\ne_0217\ne_0218\ne_0219\ne_0220\ne_0221\ne_0222\ne_0223\ne_0224\ne_0225\ne_0226\ne_0227\ne_0228\ne_0229\ne_0230\ne_0231\ne_0232\ne_0233\ne_0234\ne_0235\ne_0236\ne_0237\ne_0238\ne_0239\ne_0240\ne_0241\ne_0242\ne_0243\ne_0244\ne_0245\ne_0246\ne_0247\n...\ne_0774\ne_0775\ne_0776\ne_0777\ne_0778\ne_0779\ne_0780\ne_0781\ne_0782\ne_0783\ne_0784\ne_0785\ne_0786\ne_0787\ne_0788\ne_0789\ne_0790\ne_0791\ne_0792\ne_0793\ne_0794\ne_0795\ne_0796\ne_0797\ne_0798\ne_0799\ne_0800\ne_0801\ne_0802\ne_0803\ne_0804\ne_0805\ne_0806\ne_0807\ne_0808\ne_0809\ne_0810\ne_0811\ne_0812\ne_0813\ne_0814\ne_0815\ne_0816\ne_0817\ne_0818\ne_0819\ne_0820\ne_0821\ne_0822\ne_0823\ne_0824\ne_0825\ne_0826\ne_0827\ne_0828\ne_0829\ne_0830\ne_0831\ne_0832\ne_0833\ne_0834\ne_0835\ne_0836\ne_0837\ne_0838\ne_0839\ne_0840\ne_0841\ne_0842\ne_0843\ne_0844\ne_0845\ne_0846\ne_0847\ne_0848\ne_0849\ne_0850\ne_0851\ne_0852\ne_0853\ne_0854\ne_0855\ne_0856\ne_0857\ne_0858\ne_0859\ne_0860\ne_0861\ne_0862\ne_0863\ne_0864\ne_0865\ne_0866\ne_0867\ne_0868\ne_0869\ne_0870\ne_0871\ne_0872\ne_0873\ne_0874\ne_0875\ne_0876\ne_0877\ne_0878\ne_0879\ne_0880\ne_0881\ne_0882\ne_0883\ne_0884\ne_0885\ne_0886\ne_0887\ne_0888\ne_0889\ne_0890\ne_0891\ne_0892\ne_0893\ne_0894\ne_0895\ne_0896\ne_0897\ne_0898\ne_0899\ne_0900\ne_0901\ne_0902\ne_0903\ne_0904\ne_0905\ne_0906\ne_0907\ne_0908\ne_0909\ne_0910\ne_0911\ne_0912\ne_0913\ne_0914\ne_0915\ne_0916\ne_0917\ne_0918\ne_0919\ne_0920\ne_0921\ne_0922\ne_0923\ne_0924\ne_0925\ne_0926\ne_0927\ne_0928\ne_0929\ne_0930\ne_0931\ne_0932\ne_0933\ne_0934\ne_0935\ne_0936\ne_0937\ne_0938\ne_0939\ne_0940\ne_0941\ne_0942\ne_0943\ne_0944\ne_0945\ne_0946\ne_0947\ne_0948\ne_0949\ne_0950\ne_0951\ne_0952\ne_0953\ne_0954\ne_0955\ne_0956\ne_0957\ne_0958\ne_0959\ne_0960\ne_0961\ne_0962\ne_0963\ne_0964\ne_0965\ne_0966\ne_0967\ne_0968\ne_0969\ne_0970\ne_0971\ne_0972\ne_0973\ne_0974\ne_0975\ne_0976\ne_0977\ne_0978\ne_0979\ne_0980\ne_0981\ne_0982\ne_0983\ne_0984\ne_0985\ne_0986\ne_0987\ne_0988\ne_0989\ne_0990\ne_0991\ne_0992\ne_0993\ne_0994\ne_0995\ne_0996\ne_0997\ne_0998\ne_0999\ne_1000\ne_1001\ne_1002\ne_1003\ne_1004\ne_1005\ne_1006\ne_1007\ne_1008\ne_1009\ne_1010\ne_1011\ne_1012\ne_1013\ne_1014\ne_1015\ne_1016\ne_1017\ne_1018\ne_1019\ne_1020\ne_1021\ne_1022\ne_1023\n\n\n\n\n0\nfemale\nI loved this doctor!\n-0.601180\n0.639239\n-1.060369\n-0.493731\n-0.560601\n-1.008939\n-0.598373\n-0.672984\n-0.640709\n0.035109\n-0.394858\n1.125174\n-0.809709\n0.092503\n-1.561161\n-0.338891\n-0.980971\n-0.218150\n-0.770218\n0.518710\n-0.154178\n-0.465516\n-0.636097\n0.136777\n-0.671058\n0.887400\n1.150700\n-0.255780\n-0.124600\n-1.695019\n-0.176871\n-0.554525\n0.420271\n1.104315\n-0.662254\n-1.104489\n-0.150348\n-0.328107\n-0.265295\n-0.232560\n-0.732200\n0.102851\n1.920283\n0.345062\n0.727855\n-0.558262\n-0.727879\n0.068228\n-0.288561\n-1.376903\n0.480348\n-0.951236\n-0.184960\n-0.977992\n-0.494253\n-0.142820\n0.186124\n0.165433\n-0.054685\n0.401775\n-0.606251\n-0.400375\n0.273657\n-0.347373\n0.430465\n0.691614\n-0.515043\n-0.089149\n0.224054\n-0.449324\n-0.194017\n0.594868\n-0.614699\n-0.372429\n-0.152741\n-0.066052\n1.074707\n-0.810009\n0.675266\n-0.609482\n0.561731\n-0.939348\n-0.691044\n-0.995084\n0.166328\n-1.531809\n-0.379524\n-0.498860\n-0.741533\n-0.413629\n1.733109\n-0.791184\n-0.098716\n-1.233320\n0.137790\n0.938824\n0.544055\n-1.024858\n0.578154\n-0.508842\n-1.023441\n0.597845\n1.085201\n-1.700814\n-0.930898\n0.512371\n-1.246665\n-0.310088\n0.550669\n-1.052263\n0.829993\n-0.637790\n-0.438172\n-0.568537\n0.722001\n-0.957278\n-0.768909\n-0.160705\n1.836634\n-0.581477\n0.488977\n0.347504\n0.783655\n0.589048\n-0.770469\n0.439723\n-0.408767\n0.295209\n1.149268\n0.160561\n0.342767\n-1.275258\n-0.075461\n0.347347\n-1.197512\n-1.346758\n0.052439\n-1.996378\n0.061255\n-0.809439\n-0.636264\n-0.521608\n0.209666\n1.201379\n1.304154\n0.858928\n1.373042\n0.723125\n-0.444027\n0.397904\n-1.185389\n0.309025\n0.101140\n0.790087\n-0.622007\n-0.557396\n-1.449296\n-0.310137\n1.294056\n0.66767\n-1.077920\n-0.054805\n-0.571364\n1.299067\n-0.331780\n-0.840044\n1.282067\n0.425645\n1.46890\n-0.662942\n0.312071\n1.420856\n0.084983\n0.438224\n-0.310173\n-0.981818\n0.668649\n-1.796632\n-0.476523\n0.171581\n0.08128\n-1.055869\n0.731145\n0.082770\n0.402360\n-0.111507\n1.052606\n0.101429\n-0.436716\n-0.689745\n-0.359305\n-0.849818\n0.102386\n-0.674699\n-0.632386\n0.635284\n-0.454286\n0.002086\n-0.698927\n-1.261298\n0.795101\n-0.073547\n-0.325837\n0.421853\n-1.620993\n1.901134\n-0.371985\n-1.075006\n0.779401\n-0.981726\n1.718573\n-0.156533\n-1.501477\n0.638842\n-0.603821\n-0.441458\n-0.419934\n1.299583\n-0.329041\n0.187053\n1.476716\n0.841890\n1.378884\n1.415993\n0.490228\n0.93683\n-1.134727\n-1.298774\n-0.237284\n-0.639338\n-0.062777\n-0.571427\n-0.696611\n-1.674279\n0.200118\n0.566758\n1.258007\n0.281263\n-0.227386\n0.403024\n-0.913720\n-0.332624\n-1.145163\n-1.373416\n0.726468\n-0.116224\n-1.080073\n1.629549\n...\n-0.597258\n0.473389\n-0.087902\n-0.734512\n-0.192177\n1.098324\n0.252797\n-0.220380\n0.970834\n0.379641\n0.702579\n0.312840\n-0.014865\n0.076790\n-0.926711\n0.283459\n-0.201210\n-1.507544\n1.013160\n0.399853\n-0.560346\n-0.432460\n0.738794\n0.271019\n0.758012\n0.104948\n0.032012\n-1.118263\n0.817341\n-0.134954\n-0.367428\n-1.095511\n1.424716\n-0.45837\n-1.005259\n1.168612\n-0.739624\n-0.778042\n-0.356735\n0.470458\n0.181306\n0.867469\n-0.033199\n-0.059742\n0.067898\n-0.396584\n1.678158\n-0.886795\n0.431772\n0.239491\n-0.398206\n0.357574\n-0.649486\n0.884956\n0.774565\n-0.091967\n0.539807\n-0.098839\n0.407467\n0.022493\n0.596556\n-2.279631\n-1.012586\n-0.515414\n1.008494\n0.024449\n0.786387\n-0.039095\n-0.282467\n1.210615\n0.009027\n0.694995\n-0.778203\n-0.434733\n-0.546121\n0.111783\n-0.414437\n-0.186292\n-0.924311\n0.771270\n-0.726940\n-0.002945\n-0.904097\n-0.78010\n-1.344393\n0.419025\n0.236579\n-0.147506\n0.422931\n0.268999\n-1.120625\n-2.346339\n0.059263\n0.432407\n-0.029169\n0.342242\n-0.227718\n0.429898\n-0.487460\n0.215381\n-1.755592\n0.571806\n1.145492\n-0.595226\n0.279368\n-1.833523\n-0.318555\n-0.334240\n1.546089\n0.996179\n0.365355\n0.795756\n0.931366\n-1.328836\n2.221819\n0.533793\n0.419647\n0.607096\n1.148281\n0.962832\n-0.627507\n0.023852\n-0.977026\n0.372186\n-0.191951\n-0.261494\n1.279736\n0.743437\n0.312943\n0.249434\n-1.020184\n-0.526093\n-0.145118\n-1.224916\n0.013893\n0.314860\n-0.184937\n-0.325164\n1.366373\n0.274657\n0.026925\n-0.244764\n-0.087459\n2.440723\n-0.211444\n1.791491\n-1.783760\n1.172868\n-1.588579\n0.547428\n1.236403\n0.238765\n1.074080\n0.971804\n1.481358\n-0.260144\n-0.372862\n-1.668835\n0.814127\n0.459048\n-0.537239\n-1.363500\n-1.937048\n0.223611\n-0.093947\n0.206138\n1.323856\n-0.881426\n0.858833\n-0.481818\n-1.63406\n1.143431\n-0.822667\n-0.389236\n0.754676\n-0.474368\n1.164978\n-1.249432\n0.841197\n-0.271101\n0.239336\n-0.874708\n-0.484608\n1.776312\n-0.655398\n-0.595401\n1.292877\n-0.673088\n1.183725\n1.045448\n-0.711501\n-0.435948\n-0.414408\n-0.82087\n0.125983\n0.092412\n0.571426\n-1.369650\n0.498595\n-0.114022\n-2.056757\n-0.606038\n-0.014727\n-1.732948\n-0.208160\n-0.257968\n0.336272\n0.292738\n-1.020895\n0.707942\n-0.413066\n0.015892\n-0.870656\n0.356665\n-1.240625\n0.697207\n-0.899096\n-0.546283\n1.346067\n0.151549\n0.608179\n-0.642331\n-0.491367\n1.476060\n-0.239341\n0.210075\n0.653871\n0.124511\n-1.450796\n0.131711\n0.597644\n-0.239655\n0.151939\n-0.989297\n1.120132\n0.086377\n0.172451\n-1.515352\n-0.422561\n1.618894\n1.162732\n-0.041656\n-0.473772\n0.420647\n-0.482861\n0.206311\n-0.806356\n0.864795\n-0.179643\n-0.095540\n\n\n1\nmale\nThis doctor was absolutely terrible.\n-1.080321\n1.283710\n0.032944\n-0.505388\n-0.632284\n0.240779\n0.497700\n0.061434\n-0.951467\n-1.099914\n0.371787\n1.267668\n-0.751966\n-0.042724\n-0.142016\n0.127234\n-0.733424\n-1.139796\n-0.325070\n0.430322\n-0.098004\n1.163077\n1.057190\n0.532064\n-0.054028\n-0.344783\n1.042196\n0.132536\n0.173455\n-0.846880\n-0.294927\n-1.092173\n-0.739157\n0.072505\n-1.381498\n-0.039768\n-0.596037\n-0.635421\n-0.102166\n-0.223891\n-0.110668\n1.610051\n0.124495\n0.262522\n0.471182\n0.363986\n0.149284\n1.757610\n-0.095173\n-0.828335\n-0.169187\n-0.167354\n0.181549\n-0.468074\n0.173165\n-0.151472\n0.153541\n-0.070349\n-0.070682\n1.346813\n0.838431\n-0.173599\n-0.698330\n-0.907078\n0.686929\n-0.253123\n-0.253507\n-0.816285\n0.577228\n-0.471222\n-0.319503\n0.318208\n-1.152313\n1.608094\n0.020386\n0.240881\n1.051513\n-0.431564\n-0.734053\n0.355924\n-0.735063\n-1.024491\n-0.607373\n-0.363772\n-1.032262\n-0.755497\n-1.072544\n-0.330346\n0.112159\n-0.765853\n2.702498\n-0.059790\n-2.331072\n-0.261409\n0.662297\n-0.134803\n2.094935\n-1.216020\n-1.468843\n-0.590109\n-0.603379\n0.032229\n-0.734086\n-1.041735\n-0.096881\n0.252744\n-0.755398\n-0.196471\n-0.673408\n0.323116\n0.485170\n0.852233\n0.038043\n0.106503\n1.900742\n-0.473968\n0.440853\n-0.124218\n0.818130\n-0.249900\n0.174284\n-2.027710\n-0.841279\n-0.510334\n-1.589421\n-0.064431\n-0.204134\n0.107323\n-0.129780\n-0.373625\n-0.085754\n-0.389158\n0.630451\n0.811590\n-1.157425\n-0.036667\n0.638930\n-0.031828\n0.162673\n-0.745701\n0.047340\n0.041956\n0.455531\n1.466353\n-0.493203\n0.315198\n0.956463\n0.169743\n-0.903740\n1.078133\n-0.639152\n0.206805\n-1.212701\n0.061930\n-1.587089\n0.509692\n-0.580704\n0.743137\n0.439220\n0.11038\n-1.247447\n1.323940\n0.404472\n0.451868\n-1.951448\n-2.136478\n-0.824689\n0.520747\n0.87729\n-0.365677\n0.608508\n1.291322\n0.141776\n0.668782\n0.493870\n-0.911925\n-0.265987\n-0.342515\n0.059859\n-0.457266\n-0.24478\n1.999361\n-0.012580\n0.126561\n-0.443919\n1.152566\n-0.219918\n-0.358424\n-0.215555\n0.169946\n0.193413\n0.425413\n0.506095\n-2.375514\n-0.682047\n-0.212779\n0.261091\n-0.382527\n-0.423046\n0.087569\n0.485063\n-0.342660\n0.455986\n0.331639\n-1.648497\n1.399007\n-0.594800\n0.471352\n-0.741982\n0.568690\n-0.537344\n1.354499\n-1.521543\n0.222686\n0.505541\n-0.384466\n0.048947\n0.243410\n-1.003186\n0.442602\n1.256965\n0.718853\n1.458385\n1.336809\n-1.110115\n-0.28113\n-0.021441\n0.969155\n-0.324079\n-0.551153\n-0.346971\n-0.426813\n-0.909856\n-0.224591\n0.519270\n0.436378\n0.557002\n0.615946\n0.307261\n-0.292611\n-0.646692\n-0.091192\n-0.124168\n0.044792\n0.370954\n-1.421038\n-1.321087\n1.192953\n...\n-0.160493\n-1.280425\n-0.769862\n0.573256\n-1.297933\n1.492451\n1.244544\n0.312218\n-0.620741\n0.367966\n2.416998\n2.586343\n-1.135545\n0.896954\n0.391467\n-0.674775\n0.383277\n-0.950578\n1.830727\n-1.018144\n-0.007086\n-0.491024\n0.520239\n0.675352\n1.206401\n-1.113754\n-1.293386\n-0.928670\n0.735877\n0.426821\n-0.453119\n-0.505470\n0.643926\n-0.40995\n-1.265347\n-0.086370\n0.149850\n-0.014541\n0.152579\n0.214134\n0.190900\n0.483520\n-0.121119\n0.216187\n-0.095705\n0.484240\n-0.256438\n0.128706\n0.124124\n0.442363\n-0.328852\n0.839022\n-0.413680\n-0.218301\n0.031112\n-0.781577\n0.877376\n0.426151\n0.650736\n-0.534363\n1.324010\n-2.276321\n-3.209808\n0.747673\n-0.090331\n-0.794744\n0.910227\n0.064211\n0.187118\n-0.292773\n-0.751870\n0.891957\n-0.681515\n-1.061648\n-0.573387\n0.548157\n-0.167158\n-0.570218\n-0.115314\n0.747868\n-0.937214\n-0.019237\n-1.126545\n-0.36322\n-1.234232\n0.423862\n-0.269932\n0.576194\n0.849581\n0.444871\n-0.502688\n-1.018462\n-0.920363\n-0.202659\n-0.456458\n1.216924\n-0.185181\n0.486069\n0.267084\n0.585335\n0.036500\n-0.048680\n1.431088\n-0.141862\n0.566101\n-1.238389\n0.072949\n0.038206\n-0.293941\n1.536463\n0.458766\n-0.149625\n-0.717818\n-0.079780\n1.701869\n0.439535\n-0.174674\n0.958559\n-0.054750\n0.944752\n-0.018844\n0.701800\n-0.769989\n0.253060\n0.769639\n-0.607609\n0.696354\n0.171143\n1.106053\n0.268299\n-1.047965\n0.640154\n0.143615\n-1.105975\n-0.016227\n0.142468\n0.596629\n-0.452742\n-0.313863\n-0.227832\n-0.207953\n-0.843668\n-1.502774\n1.050109\n-0.042179\n0.633935\n-0.994892\n-0.309290\n-1.750694\n-1.035756\n-0.893423\n0.439106\n0.468417\n0.332214\n0.615565\n0.167857\n-0.761188\n-0.513775\n-0.727299\n0.233110\n0.549183\n-1.956708\n-0.498497\n-0.176335\n-1.125636\n-0.663086\n-0.504846\n-0.284807\n1.412328\n1.304304\n-0.67363\n1.146111\n-1.070053\n-0.598915\n0.518672\n-0.419871\n-0.001672\n-0.915121\n1.048180\n1.200090\n-1.123845\n-0.956011\n-0.779801\n1.226384\n0.299932\n0.497791\n-0.184537\n-0.028379\n0.185598\n0.613601\n-0.006552\n-0.340542\n0.135926\n-0.15309\n-0.933908\n-0.327588\n1.260057\n-0.727343\n-0.019971\n0.352552\n-0.667697\n-1.120148\n-0.257728\n0.343014\n0.514783\n-1.494829\n-0.767745\n-0.098165\n-0.532586\n1.300745\n0.445362\n-0.591072\n0.472784\n0.128228\n-0.951936\n-0.301227\n-0.829075\n0.356493\n2.177831\n-0.453740\n0.180738\n-0.366111\n0.788271\n-0.376016\n-0.167796\n0.945092\n0.318102\n-0.313438\n-0.521864\n-0.804645\n0.371298\n-0.102799\n-0.398658\n-0.674932\n0.712733\n0.402257\n-0.189253\n-1.744041\n0.592453\n-0.101446\n1.562682\n-0.446034\n-0.073316\n0.778162\n-0.670258\n0.576500\n-0.036422\n-0.237191\n-0.103962\n-0.018753\n\n\n\n\n2 rows × 1026 columns\n\n\n\n\nsource\n\n\nAutocoder.code_lda_topics\n\n Autocoder.code_lda_topics (docs, df, k=10, n_features=10000)\n\nEncode texts as semantically meaningful vectors using Latent Dirichlet Alocation\n\ncomments = [\"What is your favorite sitcom of all time?\", 'I cannot wait to vote!']\ndf = pd.DataFrame({\n    'over_18': ['yes', 'no'] * 5,\n     'comments' : comments * 5,\n      })\ndf.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\n\n\n\n\n0\nyes\nWhat is your favorite sitcom of all time?\n\n\n1\nno\nI cannot wait to vote!\n\n\n2\nyes\nWhat is your favorite sitcom of all time?\n\n\n3\nno\nI cannot wait to vote!\n\n\n4\nyes\nWhat is your favorite sitcom of all time?\n\n\n\n\n\n\n\n\ndf = ac.code_lda_topics(df['comments'].values, df)\n\npreprocessing texts...\nfitting model...\niteration: 1 of max_iter: 5\niteration: 2 of max_iter: 5\niteration: 3 of max_iter: 5\niteration: 4 of max_iter: 5\niteration: 5 of max_iter: 5\ndone.\ndone.\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nover_18\ncomments\ntopic_0000\ntopic_0001\ntopic_0002\ntopic_0003\ntopic_0004\ntopic_0005\ntopic_0006\ntopic_0007\ntopic_0008\ntopic_0009\n\n\n\n\n0\nyes\nWhat is your favorite sitcom of all time?\n0.148763\n0.093341\n0.080723\n0.128911\n0.109816\n0.084724\n0.093611\n0.080860\n0.091758\n0.087493\n\n\n1\nno\nI cannot wait to vote!\n0.085687\n0.097749\n0.142486\n0.084145\n0.086931\n0.099608\n0.091913\n0.114741\n0.093014\n0.103728\n\n\n2\nyes\nWhat is your favorite sitcom of all time?\n0.148763\n0.093341\n0.080723\n0.128911\n0.109816\n0.084724\n0.093611\n0.080860\n0.091758\n0.087493\n\n\n3\nno\nI cannot wait to vote!\n0.085687\n0.097749\n0.142486\n0.084145\n0.086931\n0.099608\n0.091913\n0.114741\n0.093014\n0.103728\n\n\n4\nyes\nWhat is your favorite sitcom of all time?\n0.148763\n0.093341\n0.080723\n0.128911\n0.109816\n0.084724\n0.093611\n0.080860\n0.091758\n0.087493\n\n\n\n\n\n\n\n\nsource\n\n\nAutocoder.code_callable\n\n Autocoder.code_callable (docs, df, fn)\n\nAutocodes text for any user-specified function The fn parameter must be a Callable and return a dictionary for each text in docs where the keys are desired column names and values are scores or probabilities.\n\nreviews = [\"I loved this doctor!\", \"This doctor was absolutely terrible.\"]\ndf = pd.DataFrame({\n    'gender': ['female', 'male'],\n     'review' : reviews,\n      })\ndf.head()\n\n\n\n\n\n\n\n\ngender\nreview\n\n\n\n\n0\nfemale\nI loved this doctor!\n\n\n1\nmale\nThis doctor was absolutely terrible.\n\n\n\n\n\n\n\n\ndef some_function(x):\n    val = int('terrible' in x)\n    return {'has_the_word_terrible?' : val}\n\n\ndf = ac.code_callable(df.review.values, df, some_function)\n\n\ndf.head()\n\n\n\n\n\n\n\n\ngender\nreview\nhas_the_word_terrible?\n\n\n\n\n0\nfemale\nI loved this doctor!\n0\n\n\n1\nmale\nThis doctor was absolutely terrible.\n1",
    "crumbs": [
      "Auto Coder"
    ]
  }
]