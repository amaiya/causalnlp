---

title: CausalBert


keywords: fastai
sidebar: home_sidebar

summary: "CausalBert API"
description: "CausalBert API"
nb_path: "nbs/00b_core.causalbert.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/00b_core.causalbert.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="platt_scale" class="doc_header"><code>platt_scale</code><a href="https://github.com/amaiya/causalnlp/tree/main/causalnlp/core/causalbert.py#L43" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>platt_scale</code>(<strong><code>outcome</code></strong>, <strong><code>probs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gelu" class="doc_header"><code>gelu</code><a href="https://github.com/amaiya/causalnlp/tree/main/causalnlp/core/causalbert.py#L51" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gelu</code>(<strong><code>x</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="make_bow_vector" class="doc_header"><code>make_bow_vector</code><a href="https://github.com/amaiya/causalnlp/tree/main/causalnlp/core/causalbert.py#L55" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>make_bow_vector</code>(<strong><code>ids</code></strong>, <strong><code>vocab_size</code></strong>, <strong><code>use_counts</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Make a sparse BOW vector from a tensor of dense ids.
Args:
    ids: torch.LongTensor [batch, features]. Dense tensor of ids.
    vocab_size: vocab size for this tensor.
    use_counts: if true, the outgoing BOW vector will contain
        feature counts. If false, will contain binary indicators.
Returns:
    The sparse bag-of-words representation of ids.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CausalBert" class="doc_header"><code>class</code> <code>CausalBert</code><a href="https://github.com/amaiya/causalnlp/tree/main/causalnlp/core/causalbert.py#L80" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CausalBert</code>(<strong><code>config</code></strong>) :: <code>DistilBertPreTrainedModel</code></p>
</blockquote>
<p>CausalBert is essentially an S-Learner that uses a DistilBert sequence classification model as the base learner.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CausalBertModel" class="doc_header"><code>class</code> <code>CausalBertModel</code><a href="https://github.com/amaiya/causalnlp/tree/main/causalnlp/core/causalbert.py#L178" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CausalBertModel</code>(<strong><code>g_weight</code></strong>=<em><code>0.0</code></em>, <strong><code>Q_weight</code></strong>=<em><code>0.1</code></em>, <strong><code>mlm_weight</code></strong>=<em><code>1.0</code></em>, <strong><code>batch_size</code></strong>=<em><code>32</code></em>, <strong><code>max_length</code></strong>=<em><code>128</code></em>, <strong><code>model_name</code></strong>=<em><code>'distilbert-base-uncased'</code></em>)</p>
</blockquote>
<p>CausalBertModel is a wrapper for CausalBert</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="CausalBertModel.train" class="doc_header"><code>CausalBertModel.train</code><a href="__main__.py#L204" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>CausalBertModel.train</code>(<strong><code>texts</code></strong>, <strong><code>confounds</code></strong>, <strong><code>treatments</code></strong>, <strong><code>outcomes</code></strong>, <strong><code>learning_rate</code></strong>=<em><code>2e-05</code></em>, <strong><code>epochs</code></strong>=<em><code>3</code></em>)</p>
</blockquote>
<p>Trains a CausalBert model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="CausalBertModel.estimate_ate" class="doc_header"><code>CausalBertModel.estimate_ate</code><a href="__main__.py#L265" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>CausalBertModel.estimate_ate</code>(<strong><code>C</code></strong>, <strong><code>W</code></strong>, <strong><code>Y</code></strong>=<em><code>None</code></em>, <strong><code>platt_scaling</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Computes average treatment effect using the trained estimator</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="CausalBertModel.inference" class="doc_header"><code>CausalBertModel.inference</code><a href="__main__.py#L241" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>CausalBertModel.inference</code>(<strong><code>texts</code></strong>, <strong><code>confounds</code></strong>, <strong><code>outcome</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Perform inference using the trained model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3><p>This implementation of <a href="/causalnlp/core.causalbert.html#CausalBert"><code>CausalBert</code></a> was adapted from <a href="https://arxiv.org/abs/2010.12919">Causal Effects of Linguistic Properties</a> by Pryzant et al.  <a href="/causalnlp/core.causalbert.html#CausalBert"><code>CausalBert</code></a> is essentially a kind of <a href="https://arxiv.org/abs/1706.03461">S-Learner</a> that uses a DistilBert sequence classification model as the base learner.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sample_data/music_seed50.tsv&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">error_bad_lines</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">causalnlp.core.causalbert</span> <span class="kn">import</span> <span class="n">CausalBertModel</span>
<span class="n">cb</span> <span class="o">=</span> <span class="n">CausalBertModel</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">cb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;C_true&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;T_ac&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Y_sim&#39;</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">estimate_ate</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;C_true&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of CausalBert were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#39;Q_cls.1.0.bias&#39;, &#39;Q_cls.0.0.bias&#39;, &#39;g_cls.weight&#39;, &#39;Q_cls.1.0.weight&#39;, &#39;g_cls.bias&#39;, &#39;Q_cls.1.2.bias&#39;, &#39;Q_cls.0.2.weight&#39;, &#39;Q_cls.0.0.weight&#39;, &#39;Q_cls.0.2.bias&#39;, &#39;Q_cls.1.2.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
100%|██████████| 666/666 [02:12&lt;00:00,  5.01it/s]
100%|██████████| 666/666 [00:27&lt;00:00, 24.32it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.17478953341997637
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>(Reduce the <code>batch_size</code> if you receive an Out-Of-Memory error when running the code above.)</p>

</div>
</div>
</div>
</div>


